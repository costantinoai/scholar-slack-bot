[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Mechanisms of human dynamic object recognition revealed by sequential deep neural networks",
            "pub_year": 2023,
            "citation": "PLOS Computational Biology 19 (6), e1011169, 2023",
            "author": "Lynn KA S\u00f6rensen and Sander M Boht\u00e9 and Dorina De Jong and Heleen A Slagter and H Steven Scholte",
            "journal": "PLOS Computational Biology",
            "volume": "19",
            "number": "6",
            "pages": "e1011169",
            "publisher": "Public Library of Science",
            "abstract": "Humans can quickly recognize objects in a dynamically changing world. This ability is showcased by the fact that observers succeed at recognizing objects in rapidly changing image sequences, at up to 13 ms/image. To date, the mechanisms that govern dynamic object recognition remain poorly understood. Here, we developed deep learning models for dynamic recognition and compared different computational mechanisms, contrasting feedforward and recurrent, single-image and sequential processing as well as different forms of adaptation. We found that only models that integrate images sequentially via lateral recurrence mirrored human performance (N = 36) and were predictive of trial-by-trial responses across image durations (13\u201380 ms/image). Importantly, models with sequential lateral-recurrent integration also captured how human performance changes as a function of image presentation durations, with models processing images for a few time steps capturing human object recognition at shorter presentation durations and models processing images for more time steps capturing human object recognition at longer presentation durations. Furthermore, augmenting such a recurrent model with adaptation markedly improved dynamic recognition performance and accelerated its representational dynamics, thereby predicting human trial-by-trial responses using fewer processing resources. Together, these findings provide new insights into the mechanisms rendering object recognition so fast and effective in a dynamic visual world."
        },
        "filled": true,
        "author_pub_id": "ph4erJcAAAAJ:bUkhZ_yRbTwC",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=786475816840652614,11665162515710256917",
        "cites_id": [
            "786475816840652614",
            "11665162515710256917"
        ],
        "pub_url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011169",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Ruc4p5Yf6goJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Testing, explaining, and exploring models of facial expressions of emotions",
            "pub_year": 2023,
            "citation": "Science Advances 9 (6), eabq8421, 2023",
            "author": "Lukas Snoek and Rachael E Jack and Philippe G Schyns and Oliver GB Garrod and Maximilian Mittenb\u00fchler and Chaona Chen and Suzanne Oosterwijk and H Steven Scholte",
            "journal": "Science Advances",
            "volume": "9",
            "number": "6",
            "pages": "eabq8421",
            "publisher": "American Association for the Advancement of Science",
            "abstract": "Models are the hallmark of mature scientific inquiry. In psychology, this maturity has been reached in a pervasive question\u2014what models best represent facial expressions of emotion? Several hypotheses propose different combinations of facial movements [action units (AUs)] as best representing the six basic emotions and four conversational signals across cultures. We developed a new framework to formalize such hypotheses as predictive models, compare their ability to predict human emotion categorizations in Western and East Asian cultures, explain the causal role of individual AUs, and explore updated, culture-accented models that improve performance by reducing a prevalent Western bias. Our predictive models also provide a noise ceiling to inform the explanatory power and limitations of different factors (e.g., AUs and individual differences). Thus, our framework provides a new approach to test models \u2026"
        },
        "filled": true,
        "author_pub_id": "ph4erJcAAAAJ:gDB6RRZydyMC",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=7002285372602988915",
        "cites_id": [
            "7002285372602988915"
        ],
        "pub_url": "https://www.science.org/doi/abs/10.1126/sciadv.abq8421",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:cznqWXIdLWEJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Human visual cortex and deep convolutional neural network care deeply about object background",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.04. 14.536853, 2023",
            "author": "Jessica Loke and Noor Seijdel and Lukas Snoek and Lynn KA S\u00f6rensen and Ron van de Klundert and Matthew van der Meer and Eva Quispel and Natalie Cappaert and H Steven Scholte",
            "journal": "bioRxiv",
            "pages": "2023.04. 14.536853",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Deep convolutional neural networks (DCNNs) are able to predict brain activity during object categorization tasks, but factors contributing to this predictive power are not fully understood. Our study aimed to investigate the factors contributing to the predictive power of DCNNs in object categorization tasks. We compared the activity of four DCNN architectures with electroencephalography (EEG) recordings obtained from 62 human subjects during an object categorization task. Previous physiological studies on object categorization have highlighted the importance of figure-ground segregation - the ability to distinguish objects from their backgrounds. Therefore, we set out to investigate if figureground segregation could explain DCNNs predictive power. Using a stimuli set consisting of identical target objects embedded in different backgrounds, we examined the influence of object background versus object category on both EEG and DCNN activity. Crucially, the recombination of naturalistic objects and experimentally-controlled backgrounds creates a sufficiently challenging and naturalistic task, while allowing us to retain experimental control. Our results showed that early EEG activity (<100ms) and early DCNN layers represent object background rather than object category. We also found that the predictive power of DCNNs on EEG activity is related to processing of object backgrounds, rather than categories. We provided evidence from both trained and untrained (i.e. random weights) DCNNs, showing figure-ground segregation to be a crucial step prior to the learning of object features. These findings suggest that both human visual cortex and \u2026"
        },
        "filled": true,
        "author_pub_id": "ph4erJcAAAAJ:1KpZK2B-YNUC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.04.14.536853.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:vMwF-mOtfpsJ:scholar.google.com/",
        "cites_per_year": {}
    }
]