[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The Topo-Speech sensory substitution system as a method of conveying spatial information to the blind and vision impaired",
            "pub_year": 2023,
            "citation": "Frontiers in Human Neuroscience 16, 1058093, 2023",
            "author": "Amber Maimon and Iddo Yehoshua Wald and Meshi Ben Oz and Sophie Codron and Ophir Netzer and Benedetta Heimler and Amir Amedi",
            "journal": "Frontiers in Human Neuroscience",
            "volume": "16",
            "pages": "1058093",
            "publisher": "Frontiers",
            "abstract": "Humans, like most animals, integrate sensory input in the brain from different sensory modalities. Yet humans are distinct in their ability to grasp symbolic input, which is interpreted into a cognitive mental representation of the world. This representation merges with external sensory input, providing modality integration of a different sort. This study evaluates the Topo-Speech algorithm in the blind and visually impaired. The system provides spatial information about the external world by applying sensory substitution alongside symbolic representations in a manner that corresponds with the unique way our brains acquire and process information. This is done by conveying spatial information, customarily acquired through vision, through the auditory channel, in a combination of sensory (auditory) features and symbolic language (named/spoken) features. The Topo-Speech sweeps the visual scene or image and represents objects\u2019 identity by employing naming in a spoken word and simultaneously conveying the objects\u2019 location by mapping the x-axis of the visual scene or image to the time it is announced and the y-axis by mapping the location to the pitch of the voice. This proof of concept study primarily explores the practical applicability of this approach in 22 visually impaired and blind individuals. The findings showed that individuals from both populations could effectively interpret and use the algorithm after a single training session. The blind showed an accuracy of 74.45%, while the visually impaired had an average accuracy of 72.74%. These results are comparable to those of the sighted in previous research, with all participants above chance \u2026"
        },
        "filled": true,
        "author_pub_id": "WADV6B4AAAAJ:5qfkUJPXOUwC",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=16892733435608100720",
        "cites_id": [
            "16892733435608100720"
        ],
        "pub_url": "https://www.frontiersin.org/articles/10.3389/fnhum.2022.1058093/full",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:cO_I4o4Lb-oJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Activation of human visual area V6 during egocentric navigation with and without visual experience",
            "pub_year": 2023,
            "citation": "Current Biology 33 (7), 1211-1219. e5, 2023",
            "author": "Elena Aggius-Vella and Daniel-Robert Chebat and Shachar Maidenbaum and Amir Amedi",
            "journal": "Current Biology",
            "volume": "33",
            "number": "7",
            "pages": "1211-1219. e5",
            "publisher": "Elsevier",
            "abstract": "V6 is a retinotopic area located in the dorsal visual stream that integrates eye movements with retinal and visuo-motor signals. Despite the known role of V6 in visual motion, it is unknown whether it is involved in navigation and how sensory experiences shape its functional properties. We explored the involvement of V6 in egocentric navigation in sighted and in congenitally blind (CB) participants navigating via an in-house distance-to-sound sensory substitution device (SSD), the EyeCane. We performed two fMRI experiments on two independent datasets. In the first experiment, CB and sighted participants navigated the same mazes. The sighted performed the mazes via vision, while the CB performed them via audition. The CB performed the mazes before and after a training session, using the EyeCane SSD. In the second experiment, a group of sighted participants performed a motor topography task. Our results \u2026"
        },
        "filled": true,
        "author_pub_id": "WADV6B4AAAAJ:rmuvC79q63oC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=10626438882499226593",
        "cites_id": [
            "10626438882499226593"
        ],
        "pub_url": "https://www.cell.com/current-biology/pdf/S0960-9822(23)00165-3.pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:4evDwtyxeJMJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Loss of action-related function and connectivity in the blind extrastriate body area",
            "pub_year": 2023,
            "citation": "Frontiers in Neuroscience 17, 973525, 2023",
            "author": "Or Yizhar and Zohar Tal and Amir Amedi",
            "journal": "Frontiers in Neuroscience",
            "volume": "17",
            "pages": "973525",
            "publisher": "Frontiers",
            "abstract": "The Extrastriate Body Area (EBA) participates in the visual perception and motor actions of body parts. We recently showed that EBA\u2019s perceptual function develops independently of visual experience, responding to stimuli with body-part information in a supramodal fashion. However, it is still unclear if the EBA similarly maintains its action-related function. Here, we used fMRI to study motor-evoked responses and connectivity patterns in the congenitally blind brain. We found that, unlike the case of perception, EBA does not develop an action-related response without visual experience. In addition, we show that congenital blindness alters EBA\u2019s connectivity profile in a counterintuitive way \u2013 functional connectivity with sensorimotor cortices dramatically decreases, whereas connectivity with perception-related visual occipital cortices remains high. To the best of our knowledge, we show for the first time that action-related functions and connectivity in the visual cortex could be contingent on visuomotor experience. We further discuss the role of the EBA within the context of visuomotor control and predictive coding theory."
        },
        "filled": true,
        "author_pub_id": "WADV6B4AAAAJ:HbR8gkJAVGIC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=14607532973391630393",
        "cites_id": [
            "14607532973391630393"
        ],
        "pub_url": "https://www.frontiersin.org/articles/10.3389/fnins.2023.973525/full",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:OVDQY9hhuMoJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Shape detection beyond the visual field using a visual-to-auditory sensory augmentation device",
            "pub_year": 2023,
            "citation": "Frontiers in Human Neuroscience 17, 1058617, 2023",
            "author": "Shira Shvadron and Adi Snir and Amber Maimon and Or Yizhar and Sapir Harel and Keinan Poradosu and Amir Amedi",
            "journal": "Frontiers in Human Neuroscience",
            "volume": "17",
            "pages": "1058617",
            "publisher": "Frontiers",
            "abstract": "Current advancements in both technology and science allow us to manipulate our sensory modalities in new and unexpected ways. In the present study, we explore the potential of expanding what we perceive through our natural senses by utilizing a visual-to-auditory sensory substitution device, the EyeMusic, an algorithm that converts images to sound. The EyeMusic was initially developed to allow blind individuals to create a spatial representation of information arriving from a video feed at a slow sampling rate. Here we aimed to use the EyeMusic for the blind areas of sighted individuals. We use it in this initial proof of concept study to test the ability of sighted subjects to combine visual information with surrounding auditory sonification representing visual information. Participants in this study were tasked with recognizing and adequately placing the stimuli, using sound to represent the areas outside the standard human visual field. As such, the participants were asked to report shapes\u2019 identities as well as their spatial orientation (Front/Right/Back/Left), requiring combined visual (90\u00b0 frontal) and auditory input (the remaining 270\u00b0) for the successful performance of the task (content in both vision and audition was presented in a sweeping clockwise motion around the participant). We found that participants were successful at a highly above-chance level after a brief one-hour-long session of online training and one on-site training session of an average of 20 minutes. They could even draw a 2D representation of this image in some cases. Participants could also generalize, recognizing new shapes they were not explicitly trained on. Our findings \u2026"
        },
        "filled": true,
        "author_pub_id": "WADV6B4AAAAJ:86PQX7AUzd4C",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=2200221823558888348",
        "cites_id": [
            "2200221823558888348"
        ],
        "pub_url": "https://www.frontiersin.org/articles/10.3389/fnhum.2023.1058617/full?fbclid=IwAR1nxdN2iZVAq74W3kM8kF8urlhOBwoTTH7-GF0iwQ77CZAzUlvEddKQ5Sg",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:nCtKXBfCiB4J:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Decoding reach direction in early \u201cvisual\u201d cortex of congenitally blind individuals",
            "pub_year": 2023,
            "citation": "Journal of Neuroscience, 2023",
            "author": "\u0141ukasz Bola and Petra Vetter and Mohr Wenger and Amir Amedi",
            "journal": "Journal of Neuroscience",
            "publisher": "Society for Neuroscience",
            "abstract": "Motor actions, such as reaching or grasping, can be decoded from fMRI activity of early visual cortex in sighted humans. This effect can depend on vision or visual imagery, or alternatively, could be driven by mechanisms independent of visual experience. Here, we show that the actions of reaching in different directions can be reliably decoded from fMRI activity of early visual cortex in congenitally blind humans (both sexes). Thus, neither visual experience nor visual imagery is necessary for early visual cortex to represent action-related information. We also demonstrate that, within early visual cortex of blind humans, the accuracy of reach direction decoding is highest in areas typically representing foveal vision and gradually decreases in areas typically representing peripheral vision. We propose that this might indicate the existence of a predictive, hard-wired mechanism of aligning action and visual spaces. This \u2026"
        },
        "filled": true,
        "author_pub_id": "WADV6B4AAAAJ:FAceZFleit8C",
        "num_citations": 0,
        "pub_url": "https://www.jneurosci.org/content/early/2023/09/21/JNEUROSCI.0376-23.2023.abstract",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Rapid plasticity in the ventral visual stream elicited by a newly learnt auditory script in congenitally blind adults",
            "pub_year": 2023,
            "citation": "Neuropsychologia, 108685, 2023",
            "author": "Roni Arbel and Benedetta Heimler and Amir Amedi",
            "journal": "Neuropsychologia",
            "pages": "108685",
            "publisher": "Pergamon",
            "abstract": "Accumulating evidence in the last decades has given rise to a new theory of brain organization, positing that cortical regions are recruited for specific tasks irrespective of the sensory modality via which information is channeled. For instance, the visual reading network has been shown to be recruited for reading via the tactile Braille code in congenitally blind adults. Yet, how rapidly non-typical sensory input modulates activity in typically visual regions is yet to be explored. To this aim, we developed a novel reading orthography, termed OVAL, enabling congenitally blind adults to quickly acquire reading via the auditory modality. OVAL uses the EyeMusic, a visual-to-auditory sensory-substitution-device (SSD) to transform visually presented letters optimized for auditory transformation into sound. Using fMRI, we show modulation in the right ventral visual stream following 2-h of same-day training. Crucially, following \u2026"
        },
        "filled": true,
        "author_pub_id": "WADV6B4AAAAJ:_FM0Bhl9EiAC",
        "num_citations": 0,
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S0028393223002191",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Integrating mind and body: Investigating differential activation of nodes of the default mode network",
            "pub_year": 2023,
            "citation": "Restorative Neurology and Neuroscience, 1-13, 2023",
            "author": "Inbal Linchevski and Amber Maimon and Yulia Golland and Noa Zeharia and Amir Amedi and Nava Levit-Binnun",
            "journal": "Restorative Neurology and Neuroscience",
            "number": "Preprint",
            "pages": "1-13",
            "publisher": "IOS Press",
            "abstract": "Background:The default mode network (DMN) is a large-scale brain network tightly correlated with self and self-referential processing, activated by intrinsic tasks and deactivated by externally-directed tasks.Objective:In this study, we aim to investigate the novel approach of default mode activation during progressive muscle relaxation and examine whether differential activation patterns result from the movement of different body parts.Methods:We employed neuroimaging to investigate DMN activity during simple body movements, while performing progressive muscle relaxation. We focused on differentiating the neural response between facial movements and movements of other body parts.Results:Our results show that the movement of different body parts led to deactivation in several DMN nodes, namely the temporal poles, hippocampus, medial prefrontal cortex (mPFC), and posterior cingulate cortex. However \u2026"
        },
        "filled": true,
        "author_pub_id": "WADV6B4AAAAJ:GtLg2Ama23sC",
        "num_citations": 0,
        "pub_url": "https://content.iospress.com/articles/restorative-neurology-and-neuroscience/rnn231334",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Correction: A self-training program for sensory substitution devices",
            "pub_year": 2023,
            "citation": "Plos one 18 (6), e0287802, 2023",
            "author": "Galit Buchs and Benedetta Heimler and Menachem Kerem and Shachar Maidenbaum and Liraz Braun and Amir Amedi",
            "journal": "Plos one",
            "volume": "18",
            "number": "6",
            "pages": "e0287802",
            "publisher": "Public Library of Science",
            "abstract": "The second author\u2019s name is spelled incorrectly. The correct name is: Benedetta Heimler. The correct citation is: Buchs G, Heimler B, Kerem M, Maidenbaum S, Braun L, Amedi A (2021) A self-training program for sensory substitution devices. PLoS ONE 16 (4): e0250281. https://doi. org/10.1371/journal. pone. 0250281"
        },
        "filled": true,
        "author_pub_id": "WADV6B4AAAAJ:4fGpz3EwCPoC",
        "num_citations": 0,
        "pub_url": "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0287802&type=printable",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:-Ux1pP-PBqQJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Breathing based immersive interactions for enhanced agency and body awareness: a claustrophobia motivated study",
            "pub_year": 2023,
            "citation": "Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing \u2026, 2023",
            "author": "Iddo Yehoshua Wald and Amber Maimon and Lucas Keniger De Andrade Gensas and Noemi Guiot and Meshi Ben Oz and Benjamin W Corn and Amir Amedi",
            "pages": "1-7",
            "abstract": "This work explores utilizing representations of one\u2019s physiological breath (embreathment) in immersive experiences, for enhancing presence and body awareness. Particularly, embreathment is proposed for reducing claustrophobia and associated negative cognitions such as feelings of restriction, loss of agency, and sense of suffocation, by enhancing agency and interoception in circumstances where one\u2019s ability to act is restricted. The informed design process of an experience designed for this purpose is presented, alongside an experiment employing the experience, evaluating embodiment, presence, and interoception. The results indicate that embreathment leads to significantly greater levels of embodiment and presence than either an entrainment or control condition. In addition, a modest trend was observed in a heartbeat detection task implying better interoception in the intervention conditions than the \u2026"
        },
        "filled": true,
        "author_pub_id": "WADV6B4AAAAJ:Ri6SYOTghG4C",
        "num_citations": 0,
        "pub_url": "https://dl.acm.org/doi/abs/10.1145/3544549.3585897",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:WLXCJriMcpkJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Persuasive Vibrations: Effects of Speech-Based Vibrations on Persuasion, Leadership, and Co-Presence During Verbal Communication in VR",
            "pub_year": 2023,
            "citation": "2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR), 552-560, 2023",
            "author": "Justine Saint-Aubert and Ferran Argelaguet and Marc Mac\u00e9 and Claudio Pacchierotti and Amir Amedi and Anatole L\u00e9cuyer",
            "conference": "2023 IEEE Conference Virtual Reality and 3D User Interfaces (VR)",
            "pages": "552-560",
            "publisher": "IEEE",
            "abstract": "In Virtual Reality (VR), a growing number of applications involve verbal communications with avatars, such as for teleconference, entertainment, virtual training, social networks, etc. In this context, our paper aims to investigate how tactile feedback consisting in vibrations synchronized with speech could influence aspects related to VR social interactions such as persuasion, co-presence and leadership. We conducted two experiments where participants embody a first-person avatar attending a virtual meeting in immersive VR. In the first experiment, participants were listening to two speaking virtual agents and the speech of one agent was augmented with vibrotactile feedback. Interestingly, the results show that such vibrotactile feedback could significantly improve the perceived co-presence but also the persuasiveness and leadership of the haptically-augmented agent. In the second experiment, the participants \u2026"
        },
        "filled": true,
        "author_pub_id": "WADV6B4AAAAJ:_axFR9aDTf0C",
        "num_citations": 0,
        "pub_url": "https://ieeexplore.ieee.org/abstract/document/10108422/",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:xLE5gwTRlycJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Testing geometry and 3D perception in children following vision restoring cataract-removal surgery",
            "pub_year": 2023,
            "citation": "Frontiers in Neuroscience 16, 962817, 2023",
            "author": "Amber Maimon and Ophir Netzer and Benedetta Heimler and Amir Amedi",
            "journal": "Frontiers in Neuroscience",
            "volume": "16",
            "pages": "962817",
            "publisher": "Frontiers",
            "abstract": "As neuroscience and rehabilitative techniques advance, age-old questions concerning the visual experience of those who gain sight after blindness, once thought to be philosophical alone, take center stage and become the target for scientific inquiries. In this study, we employ a battery of visual perception tasks to study the unique experience of a small group of children who have undergone vision-restoring cataract removal surgery as part of the Himalayan Cataract Project. We tested their abilities to perceive in three dimensions (3D) using a binocular rivalry task and the Brock string task, perceive visual illusions, use cross-modal mappings between touch and vision, and spatially group based on geometric cues. Some of the children in this study gained a sense of sight for the first time in their lives, having been born with bilateral congenital cataracts, while others suffered late-onset blindness in one eye alone. This study simultaneously supports yet raises further questions concerning Hubel and Wiesel's critical periods theory and provides additional insight into Molyneux's problem, the ability to correlate vision with touch quickly. We suggest that our findings present a relatively unexplored intermediate stage of 3D vision development. Importantly, we spotlight some essential geometrical perception visual abilities that strengthen the idea that spontaneous geometry intuitions arise independently from visual experience (and education), thus replicating and extending previous studies. We incorporate a new model, not previously explored, of testing children with congenital cataract removal surgeries who perform the task via vision. In contrast \u2026"
        },
        "filled": true,
        "author_pub_id": "WADV6B4AAAAJ:PVjk1bu6vJQC",
        "num_citations": 0,
        "pub_url": "https://www.frontiersin.org/articles/10.3389/fnins.2022.962817/full",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:K8qSIE7h3f8J:scholar.google.com/",
        "cites_per_year": {}
    }
]