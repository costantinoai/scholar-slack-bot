[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
<<<<<<< Updated upstream
=======
            "title": "An asynchronous, hands-off workflow for looking time experiments with infants.",
            "pub_year": 2024,
            "citation": "Developmental Psychology, 2024",
            "author": "Gal Raz and Sabrina Piccolo and Janine Medrano and Shari Liu and Kirsten Lydic and Catherine Mei and Victoria Nguyen and Tianmin Shu and Rebecca Saxe",
            "journal": "Developmental Psychology",
            "publisher": "American Psychological Association",
            "abstract": "The study of infant gaze has long been a key tool for understanding the developing mind. However, labor-intensive data collection and processing limit the speed at which this understanding can be advanced. Here, we demonstrate an asynchronous workflow for conducting violation-of-expectation (VoE) experiments, which is fully \u201chands-off\u201d for the experimenter. We first replicate four classic VoE experiments in a synchronous online setting, and show that VoE can generate highly replicable effects through remote testing. We then confirm the accuracy of a state-of-the-art gaze annotation software, iCatcher+ in a new setting. Third, we train parents to control the experiment flow based on the infant\u2019s gaze. Combining all three innovations, we then conduct an asynchronous automated infant-contingent VoE experiment. The hands-off workflow successfully replicates a classic VoE effect: infants look longer at inefficient \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:EPG8bYD4jVwC",
        "num_citations": 0,
        "pub_url": "https://psycnet.apa.org/record/2024-97072-001",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:UdFgdQ5C1BkJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Generous acts have contrasting meanings in equal versus hierarchical social relationships",
            "pub_year": 2024,
            "citation": "",
            "author": "Alicia M Chen and Rebecca Saxe",
            "abstract": "What expectations do acts of generosity create for future social interactions? In online behavioral experiments presenting human observers (N= 1159 English-speaking adults in the United States) with naturalistic vignettes, we find that knowing about the structure (equal or hierarchical) of an existing social relationship markedly reshapes people's expectations for sequences of generous acts. Notably, people do not always expect reciprocal generosity. In hierarchical relationships, people expect the opposite\u2014that the same person will repeat the generous act, following a precedent. These expectations are governed by abstract rules, tailored to specific cultural scripts, affect how people feel about generous acts, and can be used to communicate the desired structure of relationships."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:kF1pexMAQbMC",
        "num_citations": 0,
        "pub_url": "https://europepmc.org/article/ppr/ppr866079",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:j2YIUCHtTO0J:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Intervening on Emotions by Planning Over a Theory of Mind",
            "pub_year": 2024,
            "citation": "Proceedings of the Annual Meeting of the Cognitive Science Society 46, 2024",
            "author": "Tony Chen and Sean Dae Houlihan and Kartik Chandra and Josh Tenenbaum and Rebecca Saxe",
            "journal": "Proceedings of the Annual Meeting of the Cognitive Science Society",
            "volume": "46",
            "abstract": "Much of social cognition involves reasoning about others\u2019 minds: predicting their reactions, inferring their feelings, and explaining their behavior. By representing mental contents like beliefs, desires, and emotions, Bayesian theory of mind mod- els have made progress in capturing how humans manage these cognitive feats. But social life is not merely observation: hu- mans must also plan to intervene on these same mental con- tents. The present work models how people choose interven- tions to influence others\u2019 emotions. Building on a prior model of people\u2019s intuitive theory of emotions, we model how people use their intuitive theory to evaluate and simulate the effects of different interventions. We apply our model to data from behavioral experiments requiring counterfactual and joint in- terventions, and show a close alignment with human choices. Our results provide a step towards a potentially unifying expla- nation for emotion prediction and intervention, suggesting that they could arise from the same underlying generative model."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:kzcSZmkxUKAC",
        "num_citations": 0,
        "pub_url": "https://escholarship.org/uc/item/4gz7c85c",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:-FkiZe94kcUJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "How to Change a Mind: Adults and Children Use the Causal Structure of Theory of Mind to Intervene on Others\u2019 Behaviors",
            "pub_year": 2024,
            "citation": "Proceedings of the Annual Meeting of the Cognitive Science Society 46, 2024",
            "author": "Shengyi Wu and Laura Schulz and Rebecca Saxe",
            "journal": "Proceedings of the Annual Meeting of the Cognitive Science Society",
            "volume": "46",
            "abstract": "Prior studies of Theory of Mind have primarily asked observers to predict others\u2019 actions given their beliefs and desires, or to infer agents\u2019 beliefs and desires given observed actions. However, if Theory of Mind is genuinely a causal theory, people should also be able to plan interventions on others\u2019 mental states to change their behavior. The intuitive causal model of Theory of Mind predicts an asymmetry: one has to instill both the relevant belief and desire to cause an agent to act; however, to prevent a likely action, it suffices to remove either the relevant belief or desire. Here, we use these asymmetric causal interventions to probe the structure of Theory of Mind. In Experiments 1 and 2, both adults (N=80) and older children (N=42, 8-10 years) distinguished generative and preventative cases: selecting interventions on both mental states (both belief and desire) to induce an agent to act and just one of the mental states (either belief or desire) to prevent an action. However, younger children (N =42, 5-7 years) did not. To probe this age difference, in Experiment 3, we asked younger children(N=42, 5-7 years) just to predict the outcome of others\u2019 mental state interventions. Children predicted that interventions were more likely to prevent actions than to cause them, but failed to predict that intervening on both the relevant beliefs and desires is more likely to generate a novel action than intervening on either alone. These findings suggest that by eight to ten years old, people represent the causal structure of Theory of Mind and can selectively intervene on beliefs and desires to induce and prevent others\u2019 actions."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:WAzi4Gm8nLoC",
        "num_citations": 0,
        "pub_url": "https://escholarship.org/uc/item/5n09t35c",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Eq2IhxgEavQJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Predicting graded dishabituation in a rational learning model using perceptual stimulus embeddings",
            "pub_year": 2024,
            "citation": "Proceedings of the Annual Meeting of the Cognitive Science Society 46, 2024",
            "author": "Anjie Cao and Gal Raz and Rebecca Saxe and Michael C Frank",
            "journal": "Proceedings of the Annual Meeting of the Cognitive Science Society",
            "volume": "46",
            "abstract": "How do humans decide what to look at and when to stop looking? The Rational Action, Noisy Choice for Habituation (RANCH) model formulates looking behaviors as a rational information acquisition process. RANCH instantiates a hypothesis about the perceptual encoding process using a neural network-derived embedding space, which allows it to operate on raw images. In this paper, we show that the model not only captures key looking time patterns such as habituation and dishabituation, but also makes fine-grained, out-of-sample predictions about magnitudes of dishabituation to previously unseen stimuli. We validated those predictions experimentally with a self-paced looking time task in adults (N = 468). We also show that model fits are robust across parameters, but that assumptions about the perceptual encoding process, the learning process and the decision process are all critical for predicting human performance."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:raTqNPD5sRQC",
        "num_citations": 0,
        "pub_url": "https://escholarship.org/uc/item/96b1m7gh",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:cFgzdXRq46AJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Computational Social Cognition: Approaches and challenges",
            "pub_year": 2024,
            "citation": "Proceedings of the Annual Meeting of the Cognitive Science Society 46, 2024",
            "author": "Ismail Guennouni and Joseph M Barnby and Julian Jara-Ettinger and Rebecca Saxe and Maarten Speekenbrink",
            "volume": "46",
            "abstract": "Predicting the actions and reactions of others is crucial to suc- cessful social interaction. When deciding whether to bluff in a game of poker, we consider the chances that the other players will fold or continue to play and unmask our bluff. When deciding whether to tell our boss that their plans are likely to have adverse effects, we consider a range of reac- tions, from being grateful for our honesty to being dismissed out of spite. Such predictions are highly uncertain and com- plex, not least because the other\u2019s (re)actions usually result from them making equally complex and uncertain inferences about us. Nevertheless, we are often remarkably successful \u2013 although sometimes utterly wrong \u2013 in our social inferences. How do we explain these successes and failures?"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:YsrPvlHIBpEC",
        "num_citations": 0,
        "pub_url": "https://escholarship.org/uc/item/7930b0r3",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Qn1tReefKGQJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "How taking turns communicates desired equality in social relationships",
            "pub_year": 2024,
            "citation": "OSF, 2024",
            "author": "Alicia M Chen and Rebecca Saxe",
            "publisher": "OSF",
            "abstract": "When people perform generous acts for each other, they can balance out relative benefits by alternating who is generous. When and why do they do this? Here we test the explanation that sequences of generosity regulate social relationships. We find that people selectively expect reciprocal generosity in equal (vs. hierarchical) relationships, use reciprocal generosity to infer the presence of an equal relationship, and critically expect that people reciprocate generosity in order to communicate a desire for a (more) equal relationship. In a formal planning model, reciprocal generosity can emerge from the value of communicating desired equality."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:-nhnvRiOwuoC",
        "num_citations": 0,
        "pub_url": "https://osf.io/zmfe7/download",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:V176wQuDaykJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Predicting graded dishabituation using perceptual stimulus embeddings in a rational learning model",
            "pub_year": 2024,
            "citation": "OSF, 2024",
            "author": "Anjie Cao and Gal Raz and Rebecca Saxe and Michael C Frank",
            "publisher": "OSF",
            "abstract": "How do humans decide what to look at and when to stop looking? The Rational Action, Noisy Choice for Habituation (RANCH) model formulates looking behaviors as a rational information acquisition process. RANCH instantiates a hypothesis about the perceptual encoding process using a neural network-derived embedding space, which allows it to operate on raw images. In this paper, we show that the model not only captures key looking time patterns such as habituation and dishabituation, but also makes fine-grained, out-of-sample predictions about magnitudes of dishabituation to previously unseen stimuli. We validated those predictions experimentally with a self-paced looking time task in adults (N= 468). We also show that model fits are robust across parameters, but that assumptions about the perceptual encoding process, the learning process and the decision process are all critical for predicting human performance."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:3bvyWxjaHKcC",
        "num_citations": 0,
        "pub_url": "https://osf.io/jeqdm/download",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:kYL_zUyDKncJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Precision fMRI reveals that the language network exhibits adult-like left-hemispheric lateralization by 4 years of age",
            "pub_year": 2024,
            "citation": "bioRxiv, 2024.05. 15.594172, 2024",
            "author": "Ola Ozernov-Palchik and Amanda M O'Brien and Elizabeth Jiachen Lee and Hilary Richardson and Rachel Romeo and Benjamin Lipkin and Hannah Small and James Capella and Alfonso Nieto-Castanon and Rebecca Saxe and John DE Gabrieli and Evelina Fedorenko",
            "journal": "bioRxiv",
            "pages": "2024.05. 15.594172",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Left hemisphere damage in adulthood often leads to linguistic deficits, but many cases of early damage leave linguistic processing preserved, and a functional language system can develop in the right hemisphere. To explain this early apparent equipotentiality of the two hemispheres for language, some have proposed that the language system is bilateral during early development and only becomes left-lateralized with age. We examined language lateralization using functional magnetic resonance imaging with two large pediatric cohorts (total n=273 children ages 4-16; n=107 adults). Strong, adult-level left-hemispheric lateralization (in activation volume and response magnitude) was evident by age 4. Thus, although the right hemisphere can take over language function in some cases of early brain damage, and although some features of the language system do show protracted development (magnitude of language response and strength of inter-regional correlations in the language network), the left-hemisphere bias for language is robustly present by 4 years of age."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:w1MjKQ0l0TYC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2024.05.15.594172.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Z-0vQHakPcYJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Representation of navigational affordances and ego-motion in the occipital place area",
            "pub_year": 2024,
            "citation": "bioRxiv, 2024.04. 30.591964, 2024",
            "author": "Frederik S Kamps and Emily M Chen and Nancy Kanwisher and Rebecca Saxe",
            "journal": "bioRxiv",
            "pages": "2024.04. 30.591964",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Humans effortlessly use vision to plan and guide navigation through the local environment, or \"scene\". A network of three cortical regions responds selectively to visual scene information, including the occipital (OPA), parahippocampal (PPA), and medial place areas (MPA) - but how this network supports visually-guided navigation is unclear. Recent evidence suggests that one region in particular, the OPA, supports visual representations for navigation, while PPA and MPA support other aspects of scene processing. However, most previous studies tested only static scene images, which lack the dynamic experience of navigating through scenes. We used dynamic movie stimuli to test whether OPA, PPA, and MPA represent two critical kinds of navigationally-relevant information: navigational affordances (e.g., can I walk to the left, right, or both?) and ego-motion (e.g., am I walking forward or backward? turning left or right?). We found that OPA is sensitive to both affordances and ego-motion, as well as the conflict between these cues - e.g., turning toward versus away from an open doorway. These effects were significantly weaker or absent in PPA and MPA. Responses in OPA were also dissociable from those in early visual cortex, consistent with the idea that OPA responses are not merely explained by lower-level visual features. OPA responses to affordances and ego-motion were stronger in the contralateral than ipsilateral visual field, suggesting that OPA encodes navigationally relevant information within an egocentric reference frame. Taken together, these results support the hypothesis that OPA contains visual representations that are useful \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:FiDNX6EVdGUC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2024.04.30.591964.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:b46bhzZsEFwJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "An Efficient Multimodal fMRI Localizer for High-Level Visual, Auditory, and Cognitive Regions in Humans",
            "pub_year": 2024,
            "citation": "OSF, 2024",
            "author": "Samuel Hutchinson and Ammar Marvi and Frederik Kamps and Evelina Fedorenko and Rebecca Saxe and Nancy Kanwisher",
            "publisher": "OSF",
            "abstract": "Research using functional MRI (fMRI) and other neuroimaging methods has provided extensive evidence that some regions of the cortex in humans serve highly specific functions (Kanwisher 2010). In order to study these regions and characterize their representations, we need to first find them. While these functionally-specific cortical regions generally co-localize across people, their precise location varies from one individual to the next. It is therefore necessary to functionally identify each region in each participant individually with a functional localizer scan. However there are many such regions, and running a large number of localizer scans to identify each of them is expensive and time consuming. Here we test the effectiveness of a new experimental design to functionally localize multiple regions of interest robustly, efficiently, and accurately in each participant individually in just 23 minutes of fMRI scan time per person. This new localizer\u2013which presents simultaneous auditory and visual stimuli\u2013is designed to identify, within individual participants, cortical regions selectively engaged in visually processing faces, scenes, bodies, words, and objects, as well as speech sounds, language, and theory of mind. Here we test the success of this new localizer against the current gold standard of established standard localizers for these functions."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:pAkWuXOU-OoC",
        "num_citations": 0,
        "pub_url": "https://osf.io/gjsdb/resources",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:3YtiBYeYujYJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "An asynchronous, automated workflow for looking time experiments with infants",
            "pub_year": 2024,
            "citation": "",
            "author": "Gal Raz and SH Piccolo and Janine A Medrano and Shari Liu and Kirsten Lydic and Catherine Mei and Victoria Nguyen and Tianmin Shu and Rebecca Saxe",
            "abstract": "The study of infant gaze has long been a key tool for understanding the developing mind. However, labor-intensive data collection and processing limit the speed at which this understanding can be advanced. Here, we demonstrate a fully asynchronous, automated workflow for conducting Violation-of-Expectation (VoE) experiments. We first replicate four classic VoE experiments in a synchronous online setting, and show that VoE can generate highly replicable effects through remote testing. We then confirm the accuracy of a state-of-the-art gaze annotation software, iCatcher+ in a new setting. Third, we train parents to control the experiment flow based on the infant's gaze. Combining all three innovations, we then conduct an asynchronous automated infant-contingent VoE experiment. The automatic workflow successfully replicates a classic VoE effect: infants look longer at inefficient actions than efficient ones. We compare the resulting effect size and statistical power to the same study run in-lab and synchronously via Zoom. The automated workflow significantly reduces the marginal cost and time per participant, enabling larger sample sizes. By enhancing the reproducibility and robustness of findings relying on infant looking, this workflow could help support a cumulative science of infant cognition. Tools to implement the workflow are openly available."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:mKu_rENv82IC",
        "num_citations": 0,
        "pub_url": "https://europepmc.org/article/ppr/ppr807558",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:G-LpJgHbHYgJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Study 5: Zoo Prediction (Child Age 5-7)",
            "pub_year": 2024,
            "citation": "OSF, 2024",
            "author": "Shengyi Wu and Laura Schulz and Rebecca Saxe",
            "publisher": "OSF",
            "abstract": "Many studies have shown that preschoolers can use others' beliefs and desires to predict or explain their behaviors. However, previous work has not looked at whether children can use their understanding of others' mental states to try to change their behaviors. There is an asymmetry between the interventions needed to induce someone to take a new action and the interventions to stop someone from taking a planned action. To induce someone to act, you must ensure that they have both the relevant beliefs and desires; to prevent someone from acting, it is sufficient to remove either the relevant beliefs or desires. In previous work, we saw that adult participants tended to intervene on both beliefs and desires to cause an agent to take an action but only intervened on either the agent's belief or desire to prevent the agent from taking a planned action. We used the same experimental stimuli used in the adult study to see if there is an asymmetry between generative and preventative interventions when young children at the ages of 5-7 design interventions to change others' actions. We didn't see the expected asymmetry of interventions in 5-7-year-old children. Then, we used the same experimental stimuli to test if there is an asymmetry between generative and preventative interventions when older children at the ages of 8-10 design interventions to change others' actions. The results show that older children are able to distinguish generative and preventative outcomes and selectively intervene on both beliefs and desires to cause agents to act but intervene either on beliefs or desires to prevent an action. Why did younger children at the ages of 5 to \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:-jrNzM816MMC",
        "num_citations": 0,
        "pub_url": "https://osf.io/fvwjt/resources",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Fgt7nCN_CiMJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
>>>>>>> Stashed changes
            "title": "Open dataset of theory of mind reasoning in early to middle childhood",
            "pub_year": 2023,
            "citation": "Data in Brief, 109905, 2023",
            "author": "Koraima Sotomayor Enriquez and Hyowon Gweon and Rebecca Saxe and Hilary Richardson",
            "journal": "Data in Brief",
            "pages": "109905",
            "publisher": "Elsevier",
            "abstract": "Theory of mind (ToM) reasoning refers to the process by which we reason about the mental states (beliefs, desires, emotions) of others. Here, we describe an open dataset of responses from children who completed a story booklet task for assessing ToM reasoning (n=321 3\u201312-year-old children, including 64 (neurotypical) children assessed longitudinally and 68 autistic children). Children completed one of two versions of the story booklet task (Booklet 1 or 2). Both versions include two-alternative forced choice and free response questions that tap ToM concepts ranging in difficulty from reasoning about desires and beliefs to reasoning about moral blameworthiness and mistaken referents. Booklet 2 additionally includes items that assess understanding of sarcasm, lies, and second-order belief-desire reasoning. Compared to other ToM tasks, the booklet task provides relatively dense sampling of ToM reasoning \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:jFemdcug13IC",
        "num_citations": 0,
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S2352340923009484",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Left-Hemisphere Cortical Language Regions Respond Equally to Observed Dialogue and Monologue",
            "pub_year": 2023,
            "citation": "Neurobiology of Language, 1-36, 2023",
            "author": "Halie A Olson and Emily M Chen and Kirsten O Lydic and Rebecca R Saxe",
            "journal": "Neurobiology of Language",
            "pages": "1-36",
            "publisher": "MIT Press",
            "abstract": "Much of the language we encounter in our everyday lives comes in the form of conversation, yet the majority of research on the neural basis of language comprehension has used input from only one speaker at a time. Twenty adults were scanned while passively observing audiovisual conversations using functional magnetic resonance imaging. In a block-design task, participants watched 20 s videos of puppets speaking either to another puppet (the dialogue condition) or directly to the viewer (the monologue condition), while the audio was either comprehensible (played forward) or incomprehensible (played backward). Individually functionally localized left-hemisphere language regions responded more to comprehensible than incomprehensible speech but did not respond differently to dialogue than monologue. In a second task, participants watched videos (1\u20133 min each) of two puppets conversing with \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:rHJHxKgnXwkC",
        "num_citations": 0,
        "pub_url": "https://direct.mit.edu/nol/article/doi/10.1162/nol_a_00123/117766",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Emotion prediction as computation over a generative theory of mind",
            "pub_year": 2023,
            "citation": "Philosophical Transactions of the Royal Society A 381 (2251), 20220047, 2023",
            "author": "Sean Dae Houlihan and Max Kleiman-Weiner and Luke B Hewitt and Joshua B Tenenbaum and Rebecca Saxe",
            "journal": "Philosophical Transactions of the Royal Society A",
            "volume": "381",
            "number": "2251",
            "pages": "20220047",
            "publisher": "The Royal Society",
            "abstract": "From sparse descriptions of events, observers can make systematic and nuanced predictions of what emotions the people involved will experience. We propose a formal model of emotion prediction in the context of a public high-stakes social dilemma. This model uses inverse planning to infer a person\u2019s beliefs and preferences, including social preferences for equity and for maintaining a good reputation. The model then combines these inferred mental contents with the event to compute \u2018appraisals\u2019: whether the situation conformed to the expectations and fulfilled the preferences. We learn functions mapping computed appraisals to emotion labels, allowing the model to match human observers\u2019 quantitative predictions of 20 emotions, including joy, relief, guilt and envy. Model comparison indicates that inferred monetary preferences are not sufficient to explain observers\u2019 emotion predictions; inferred social \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:kw52XkFRtyQC",
        "num_citations": 7,
        "citedby_url": "/scholar?hl=en&cites=16940775940699691363",
        "cites_id": [
            "16940775940699691363"
        ],
        "pub_url": "https://royalsocietypublishing.org/doi/abs/10.1098/rsta.2022.0047",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Y5njRPa5GesJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 7
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Habituation reflects optimal exploration over noisy perceptual samples",
            "pub_year": 2023,
            "citation": "Topics in Cognitive Science 15 (2), 290-302, 2023",
            "author": "Anjie Cao and Gal Raz and Rebecca Saxe and Michael C Frank",
            "journal": "Topics in Cognitive Science",
            "volume": "15",
            "number": "2",
            "pages": "290-302",
            "abstract": "From birth, humans constantly make decisions about what to look at and for how long. Yet, the mechanism behind such decision\u2010making remains poorly understood. Here, we present the rational action, noisy choice for habituation (RANCH) model. RANCH is a rational learning model that takes noisy perceptual samples from stimuli and makes sampling decisions based on expected information gain (EIG). The model captures key patterns of looking time documented in developmental research: habituation and dishabituation. We evaluated the model with adult looking time collected from a paradigm analogous to the infant habituation paradigm. We compared RANCH with baseline models (no learning model, no perceptual noise model) and models with alternative linking hypotheses (Surprisal, KL divergence). We showed that (1) learning and perceptual noise are critical assumptions of the model, and (2 \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:AHdEip9mkN0C",
        "num_citations": 5,
        "citedby_url": "/scholar?hl=en&cites=2959474266126945977",
        "cites_id": [
            "2959474266126945977"
        ],
        "pub_url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/tops.12631",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:uQ5oQioqEikJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 4
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Preliminary evidence for selective cortical responses to music in one\u2010month\u2010old infants",
            "pub_year": 2023,
            "citation": "Developmental Science, e13387, 2023",
            "author": "Heather L Kosakowski and Samuel Norman\u2010Haignere and Anna Mynick and Atsushi Takahashi and Rebecca Saxe and Nancy Kanwisher",
            "journal": "Developmental Science",
            "pages": "e13387",
            "abstract": "Prior studies have observed selective neural responses in the adult human auditory cortex to music and speech that cannot be explained by the differing lower\u2010level acoustic properties of these stimuli. Does infant cortex exhibit similarly selective responses to music and speech shortly after birth? To answer this question, we attempted to collect functional magnetic resonance imaging (fMRI) data from 45 sleeping infants (2.0\u2010 to 11.9\u2010weeks\u2010old) while they listened to monophonic instrumental lullabies and infant\u2010directed speech produced by a mother. To match acoustic variation between music and speech sounds we (1) recorded music from instruments that had a similar spectral range as female infant\u2010directed speech, (2) used a novel excitation\u2010matching algorithm to match the cochleagrams of music and speech stimuli, and (3) synthesized \u201cmodel\u2010matched\u201d stimuli that were matched in spectrotemporal \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:FiytvqdAVhgC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=18080781322115500175",
        "cites_id": [
            "18080781322115500175"
        ],
        "pub_url": "https://onlinelibrary.wiley.com/doi/abs/10.1111/desc.13387",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:j0g2_tDW6_oJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 3
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "No evidence for discontinuity between infants and adults",
            "pub_year": 2023,
            "citation": "PsyArXiv. February 14, 2023",
            "author": "Shari Liu and Gal Raz and Frederik Kamps and Tobias Grossmann and Rebecca Saxe",
            "volume": "14",
            "abstract": "Based on studies of infant gaze, developmental psychologists have ascribed abstract cognitive functions to young infants. In their thought-provoking article, Blumberg and Adolph (B+ A)[1] consider the implications of developmental neurobiology for these claims. Abstract cognitive functions in adults depend on cortical circuits; however, B+ A hypothesize that the developing cortex is too immature to drive gaze in the youngest infants. If this is true, then subcortical regions must be driving all observed gaze behavior in young infants."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:IaI1MmNe2tcC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=8371457581924684",
        "cites_id": [
            "8371457581924684"
        ],
        "pub_url": "https://www.cell.com/trends/cognitive-sciences/newarticles",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:TEFs28u9HQAJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 3
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Desperation and inequality increase stealing: evidence from experimental microsocieties",
            "pub_year": 2023,
            "citation": "Royal Society Open Science 10 (7), 221385, 2023",
            "author": "Setayesh Radkani and Eleanor Holton and Beno\u00eet De Courson and Rebecca Saxe and Daniel Nettle",
            "journal": "Royal Society Open Science",
            "volume": "10",
            "number": "7",
            "pages": "221385",
            "publisher": "The Royal Society",
            "abstract": "People facing material deprivation are more likely to turn to acquisitive crime. It is not clear why it makes sense for them to do so, given that apprehension and punishment may make their situation even worse. Recent theory suggests that people should be more willing to steal if they are on the wrong side of a \u2018desperation threshold\u2019; that is, a level of resources critical to wellbeing. Below such a threshold, people should pursue any risky behaviour that offers the possibility of a short route back above, and should be insensitive to the severity of possible punishments, since they have little left to lose. We developed a multi-round, multi-player economic game with a desperation threshold and the possibility of theft as well as cooperation. Across four experiments with 1000 UK and US adults, we showed that falling short of a desperation threshold increased stealing from other players, even when the payoff from stealing \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:XUvXOeBm_78C",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=7409749943785088462",
        "cites_id": [
            "7409749943785088462"
        ],
        "pub_url": "https://royalsocietypublishing.org/doi/abs/10.1098/rsos.221385",
        "cites_per_year": {
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Challenging the classical view: recognition of identity and expression as integrated processes",
            "pub_year": 2023,
            "citation": "Brain Sciences 13 (2), 296, 2023",
            "author": "Emily Schwartz and Kathryn O\u2019Nell and Rebecca Saxe and Stefano Anzellotti",
            "journal": "Brain Sciences",
            "volume": "13",
            "number": "2",
            "pages": "296",
            "publisher": "MDPI",
            "abstract": "Recent neuroimaging evidence challenges the classical view that face identity and facial expression are processed by segregated neural pathways, showing that information about identity and expression are encoded within common brain regions. This article tests the hypothesis that integrated representations of identity and expression arise spontaneously within deep neural networks. A subset of the CelebA dataset is used to train a deep convolutional neural network (DCNN) to label face identity (chance = 0.06%, accuracy = 26.5%), and the FER2013 dataset is used to train a DCNN to label facial expression (chance = 14.2%, accuracy = 63.5%). The identity-trained and expression-trained networks each successfully transfer to labeling both face identity and facial expression on the Karolinska Directed Emotional Faces dataset. This study demonstrates that DCNNs trained to recognize face identity and DCNNs trained to recognize facial expression spontaneously develop representations of facial expression and face identity, respectively. Furthermore, a congruence coefficient analysis reveals that features distinguishing between identities and features distinguishing between expressions become increasingly orthogonal from layer to layer, suggesting that deep neural networks disentangle representational subspaces corresponding to different sources."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:j7_hQOaDUrUC",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=3749881966985276588",
        "cites_id": [
            "3749881966985276588"
        ],
        "pub_url": "https://www.mdpi.com/2076-3425/13/2/296",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:rOzM_8dBCjQJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Left-hemisphere cortical language regions respond equally to dialogue and monologue",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.01. 30.526344, 2023",
            "author": "Halie Ann Olson and Emily May-Ying Chen and Kirsten Lydic and Rebecca Saxe",
            "journal": "bioRxiv",
            "pages": "2023.01. 30.526344",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Much of the language we encounter in our everyday lives comes in the form of conversation, yet the majority of research on the neural basis of language comprehension has used language input from a single source. To determine whether canonical left-hemisphere language regions are sensitive to features of dialogue beyond the comprehensibility of the speech stream, we scanned 20 adults on two novel tasks using functional magnetic resonance imaging. In the first, participants watched videos of puppets speaking either to the viewer (monologue) or to a partner (dialogue), while the audio was either comprehensible (forward) or reversed (backward). Canonical left-hemisphere language regions responded more to forward than backward speech, as expected, but did not respond more to dialogue than monologue. In a second task, two puppets conversed with each other, but only one was comprehensible while the other's speech stream was reversed. Left-hemisphere cortical language regions again responded more to forward than backwards speech, and activity in these regions was only correlated among participants who heard the same characters speaking forward and backward. In contrast, some theory of mind regions and right hemisphere homologues of language regions responded more to dialogue than monologue, and activity in some of these regions was correlated among participants even when opposite characters were speaking forward and backward (in both cases, the visual video clips were held constant). Together, these experiments suggest that canonical left-hemisphere cortical language regions are only sensitive to the \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:7BrZ7Jt4UNcC",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=12778227426865949946",
        "cites_id": [
            "12778227426865949946"
        ],
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.01.30.526344.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:-qx_jSRiVbEJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Using fMRI to study the neural basis of violation-of-expectation",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 4925-4925, 2023",
            "author": "Shari Liu and Kirsten Lydic and Rebecca Saxe",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "4925-4925",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Why do babies look longer when objects float in midair, or people behave inefficiently (Carey; 2009; Spelke 2022) during violation-of-expectation (VOE) studies? Here we test two non-mutually exclusive hypotheses. One hypothesis is that VOE is supported (H1) by domain-general processes, like visual prediction error and endogenous attention. A second hypothesis is that VOE is supported (H2) by domain-specific prediction error over psychological and physical expectations. These hypotheses predict responses in distinct neural regions. Whereas the domain-general hypothesis predicts greater responses to unexpected than expected events in visual and multiple demand regions, that generalize across domains, the domain-specific hypothesis predicts greater responses to unexpected events in different regions depending on the domain (eg supramarginal gyrus for physics, superior temporal sulcus for \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:6yz0xqPARnAC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=9348763344785872511",
        "cites_id": [
            "9348763344785872511"
        ],
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791584",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Left-hemisphere cortical language regions respond equally to observed dialogue and monologue",
            "pub_year": 2023,
            "citation": "Neurobiology of Language, 1-89, 2023",
            "author": "Halie Olson and Emily Chen and Kirsten Lydic and Rebecca Saxe",
            "journal": "Neurobiology of Language",
            "pages": "1-89",
            "publisher": "MIT Press",
            "abstract": "Much of the language we encounter in our everyday lives comes in the form of conversation, yet the majority of research on the neural basis of language comprehension has used input from only one speaker at a time. 20 adults were scanned while passively observing audiovisual conversations using functional magnetic resonance imaging. In a block-design task, participants watched 20-second videos of puppets speaking either to another puppet (the \u201cdialogue\u201d condition) or directly to the viewer (\u201cmonologue\u201d), while the audio was either comprehensible (played forward) or incomprehensible (played backward). Individually functionally-localized left-hemisphere language regions responded more to comprehensible than incomprehensible speech but did not respond differently to dialogue than monologue. In a second task, participants watched videos (1\u20133 minutes each) of two puppets conversing with each \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:rHJHxKgnXwkC",
        "num_citations": 0,
        "pub_url": "https://direct.mit.edu/nol/article/doi/10.1162/nol_a_00123/117766",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Neural correlates of theory of mind reasoning in congenitally blind children",
            "pub_year": 2023,
            "citation": "Developmental Cognitive Neuroscience 63, 101285, 2023",
            "author": "Hilary Richardson and Rebecca Saxe and Marina Bedny",
            "journal": "Developmental Cognitive Neuroscience",
            "volume": "63",
            "pages": "101285",
            "publisher": "Elsevier",
            "abstract": "Vision is an important source of information about other minds for sighted children, especially prior to the onset of language. Visually observed actions, eye gaze, and facial expressions of others provide information about mental states, such as beliefs, desires, and emotions. Does such experience contribute causally to the development of cortical networks supporting social cognition? To address this question we compared functional development of brain regions supporting theory of mind (ToM), as well as behavioral ToM reasoning, across congenitally blind (n=17) and sighted (n=114) children and adolescents (4\u201317 years old). We find that blind children in this age range show slightly lower ToM behavioral performance relative to sighted children. Likewise, the functional profile of ToM brain regions is qualitatively similar, but quantitatively weaker in blind relative to sighted children. Alongside prior research, these \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:prdVHNxh-e8C",
        "num_citations": 0,
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S1878929323000907",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Study 2: Zoo Intervention (Adult version)",
            "pub_year": 2023,
            "citation": "OSF, 2023",
            "author": "Shengyi Wu and Laura Schulz and Rebecca Saxe",
            "publisher": "OSF",
            "abstract": "In this study, we are interested in if and how people use a causal Theory of Mind framework to plan to change others' actions. If actions are jointly caused by appropriate pairs of desires and beliefs, there exists an asymmetry between the interventions to induce someone to take a new action and the interventions to stop someone from taking a planned action. To induce someone to act, you have to ensure that they have both the relevant beliefs and desires; to prevent someone from acting, it is sufficient to remove either the relevant beliefs or desires. In a previous study, we tested for this asymmetry between generative and preventative interventions using vignettes of real-life situations that describe characters' mental states and plans to act or not to act. For each vignette, we gave participants three action options: choice A is intended to change what the other character believes; choice B is intended to change what the other character desires/wants, and choice C is to perform both A and B. We found that people's choices of action varied significantly based on if the interventions are generative, where the goal is to make the character act when they had not previously intended to, or preventative, where the goal is to prevent the character from taking the action they had initially intended. More specifically, adult participants chose the options that act on others' both desires and beliefs more often in the generative than the preventative condition. In the current study, we use a rank of preference paradigm to test whether adults make this distinction in intervening on others' beliefs and desires to generate versus prevent their actions. In each story stimulus, we \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:DBa1UEJaJKAC",
        "num_citations": 0,
        "pub_url": "https://osf.io/fm6s3/resources",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Conceptual and perceptual novelty reflect distinct motives of infant looking: Meta-analytic evidence",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Linette Kunin and Sabrina Piccolo and Rebecca Saxe and Shari Liu",
            "publisher": "PsyArXiv",
            "abstract": "Infants look longer at events that are unexpected (eg a ball floating in midair) and at events that are different from what they have previously seen (eg rightward motion, after repeated exposure to leftward motion). This has led to debate about whether shared or distinct mechanisms lead infants to look longer toward unexpected events (the violation-of-expectation response, or VOE) versus visually novel events (the perceptual novelty response, or PN). Here, we studied both looking behaviors using meta-analysis of condition-level data (from 34 papers, 78 conditions, and 1915 infants) and mega-analysis of infant-level data (from 25 papers, 60 conditions, and 1482 infants) from prior studies of infants\u2019 understanding of agents and objects. First, we estimated VOE and PN in the same data and found that showing infants an unexpected event drove their looking behavior as reliably as showing infants a visually novel event. Second, we tested whether VOE and PN are supported by similar or distinct mechanisms. Under the hypothesis that both responses are driven by a common mechanism, the same factors should predict the size of both effects. However, these responses were moderated by different predictors. The PN effect was larger after infants were habituated instead of familiarized, and did not differ depending on infant age. The VOE effect, in contrast, was not moderated by habituation vs familiarization and was larger for younger infants. These findings suggest that these two responses reflect distinct drivers of infant visual attention"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:CdxZDUztZiMC",
        "num_citations": 0,
        "pub_url": "https://osf.io/preprints/psyarxiv/kx76y/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "An empirical testbed for models of information seeking in infants",
            "pub_year": 2023,
            "citation": "OSF, 2023",
            "author": "Janine A Medrano and Gal Raz and Anjie Cao and Michael C Frank and Rebecca Saxe",
            "publisher": "OSF",
            "abstract": "This study attempts to elicit dishabituation in response to different types of violations using a within-subjects design. By showing each infants several familiarization-test blocks, and varying the way in which the test differs from the familiarization (by varying number of items, pose, animacy and identity), we ask whether different types of violations elicit different degrees of dishabituation relative to a background test trials, in which the same familiar stimulus is shown again. The goal is to compare behavior on this task to our computational model, GRANCH, which generates predictions on the same stimuli."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:Ade32sEp0pkC",
        "num_citations": 0,
        "pub_url": "https://osf.io/auf8e/resources",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Development of navigational affordance perception in infancy",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5716-5716, 2023",
            "author": "Frederik Kamps and Emily Chen and Adele Mah and Stephanie Washburn and Nancy Kanwisher and Rebecca Saxe",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5716-5716",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Shortly after learning to crawl or walk, toddlers successfully use vision to guide navigation through the local visual space. How does this ability develop? One hypothesis is that the emergence of navigational affordance perception depends on active navigation experience (eg, crawling). However, this hypothesis has never been tested, as almost all prior work conflates perception of navigational affordances with the integration of this information into a motor plan. Here we developed a measure of navigational affordance perception based only on preferential looking. Infants and toddlers viewed 10s videos depicting an egocentric perspective of navigation toward the corner of a room, with one wall containing an open doorway affording further navigation, and the other containing a perceptually similar distractor. Across three experiments, 16-month-old toddlers looked significantly more toward doorways (i) relative to \u2026"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:3NQIlFlcGxIC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2792558",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "What people learn from punishment: joint inference of wrongness and punisher\u2019s motivations from observation of punitive choices",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Setayesh Radkani and Rebecca Saxe",
            "publisher": "PsyArXiv",
            "abstract": "Punishment is a cost imposed on a target, in response to an undesirable action. Yet choosing to punish also reveals information about the authority\u2019s own motives and values. We propose that observers jointly infer the wrongness of the action and the authority\u2019s motivations. Using hypothetical scenarios in unfamiliar societies, we experimentally manipulated observers\u2019 prior beliefs and measured human observers\u2019 inferences after observing punishment. These inferences were recapitulated in a formal model that inverts an intuitive causal model of authorities who make rational choices about punishment by weighing its costs and benefits (ie utilities). An essential component of this model, driving these inferences, is that legitimate authorities consider the utility of a proportional response to harmful actions, which depends on the balance between the wrongness of the act and the severity of the punishment."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:PYBJJbyH-FwC",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/9sbmn/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:VXK6OAQSJRMJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Author Correction: Single-neuronal predictions of others\u2019 beliefs in humans",
            "pub_year": 2023,
            "citation": "Nature, 1-1, 2023",
            "author": "Mohsen Jamali and Benjamin L Grannan and Evelina Fedorenko and Rebecca Saxe and Raymundo B\u00e1ez-Mendoza and Ziv M Williams",
            "journal": "Nature",
            "pages": "1-1",
            "publisher": "Nature Publishing Group UK",
            "abstract": "When we recently reconstructed our recording locations on a standardized 3D brain model, we observed that the recording sites were in near proximity to those originally estimated but were also more posterolateral and somewhat broader in distribution. These recordings collectively spanned the superior frontal gyrus as well as part of its medial middle frontal gyrus border. These observations do not alter the neuronal findings or results of the paper and do not affect the analyses or other figures. There are two interesting implications of these observations, though, with respect to prior functional imaging studies."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:7H_MAutzIkAC",
        "num_citations": 0,
        "pub_url": "https://www.nature.com/articles/s41586-023-06263-6",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:pXmxnV8jsk8J:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "People have systematic expectations linking social relationships to patterns of reciprocal altruism",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Alicia M Chen and Rebecca Saxe",
            "publisher": "PsyArXiv",
            "abstract": "In two-person asymmetric coordination dilemmas, both people are better off if they coordinate, but one person benefits more than the other. When these interactions recur, people can form expectations to balance who is better off over time. What does it mean when asymmetric social interactions recur, and what can we learn from how people solve these dilemmas? We hypothesize that people expect social interactions to recur when two people are in a social relationship, and that knowing about the symmetry of the social relationship influences the stable solution to asymmetric coordination dilemmas over time. We report two experiments where participants read stories and answered questions about social interactions between two people. In Experiment 1, participants infer that two people are in a social relationship when there is a sequence of altruistic interactions between them, and specifically infer an asymmetric relationship when one person always performs the altruistic action, and a symmetric relationship when the two people alternate performing the altruistic action. In Experiment 2, participants equally expect alternating and repeating altruistic actions when the relationship is symmetric, but expect repeating actions (following a precedent) when the relationship is asymmetric. Our results suggest that people are able to use knowledge of relationships to generate shared expectations for coordinating on recurrent altruistic social interactions, and vice versa."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:WHdLCjDvYFkC",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/f4spk/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:DRh9vcRO8j0J:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "No evidence for familiarity preferences after partial exposure to visual concepts in preschoolers and infants",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Gal Raz and Anjie Cao and Minh Khong Bui and Michael C Frank and Rebecca Saxe",
            "publisher": "PsyArXiv",
            "abstract": "From birth, humans make decisions about what to look at and for how long. A classic framework proposes encoding as a key driver of looking behavior in development-in early stages of encoding, infants and young children prefer to engage with familiar stimuli, while at later stages of encoding they prefer novel stimuli. Though this framework is often invoked when interpreting looking time studies, it is rarely validated empirically. Here, we test these predictions by explicitly manipulating exposure durations within-subjects. While we found robust evidence for habituation and novelty preferences, limiting exposure to visual concepts did not result in familiarity preferences in any age group. Our findings suggest that limited exposure does not generically lead to familiarity preferences, and that interpretations of observed familiarity preferences should be made with care. We argue for the development of formal frameworks which link the learning problem faced by participants to their attentional preferences."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:wKETBy42zhYC",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/sfb4z/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:RSBw0WSRq_kJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Domain-specific and domain-general neural responses to surprising psychological and physical events",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Shari Liu and Kirsten Lydic and Lingjie Mei and Rebecca Saxe",
            "publisher": "PsyArXiv",
            "abstract": "Why do babies look longer when they see an object pass through a solid wall, or a person act inefficiently, during violation-of-expectation (VOE) studies? Here we test two non-mutually exclusive hypotheses:(i) VOE involves domain-general processes, like visual prediction error, and curiosity about the source of surprise.(ii) VOE involves domain-specific processes, like prediction error over distinctively physical and psychological expectations (objects fall; agents behave rationally). In a pre-registered experiment, we scanned 32 adults using functional magnetic resonance imaging (fMRI) while they watched videos of agents and objects, adapted from infant behavioral research. Early visual regions responded equally to surprising and expected events in both domains, providing evidence against domain-general visual prediction error. Some multiple demand regions, that are engaged when people deploy goal-directed attention, responded more to surprising events from both domains, providing evidence for domain-general endogenous attention. Domain-specific regions, that prefer stimuli involving agents vs objects more broadly, showed similar preferences for the current videos of agents and objects. One region implicated in physical reasoning responded selectively to unexpected events from the physical domain, providing evidence for domain-specific physical prediction error. Thus, in adult brains, both domain-specific and high-level domain-general regions encode violation-of-expectation involving agents and objects, paving the way towards future developmental work."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:1taIhTC69MYC",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/54x6b/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:S9CACGlxqycJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Study 1-Joint inference of wrongness and legitimacy by observing punishment decisions",
            "pub_year": 2023,
            "citation": "OSF, 2023",
            "author": "Setayesh Radkani and Rebecca Saxe",
            "publisher": "OSF"
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:AXkvAH5U_nMC",
        "num_citations": 0,
        "pub_url": "https://osf.io/nhmcy/resources",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "No evidence for familiarity preferences after limited exposure to visual concepts in preschoolers and infants",
            "pub_year": 2023,
            "citation": "Proceedings of the Annual Meeting of the Cognitive Science Society 45 (45), 2023",
            "author": "Gal Raz and Anjie Cao and Minh Khong Bui and Michael C Frank and Rebecca Saxe",
            "journal": "Proceedings of the Annual Meeting of the Cognitive Science Society",
            "volume": "45",
            "number": "45",
            "abstract": "From birth, humans make decisions about what to look at and for how long. A classic framework proposes encoding as a key driver of looking behavior in development - in early stages of encoding, infants and young children prefer to engage with familiar stimuli, while at later stages of encoding they prefer novel stimuli. Though this framework is often invoked when interpreting looking time studies, it is rarely validated empirically. Here, we test these predictions by explicitly manipulating exposure durations within-subjects. While we found robust evidence for habituation and novelty preferences, limiting exposure to visual concepts did not result in familiarity preferences in any age group. Our findings suggest that limited exposure does not generically lead to familiarity preferences, and that interpretations of observed familiarity preferences should be made with care. We argue for the development of formal frameworks which link the learning problem faced by participants to their attentional preferences."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:L1USKYWJimsC",
        "num_citations": 0,
        "pub_url": "https://escholarship.org/uc/item/5f38t3cd",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Violations of physical and psychological expectations in the human adult brain",
            "pub_year": 2023,
            "citation": "Proceedings of the Annual Meeting of the Cognitive Science Society 45 (45), 2023",
            "author": "Shari Liu and Kirsten Lydic and Lingjie Mei and Rebecca Saxe",
            "journal": "Proceedings of the Annual Meeting of the Cognitive Science Society",
            "volume": "45",
            "number": "45",
            "abstract": "When adults see one solid object pass through another, or see a person take the long route to a destination when a shortcut was available, we classify those events as surprising. Infants look infants look longer at the same unexpected outcomes, compared with visually similar but expected outcomes, in violation-of-expectation (VOE) experiments. What domain-specific and domain-general cognitive processes support these judgments? In a pre-registered experiment, we scanned 32 adults using functional magnetic resonance imaging (fMRI) while they watched videos designed for infant research. One region implicated in physical reasoning responded selectively to unexpected physical events, providing evidence for domain-specific physical prediction error. Multiple demand regions responded more to unexpected events regardless of domain, providing evidence for domain-general goal-directed attention. Early visual regions responded equally to unexpected and expected events, providing evidence against stimulus-driven prediction error. Thus, in adults, VOE involves domain-specific, and high-level, domain-general computations."
        },
        "filled": true,
        "author_pub_id": "Tv-zquoAAAAJ:jU7OWUQzBzMC",
        "num_citations": 0,
        "pub_url": "https://escholarship.org/uc/item/0gd2j3g8",
        "cites_per_year": {}
    }
]