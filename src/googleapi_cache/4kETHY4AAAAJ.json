[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "LLMs are not ready for editorial work",
            "pub_year": 2023,
            "citation": "Nature Human Behaviour, 1-2, 2023",
            "author": "Grace W Lindsay",
            "journal": "Nature Human Behaviour",
            "pages": "1-2",
            "publisher": "Nature Publishing Group UK",
            "abstract": "Large language models are capable of impressive feats, but the job of scientific review requires more than the statistics of published work can provide."
        },
        "filled": true,
        "author_pub_id": "4kETHY4AAAAJ:dhFuZR0502QC",
        "num_citations": 0,
        "pub_url": "https://www.nature.com/articles/s41562-023-01730-6",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Grounding Neuroscience in Behavioral Changes using Artificial Neural Networks",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2311.07526, 2023",
            "author": "Grace W Lindsay",
            "journal": "arXiv preprint arXiv:2311.07526",
            "abstract": "Connecting neural activity to function is a common aim in neuroscience. How to define and conceptualize function, however, can vary. Here I focus on grounding this goal in the specific question of how a given change in behavior is produced by a change in neural circuits or activity. Artificial neural network models offer a particularly fruitful format for tackling such questions because they use neural mechanisms to perform complex transformations and produce appropriate behavior. Therefore, they can be a means of causally testing the extent to which a neural change can be responsible for an experimentally observed behavioral change. Furthermore, because the field of interpretability in artificial intelligence has similar aims, neuroscientists can look to interpretability methods for new ways of identifying neural features that drive performance and behaviors."
        },
        "filled": true,
        "author_pub_id": "4kETHY4AAAAJ:QIV2ME_5wuYC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2311.07526",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The neuroconnectionist research programme",
            "pub_year": 2023,
            "citation": "Nature Reviews Neuroscience, 1-20, 2023",
            "author": "Adrien Doerig and Rowan P Sommers and Katja Seeliger and Blake Richards and Jenann Ismael and Grace W Lindsay and Konrad P Kording and Talia Konkle and Marcel AJ Van Gerven and Nikolaus Kriegeskorte and Tim C Kietzmann",
            "pages": "1-20",
            "publisher": "Nature Publishing Group UK",
            "abstract": "Artificial neural networks (ANNs) inspired by biology are beginning to be widely used to model behavioural and neural data, an approach we call \u2018neuroconnectionism\u2019. ANNs have been not only lauded as the current best models of information processing in the brain but also criticized for failing to account for basic cognitive functions. In this Perspective article, we propose that arguing about the successes and failures of a restricted set of current ANNs is the wrong approach to assess the promise of neuroconnectionism for brain science. Instead, we take inspiration from the philosophy of science, and in particular from Lakatos, who showed that the core of a scientific research programme is often not directly falsifiable but should be assessed by its capacity to generate novel insights. Following this view, we present neuroconnectionism as a general research programme centred around ANNs as a computational \u2026"
        },
        "filled": true,
        "author_pub_id": "4kETHY4AAAAJ:M3ejUd6NZC8C",
        "num_citations": 27,
        "citedby_url": "/scholar?hl=en&cites=3334113232536501466",
        "cites_id": [
            "3334113232536501466"
        ],
        "pub_url": "https://www.nature.com/articles/s41583-023-00705-w",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:2nxE8lEmRS4J:scholar.google.com/",
        "cites_per_year": {
            "2022": 5,
            "2023": 22
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Consciousness in artificial intelligence: Insights from the science of consciousness",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2308.08708, 2023",
            "author": "Patrick Butlin and Robert Long and Eric Elmoznino and Yoshua Bengio and Jonathan Birch and Axel Constant and George Deane and Stephen M Fleming and Chris Frith and Xu Ji and Ryota Kanai and Colin Klein and Grace Lindsay and Matthias Michel and Liad Mudrik and Megan AK Peters and Eric Schwitzgebel and Jonathan Simon and Rufin VanRullen",
            "journal": "arXiv preprint arXiv:2308.08708",
            "abstract": "Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive \"indicator properties\" of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators."
        },
        "filled": true,
        "author_pub_id": "4kETHY4AAAAJ:mVmsd5A6BfQC",
        "num_citations": 13,
        "citedby_url": "/scholar?hl=en&cites=8239061011717183910",
        "cites_id": [
            "8239061011717183910"
        ],
        "pub_url": "https://arxiv.org/abs/2308.08708",
        "cites_per_year": {
            "2023": 12
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Testing methods of neural systems understanding",
            "pub_year": 2023,
            "citation": "Cognitive Systems Research 82, 101156, 2023",
            "author": "Grace W Lindsay and David Bau",
            "journal": "Cognitive Systems Research",
            "volume": "82",
            "pages": "101156",
            "publisher": "Elsevier",
            "abstract": "Neuroscientists apply a range of analysis tools to recorded neural activity in order to glean insights into how neural circuits drive behavior in organisms. Despite the fact that these tools shape the progress of the field as a whole, we have little empirical proof that they are effective at identifying the mechanisms of interest. At the same time, deep learning systems are trained to produce intelligent behavior using neural networks, and the resulting models are impressive but also largely impenetrable. Can the tools of neuroscience be applied to artificial neural networks (ANNs) and if so what would this process tell us about ANNs, brains, and \u2013 most importantly \u2013 the tools themselves? Here we argue that applying analysis methods from neuroscience to ANNs will provide a much-needed test of the abilities of these tools. It would also encourage the development of a unified field of neural systems understanding, which can \u2026"
        },
        "filled": true,
        "author_pub_id": "4kETHY4AAAAJ:Wp0gIr-vW9MC",
        "num_citations": 0,
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S1389041723000906",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Invited Session III: Neural network models of the visual system: Exploring the function of different forms of visual recurrence with artificial neural networks",
            "pub_year": 2023,
            "citation": "Journal of vision 23 (11), 16-16, 2023",
            "author": "Grace Lindsay",
            "journal": "Journal of vision",
            "volume": "23",
            "number": "11",
            "pages": "16-16",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Behavioral studies suggest that recurrence in the visual system is important for processing degraded stimuli. There are two broad anatomical forms this recurrence can take, lateral or feedback, each with different assumed functions. I'll discuss work wherein I add four different kinds of recurrence\u2014two of each anatomical form\u2014to a feedforward convolutional neural network and find all forms capable of increasing the ability of the network to classify noisy digit images. By using several analysis tools frequently applied to neural data, the distinct strategies used by different networks were identified. The analyses used here can be applied to real neural recordings to identify the strategies at play in the brain. An analysis of an fMRI dataset weakly supports the predictive feedback model but points to a need for higher-resolution cross-regional data to understand recurrent visual processing."
        },
        "filled": true,
        "author_pub_id": "4kETHY4AAAAJ:9ZlFYXVOiuMC",
        "num_citations": 0,
        "pub_url": "https://iovs.arvojournals.org/article.aspx?articleid=2792850",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Deep neural networks are not a single hypothesis but a language for expressing computational hypotheses",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Tal Golan and JohnMark Taylor and Heiko Sch\u00fctt and Benjamin Peters and Rowan Paolo Sommers and Katja Seeliger and Adrien Doerig and Paul Linton and Talia Konkle and Marcel van Gerven and Konrad Kording and Blake Richards and Tim Christian Kietzmann and Grace W Lindsay and Nikolaus Kriegeskorte",
            "publisher": "PsyArXiv",
            "abstract": "An ideal vision model accounts for behavior and neurophysiology in both naturalistic conditions and designed lab experiments. Unlike psychological theories, artificial neural networks (ANNs) actually perform visual tasks and generate testable predictions for arbitrary inputs. These advantages enable ANNs to engage the entire spectrum of the evidence. Failures of particular models drive progress in a vibrant ANN research program of human vision."
        },
        "filled": true,
        "author_pub_id": "4kETHY4AAAAJ:aqlVkmm33-oC",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/tr7gx/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:1VpvSvB-icIJ:scholar.google.com/",
        "cites_per_year": {}
    }
]