[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The neuroconnectionist research programme",
            "pub_year": 2023,
            "citation": "Nature Reviews Neuroscience, 1-20, 2023",
            "author": "Adrien Doerig and Rowan P Sommers and Katja Seeliger and Blake Richards and Jenann Ismael and Grace W Lindsay and Konrad P Kording and Talia Konkle and Marcel AJ Van Gerven and Nikolaus Kriegeskorte and Tim C Kietzmann",
            "pages": "1-20",
            "publisher": "Nature Publishing Group UK",
            "abstract": "Artificial neural networks (ANNs) inspired by biology are beginning to be widely used to model behavioural and neural data, an approach we call \u2018neuroconnectionism\u2019. ANNs have been not only lauded as the current best models of information processing in the brain but also criticized for failing to account for basic cognitive functions. In this Perspective article, we propose that arguing about the successes and failures of a restricted set of current ANNs is the wrong approach to assess the promise of neuroconnectionism for brain science. Instead, we take inspiration from the philosophy of science, and in particular from Lakatos, who showed that the core of a scientific research programme is often not directly falsifiable but should be assessed by its capacity to generate novel insights. Following this view, we present neuroconnectionism as a general research programme centred around ANNs as a computational \u2026"
        },
        "filled": true,
        "author_pub_id": "4kETHY4AAAAJ:M3ejUd6NZC8C",
        "num_citations": 18,
        "citedby_url": "/scholar?hl=en&cites=3334113232536501466",
        "cites_id": [
            "3334113232536501466"
        ],
        "pub_url": "https://www.nature.com/articles/s41583-023-00705-w",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:2nxE8lEmRS4J:scholar.google.com/",
        "cites_per_year": {
            "2022": 3,
            "2023": 15
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Consciousness in artificial intelligence: Insights from the Science of consciousness",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2308.08708, 2023",
            "author": "Patrick Butlin and Robert Long and Eric Elmoznino and Yoshua Bengio and Jonathan Birch and Axel Constant and George Deane and Stephen M Fleming and Chris Frith and Xu Ji and Ryota Kanai and Colin Klein and Grace Lindsay and Matthias Michel and Liad Mudrik and Megan AK Peters and Eric Schwitzgebel and Jonathan Simon and Rufin VanRullen",
            "journal": "arXiv preprint arXiv:2308.08708",
            "abstract": "Whether current or near-term AI systems could be conscious is a topic of scientific interest and increasing public concern. This report argues for, and exemplifies, a rigorous and empirically grounded approach to AI consciousness: assessing existing AI systems in detail, in light of our best-supported neuroscientific theories of consciousness. We survey several prominent scientific theories of consciousness, including recurrent processing theory, global workspace theory, higher-order theories, predictive processing, and attention schema theory. From these theories we derive \"indicator properties\" of consciousness, elucidated in computational terms that allow us to assess AI systems for these properties. We use these indicator properties to assess several recent AI systems, and we discuss how future systems might implement them. Our analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators."
        },
        "filled": true,
        "author_pub_id": "4kETHY4AAAAJ:mVmsd5A6BfQC",
        "num_citations": 6,
        "citedby_url": "/scholar?hl=en&cites=8239061011717183910",
        "cites_id": [
            "8239061011717183910"
        ],
        "pub_url": "https://arxiv.org/abs/2308.08708",
        "cites_per_year": {
            "2023": 6
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Testing methods of neural systems understanding",
            "pub_year": 2023,
            "citation": "Cognitive Systems Research 82, 101156, 2023",
            "author": "Grace W Lindsay and David Bau",
            "journal": "Cognitive Systems Research",
            "volume": "82",
            "pages": "101156",
            "publisher": "Elsevier",
            "abstract": "Neuroscientists apply a range of analysis tools to recorded neural activity in order to glean insights into how neural circuits drive behavior in organisms. Despite the fact that these tools shape the progress of the field as a whole, we have little empirical proof that they are effective at identifying the mechanisms of interest. At the same time, deep learning systems are trained to produce intelligent behavior using neural networks, and the resulting models are impressive but also largely impenetrable. Can the tools of neuroscience be applied to artificial neural networks (ANNs) and if so what would this process tell us about ANNs, brains, and \u2013 most importantly \u2013 the tools themselves? Here we argue that applying analysis methods from neuroscience to ANNs will provide a much-needed test of the abilities of these tools. It would also encourage the development of a unified field of neural systems understanding, which can \u2026"
        },
        "filled": true,
        "author_pub_id": "4kETHY4AAAAJ:Wp0gIr-vW9MC",
        "num_citations": 0,
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S1389041723000906",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Deep neural networks are not a single hypothesis but a language for expressing computational hypotheses",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Tal Golan and JohnMark Taylor and Heiko Sch\u00fctt and Benjamin Peters and Rowan Paolo Sommers and Katja Seeliger and Adrien Doerig and Paul Linton and Talia Konkle and Marcel van Gerven and Konrad Kording and Blake Richards and Tim Christian Kietzmann and Grace W Lindsay and Nikolaus Kriegeskorte",
            "publisher": "PsyArXiv",
            "abstract": "An ideal vision model accounts for behavior and neurophysiology in both naturalistic conditions and designed lab experiments. Unlike psychological theories, artificial neural networks (ANNs) actually perform visual tasks and generate testable predictions for arbitrary inputs. These advantages enable ANNs to engage the entire spectrum of the evidence. Failures of particular models drive progress in a vibrant ANN research program of human vision."
        },
        "filled": true,
        "author_pub_id": "4kETHY4AAAAJ:aqlVkmm33-oC",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/tr7gx/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:1VpvSvB-icIJ:scholar.google.com/",
        "cites_per_year": {}
    }
]