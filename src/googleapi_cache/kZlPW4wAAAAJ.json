[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Don't Lie to Me! Robust and Efficient Explainability with Verified Perturbation Analysis",
            "pub_year": 2023,
            "citation": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern \u2026, 2023",
            "author": "Thomas Fel and M\u00e9lanie Ducoffe and David Vigouroux and R\u00e9mi Cad\u00e8ne and Mikael Capelle and Claire Nicod\u00e8me and Thomas Serre",
            "conference": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "pages": "16153-16163",
            "abstract": "A variety of methods have been proposed to try to explain how deep neural networks make their decisions. Key to those approaches is the need to sample the pixel space efficiently in order to derive importance maps. However, it has been shown that the sampling methods used to date introduce biases and other artifacts, leading to inaccurate estimates of the importance of individual pixels and severely limit the reliability of current explainability methods. Unfortunately, the alternative--to exhaustively sample the image space is computationally prohibitive. In this paper, we introduce EVA (Explaining using Verified perturbation Analysis)--the first explainability method guarantee to have an exhaustive exploration of a perturbation space. Specifically, we leverage the beneficial properties of verified perturbation analysis--time efficiency, tractability and guaranteed complete coverage of a manifold--to efficiently characterize the input variables that are most likely to drive the model decision. We evaluate the approach systematically and demonstrate state-of-the-art results on multiple benchmarks."
        },
        "filled": true,
        "author_pub_id": "kZlPW4wAAAAJ:4tNoA7Af41QC",
        "num_citations": 15,
        "citedby_url": "/scholar?hl=en&cites=149153390913869137",
        "cites_id": [
            "149153390913869137"
        ],
        "pub_url": "https://openaccess.thecvf.com/content/CVPR2023/html/Fel_Dont_Lie_to_Me_Robust_and_Efficient_Explainability_With_Verified_CVPR_2023_paper.html",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:UVV3AjjmEQIJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 9,
            "2023": 6
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Craft: Concept recursive activation factorization for explainability",
            "pub_year": 2023,
            "citation": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern \u2026, 2023",
            "author": "Thomas Fel and Agustin Picard and Louis Bethune and Thibaut Boissin and David Vigouroux and Julien Colin and R\u00e9mi Cad\u00e8ne and Thomas Serre",
            "conference": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition",
            "pages": "2711-2721",
            "abstract": "Attribution methods are a popular class of explainability methods that use heatmaps to depict the most important areas of an image that drive a model decision. Nevertheless, recent work has shown that these methods have limited utility in practice, presumably because they only highlight the most salient parts of an image (ie,\" where\" the model looked) and do not communicate any information about\" what\" the model saw at those locations. In this work, we try to fill in this gap with Craft--a novel approach to identify both\" what\" and\" where\" by generating concept-based explanations. We introduce 3 new ingredients to the automatic concept extraction literature:(i) a recursive strategy to detect and decompose concepts across layers,(ii) a novel method for a more faithful estimation of concept importance using Sobol indices, and (iii) the use of implicit differentiation to unlock Concept Attribution Maps. We conduct both human and computer vision experiments to demonstrate the benefits of the proposed approach. We show that our recursive decomposition generates meaningful and accurate concepts and that the proposed concept importance estimation technique is more faithful to the model than previous methods. When evaluating the usefulness of the method for human experimenters on the utility benchmark, we find that our approach significantly improves on two of the three test scenarios (while none of the current methods including ours help on the third). Overall, our study suggests that, while much work remains toward the development of general explainability methods that are useful in practical scenarios, the identification of meaningful \u2026"
        },
        "filled": true,
        "author_pub_id": "kZlPW4wAAAAJ:6IBXqrN-DEwC",
        "num_citations": 8,
        "citedby_url": "/scholar?hl=en&cites=13339911549550342907",
        "cites_id": [
            "13339911549550342907"
        ],
        "pub_url": "http://openaccess.thecvf.com/content/CVPR2023/html/Fel_CRAFT_Concept_Recursive_Activation_FacTorization_for_Explainability_CVPR_2023_paper.html",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:-zIUXuDiILkJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 8
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Break it down: evidence for structural compositionality in neural networks",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2301.10884, 2023",
            "author": "Michael A Lepori and Thomas Serre and Ellie Pavlick",
            "journal": "arXiv preprint arXiv:2301.10884",
            "abstract": "Many tasks can be described as compositions over subroutines. Though modern neural networks have achieved impressive performance on both vision and language tasks, we know little about the functions that they implement. One possibility is that neural networks implicitly break down complex tasks into subroutines, implement modular solutions to these subroutines, and compose them into an overall solution to a task -- a property we term structural compositionality. Or they may simply learn to match new inputs to memorized representations, eliding task decomposition entirely. Here, we leverage model pruning techniques to investigate this question in both vision and language, across a variety of architectures, tasks, and pretraining regimens. Our results demonstrate that models oftentimes implement solutions to subroutines via modular subnetworks, which can be ablated while maintaining the functionality of other subroutines. This suggests that neural networks may be able to learn to exhibit compositionality, obviating the need for specialized symbolic mechanisms."
        },
        "filled": true,
        "author_pub_id": "kZlPW4wAAAAJ:fF_gHTpLxhAC",
        "num_citations": 4,
        "citedby_url": "/scholar?hl=en&cites=7816230005853409920",
        "cites_id": [
            "7816230005853409920"
        ],
        "pub_url": "https://arxiv.org/abs/2301.10884",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:gFKkNcfTeGwJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 4
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Diffusion Models as Artists: Are we Closing the Gap between Humans and Machines?",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2301.11722, 2023",
            "author": "Victor Boutin and Thomas Fel and Lakshya Singhal and Rishav Mukherji and Akash Nagaraj and Julien Colin and Thomas Serre",
            "journal": "arXiv preprint arXiv:2301.11722",
            "abstract": "An important milestone for AI is the development of algorithms that can produce drawings that are indistinguishable from those of humans. Here, we adapt the 'diversity vs. recognizability' scoring framework from Boutin et al, 2022 and find that one-shot diffusion models have indeed started to close the gap between humans and machines. However, using a finer-grained measure of the originality of individual samples, we show that strengthening the guidance of diffusion models helps improve the humanness of their drawings, but they still fall short of approximating the originality and recognizability of human drawings. Comparing human category diagnostic features, collected through an online psychophysics experiment, against those derived from diffusion models reveals that humans rely on fewer and more localized features. Overall, our study suggests that diffusion models have significantly helped improve the quality of machine-generated drawings; however, a gap between humans and machines remains -- in part explainable by discrepancies in visual strategies."
        },
        "filled": true,
        "author_pub_id": "kZlPW4wAAAAJ:_n8fIOMweQoC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=16712152635231374832",
        "cites_id": [
            "16712152635231374832"
        ],
        "pub_url": "https://arxiv.org/abs/2301.11722",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:8A0T50Z-7ecJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Diagnosing and exploiting the computational demands of videos games for deep reinforcement learning",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2309.13181, 2023",
            "author": "Lakshmi Narasimhan Govindarajan and Rex G Liu and Drew Linsley and Alekh Karkada Ashok and Max Reuter and Michael J Frank and Thomas Serre",
            "journal": "arXiv preprint arXiv:2309.13181",
            "abstract": "Humans learn by interacting with their environments and perceiving the outcomes of their actions. A landmark in artificial intelligence has been the development of deep reinforcement learning (dRL) algorithms capable of doing the same in video games, on par with or better than humans. However, it remains unclear whether the successes of dRL models reflect advances in visual representation learning, the effectiveness of reinforcement learning algorithms at discovering better policies, or both. To address this question, we introduce the Learning Challenge Diagnosticator (LCD), a tool that separately measures the perceptual and reinforcement learning demands of a task. We use LCD to discover a novel taxonomy of challenges in the Procgen benchmark, and demonstrate that these predictions are both highly reliable and can instruct algorithmic development. More broadly, the LCD reveals multiple failure cases that can occur when optimizing dRL algorithms over entire video game benchmarks like Procgen, and provides a pathway towards more efficient progress."
        },
        "filled": true,
        "author_pub_id": "kZlPW4wAAAAJ:-fu4zM_6qcIC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2309.13181",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:w2ZoiGzreZgJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Cerebrospinal fluid transcripts may predict shunt surgery responses in normal pressure hydrocephalus",
            "pub_year": 2023,
            "citation": "Brain, awad109, 2023",
            "author": "Zachary Levin and Owen P Leary and Victor Mora and Shawn Kant and Sarah Brown and Konstantina Svokos and Umer Akbar and Thomas Serre and Petra Klinge and Alexander Fleischmann and Maria Grazia Ruocco",
            "journal": "Brain",
            "pages": "awad109",
            "publisher": "Oxford University Press",
            "abstract": "Molecular biomarkers for neurodegenerative diseases are critical for advancing diagnosis and therapy. Normal pressure hydrocephalus (NPH) is a neurological disorder characterized by progressive neurodegeneration, gait impairment, urinary incontinence and cognitive decline. In contrast to most other neurodegenerative disorders, NPH symptoms can be improved by the placement of a ventricular shunt that drains excess CSF. A major challenge in NPH management is the identification of patients who benefit from shunt surgery. Here, we perform genome-wide RNA sequencing of extracellular vesicles in CSF of 42 NPH patients, and we identify genes and pathways whose expression levels correlate with gait, urinary or cognitive symptom improvement after shunt surgery. We describe a machine learning algorithm trained on these gene expression profiles to predict shunt surgery response with high \u2026"
        },
        "filled": true,
        "author_pub_id": "kZlPW4wAAAAJ:JIEWM9yDoCIC",
        "num_citations": 0,
        "pub_url": "https://academic.oup.com/brain/advance-article-abstract/doi/10.1093/brain/awad109/7174209",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:0Wkt4GLd0l4J:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Learning Functional Transduction",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2302.00328, 2023",
            "author": "Mathieu Chalvidal and Thomas Serre and Rufin VanRullen",
            "journal": "arXiv preprint arXiv:2302.00328",
            "abstract": "Research in Machine Learning has polarized into two general regression approaches: Transductive methods derive estimates directly from available data but are usually problem unspecific. Inductive methods can be much more particular, but generally require tuning and compute-intensive searches for solutions. In this work, we adopt a hybrid approach: We leverage the theory of Reproducing Kernel Banach Spaces (RKBS) and show that transductive principles can be induced through gradient descent to form efficient \\textit{in-context} neural approximators. We apply this approach to RKBS of function-valued operators and show that once trained, our \\textit{Transducer} model can capture on-the-fly relationships between infinite-dimensional input and output functions, given a few example pairs, and return new function estimates. We demonstrate the benefit of our transductive approach to model complex physical systems influenced by varying external factors with little data at a fraction of the usual deep learning training computation cost for partial differential equations and climate modeling applications."
        },
        "filled": true,
        "author_pub_id": "kZlPW4wAAAAJ:f2PrUAIjnKUC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2302.00328",
        "cites_per_year": {}
    }
]