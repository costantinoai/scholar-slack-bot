[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Deep neural networks as scientific models",
            "pub_year": 2019,
            "citation": "Trends in cognitive sciences 23 (4), 305-317, 2019",
            "author": "Radoslaw M Cichy and Daniel Kaiser",
            "volume": "23",
            "number": "4",
            "pages": "305-317",
            "publisher": "Elsevier",
            "abstract": "Artificial deep neural networks (DNNs) initially inspired by the brain enable computers to solve cognitive tasks at which humans excel. In the absence of explanations for such cognitive phenomena, in turn cognitive scientists have started using DNNs as models to investigate biological cognition and its neural basis, creating heated debate. Here, we reflect on the case from the perspective of philosophy of science. After putting DNNs as scientific models into context, we discuss how DNNs can fruitfully contribute to cognitive science. We claim that beyond their power to provide predictions and explanations of cognitive phenomena, DNNs have the potential to contribute to an often overlooked but ubiquitous and fundamental use of scientific models: exploration."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:738O_yMBCRsC",
        "num_citations": 311,
        "citedby_url": "/scholar?hl=en&cites=18156980676787796567",
        "cites_id": [
            "18156980676787796567"
        ],
        "pub_url": "https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19)30034-8",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:V3qRybmN-vsJ:scholar.google.com/",
        "cites_per_year": {
            "2019": 18,
            "2020": 61,
            "2021": 80,
            "2022": 74,
            "2023": 75
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Disentangling representations of object shape and object category in human visual cortex: The animate\u2013inanimate distinction",
            "pub_year": 2016,
            "citation": "Journal of cognitive neuroscience 28 (5), 680-692, 2016",
            "author": "Daria Proklova* and Daniel Kaiser* and Marius V Peelen",
            "journal": "Journal of cognitive neuroscience",
            "volume": "28",
            "number": "5",
            "pages": "680-692",
            "publisher": "MIT Press",
            "abstract": "Objects belonging to different categories evoke reliably different fMRI activity patterns in human occipitotemporal cortex, with the most prominent distinction being that between animate and inanimate objects. An unresolved question is whether these categorical distinctions reflect category-associated visual properties of objects or whether they genuinely reflect object category. Here, we addressed this question by measuring fMRI responses to animate and inanimate objects that were closely matched for shape and low-level visual features. Univariate contrasts revealed animate- and inanimate-preferring regions in ventral and lateral temporal cortex even for individually matched object pairs (e.g., snake\u2013rope). Using representational similarity analysis, we mapped out brain regions in which the pairwise dissimilarity of multivoxel activity patterns (neural dissimilarity) was predicted by the objects' pairwise visual \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:GnPB-g6toBAC",
        "num_citations": 133,
        "citedby_url": "/scholar?hl=en&cites=13178746971693455715",
        "cites_id": [
            "13178746971693455715"
        ],
        "pub_url": "https://direct.mit.edu/jocn/article-abstract/28/5/680/28488",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:YxmL-ItQ5LYJ:scholar.google.com/",
        "cites_per_year": {
            "2016": 1,
            "2017": 17,
            "2018": 15,
            "2019": 25,
            "2020": 23,
            "2021": 13,
            "2022": 21,
            "2023": 16
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Object vision in a structured world",
            "pub_year": 2019,
            "citation": "Trends in cognitive sciences 23 (8), 672-685, 2019",
            "author": "Daniel Kaiser and Genevieve L Quek and Radoslaw M Cichy and Marius V Peelen",
            "volume": "23",
            "number": "8",
            "pages": "672-685",
            "publisher": "Elsevier",
            "abstract": "In natural vision, objects appear at typical locations, both with respect to visual space (e.g., an airplane in the upper part of a scene) and other objects (e.g., a lamp above a table). Recent studies have shown that object vision is strongly adapted to such positional regularities. In this review we synthesize these developments, highlighting that adaptations to positional regularities facilitate object detection and recognition, and sharpen the representations of objects in visual cortex. These effects are pervasive across various types of high-level content. We posit that adaptations to real-world structure collectively support optimal usage of limited cortical processing resources. Taking positional regularities into account will thus be essential for understanding efficient object vision in the real world."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:08ZZubdj9fEC",
        "num_citations": 105,
        "citedby_url": "/scholar?hl=en&cites=13013355733010523926",
        "cites_id": [
            "13013355733010523926"
        ],
        "pub_url": "https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(19)30105-6",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:FqfiaRe6mLQJ:scholar.google.com/",
        "cites_per_year": {
            "2019": 1,
            "2020": 23,
            "2021": 24,
            "2022": 30,
            "2023": 27
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Repetition probability does not affect fMRI repetition suppression for objects",
            "pub_year": 2013,
            "citation": "Journal of Neuroscience 33 (23), 9805-9812, 2013",
            "author": "Gyula Kov\u00e1cs and Daniel Kaiser and Dzmitry A Kaliukhovich and Zolt\u00e1n Vidny\u00e1nszky and Rufin Vogels",
            "journal": "Journal of Neuroscience",
            "volume": "33",
            "number": "23",
            "pages": "9805-9812",
            "publisher": "Society for Neuroscience",
            "abstract": "Previously several functional magnetic resonance imaging (fMRI) studies point toward the role of perceptual expectations in determining adaptation or repetition suppression (RS) in humans. These studies showed that the probability of repetitions of faces within a block influences the magnitude of adaptation in face-related areas of the human brain . However, a current macaque single-cell/local field potential (LFP) recording study using objects as stimuli found no evidence for the modulation of the neural response by the repetition probability in the inferior temporal cortex . Here we examined whether stimulus repetition probability affects fMRI repetition suppression for nonface object stimuli in the human brain. Subjects were exposed to either two identical [repetition trials (RTs)] or two different [alternation trials (ATs)] object stimuli. Both types of trials were presented blocks consisting of either 75% [repetition blocks \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:ns9cj8rnVeAC",
        "num_citations": 90,
        "citedby_url": "/scholar?hl=en&cites=4239982254782921689",
        "cites_id": [
            "4239982254782921689"
        ],
        "pub_url": "https://www.jneurosci.org/content/33/23/9805.short",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:2btLdmVx1zoJ:scholar.google.com/",
        "cites_per_year": {
            "2013": 2,
            "2014": 8,
            "2015": 5,
            "2016": 12,
            "2017": 11,
            "2018": 14,
            "2019": 6,
            "2020": 10,
            "2021": 12,
            "2022": 5,
            "2023": 5
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Object grouping based on real-world regularities facilitates perception by reducing competitive interactions in visual cortex",
            "pub_year": 2014,
            "citation": "Proceedings of the National Academy of Sciences 111 (30), 11217-11222, 2014",
            "author": "Daniel Kaiser and Timo Stein and Marius V Peelen",
            "journal": "Proceedings of the National Academy of Sciences",
            "volume": "111",
            "number": "30",
            "pages": "11217-11222",
            "publisher": "National Academy of Sciences",
            "abstract": "In virtually every real-life situation humans are confronted with complex and cluttered visual environments that contain a multitude of objects. Because of the limited capacity of the visual system, objects compete for neural representation and cognitive processing resources. Previous work has shown that such attentional competition is partly object based, such that competition among elements is reduced when these elements perceptually group into an object based on low-level cues. Here, using functional MRI (fMRI) and behavioral measures, we show that the attentional benefit of grouping extends to higher-level grouping based on the relative position of objects as experienced in the real world. An fMRI study designed to measure competitive interactions among objects in human visual cortex revealed reduced neural competition between objects when these were presented in commonly experienced \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:blknAaTinKkC",
        "num_citations": 89,
        "citedby_url": "/scholar?hl=en&cites=824751488311005479",
        "cites_id": [
            "824751488311005479"
        ],
        "pub_url": "https://www.pnas.org/doi/abs/10.1073/pnas.1400559111",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:J5HA4BsbcgsJ:scholar.google.com/",
        "cites_per_year": {
            "2015": 7,
            "2016": 2,
            "2017": 6,
            "2018": 11,
            "2019": 14,
            "2020": 13,
            "2021": 11,
            "2022": 14,
            "2023": 10
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Reward guides attention to object categories in real-world scenes.",
            "pub_year": 2015,
            "citation": "Journal of Experimental Psychology: General 144 (2), 264, 2015",
            "author": "Clayton Hickey and Daniel Kaiser and Marius V Peelen",
            "journal": "Journal of Experimental Psychology: General",
            "volume": "144",
            "number": "2",
            "pages": "264",
            "publisher": "American Psychological Association",
            "abstract": "Reward is thought to motivate animal-approach behavior in part by automatically facilitating the perceptual processing of reward-associated visual stimuli. Studies have demonstrated this effect for low-level visual features such as color and orientation. However, outside of the laboratory, it is rare that low-level features uniquely characterize objects relevant for behavior. Here, we test whether reward can prime representations at the level of object category. Participants detected category exemplars (cars, trees, people) in briefly presented photographs of real-world scenes. On a subset of trials, successful target detection was rewarded and the effect of this reward was measured on the subsequent trial. Results show that rewarded selection of a category exemplar caused other members of this category to become visually salient, disrupting search when subsequently presented as distractors. It is important to note that \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:M3NEmzRMIkIC",
        "num_citations": 87,
        "citedby_url": "/scholar?hl=en&cites=10408541488046297428",
        "cites_id": [
            "10408541488046297428"
        ],
        "pub_url": "https://psycnet.apa.org/record/2015-00009-001",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:VFHqKFaRcpAJ:scholar.google.com/",
        "cites_per_year": {
            "2014": 1,
            "2015": 5,
            "2016": 9,
            "2017": 12,
            "2018": 14,
            "2019": 8,
            "2020": 14,
            "2021": 9,
            "2022": 6,
            "2023": 9
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Shape-independent object category responses revealed by MEG and fMRI decoding",
            "pub_year": 2016,
            "citation": "Journal of Neurophysiology, 2016",
            "author": "Daniel Kaiser* and Damiano C Azzalini* and Marius V Peelen",
            "journal": "Journal of Neurophysiology",
            "publisher": "The American Physiological Society",
            "abstract": "Neuroimaging research has identified category-specific neural response patterns to a limited set of object categories. For example, faces, bodies, and scenes evoke activity patterns in visual cortex that are uniquely traceable in space and time. It is currently debated whether these apparently categorical responses truly reflect selectivity for categories or instead reflect selectivity for category-associated shape properties. In the present study, we used a cross-classification approach on functional MRI (fMRI) and magnetoencephalographic (MEG) data to reveal both category-independent shape responses and shape-independent category responses. Participants viewed human body parts (hands and torsos) and pieces of clothing that were closely shape-matched to the body parts (gloves and shirts). Category-independent shape responses were revealed by training multivariate classifiers on discriminating shape within \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:hMod-77fHWUC",
        "num_citations": 80,
        "citedby_url": "/scholar?hl=en&cites=14158762962106434176",
        "cites_id": [
            "14158762962106434176"
        ],
        "pub_url": "https://journals.physiology.org/doi/abs/10.1152/jn.01074.2015",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:gMJPz-UHfsQJ:scholar.google.com/",
        "cites_per_year": {
            "2016": 3,
            "2017": 14,
            "2018": 12,
            "2019": 16,
            "2020": 11,
            "2021": 3,
            "2022": 8,
            "2023": 13
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The neural dynamics of attentional selection in natural scenes",
            "pub_year": 2016,
            "citation": "Journal of neuroscience 36 (41), 10522-10528, 2016",
            "author": "Daniel Kaiser and Nikolaas N Oosterhof and Marius V Peelen",
            "journal": "Journal of neuroscience",
            "volume": "36",
            "number": "41",
            "pages": "10522-10528",
            "publisher": "Society for Neuroscience",
            "abstract": "The human visual system can only represent a small subset of the many objects present in cluttered scenes at any given time, such that objects compete for representation. Despite these processing limitations, the detection of object categories in cluttered natural scenes is remarkably rapid. How does the brain efficiently select goal-relevant objects from cluttered scenes? In the present study, we used multivariate decoding of magneto-encephalography (MEG) data to track the neural representation of within-scene objects as a function of top-down attentional set. Participants detected categorical targets (cars or people) in natural scenes. The presence of these categories within a scene was decoded from MEG sensor patterns by training linear classifiers on differentiating cars and people in isolation and testing these classifiers on scenes containing one of the two categories. The presence of a specific category in a \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:BqipwSGYUEgC",
        "num_citations": 79,
        "citedby_url": "/scholar?hl=en&cites=9145428195489379311",
        "cites_id": [
            "9145428195489379311"
        ],
        "pub_url": "https://www.jneurosci.org/content/36/41/10522.short",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:73P8Pn0W634J:scholar.google.com/",
        "cites_per_year": {
            "2016": 1,
            "2017": 7,
            "2018": 11,
            "2019": 13,
            "2020": 11,
            "2021": 8,
            "2022": 14,
            "2023": 13
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Testing promotes long-term learning via stabilizing activation patterns in a large network of brain areas",
            "pub_year": 2014,
            "citation": "Cerebral Cortex 24 (11), 3025-3035, 2014",
            "author": "Attila Keresztes and Daniel Kaiser and Gyula Kov\u00e1cs and Mih\u00e1ly Racsm\u00e1ny",
            "journal": "Cerebral Cortex",
            "volume": "24",
            "number": "11",
            "pages": "3025-3035",
            "publisher": "Oxford University Press",
            "abstract": "The testing effect refers to the phenomenon that repeated retrieval of memories promotes better long-term retention than repeated study. To investigate the neural correlates of the testing effect, we used event-related functional magnetic resonance imaging methods while participants performed a cued recall task. Prior to the neuroimaging experiment, participants learned Swahili\u2013German word pairs, then half of the word pairs were repeatedly studied, whereas the other half were repeatedly tested. For half of the participants, the neuroimaging experiment was performed immediately after the learning phase; a 1-week retention interval was inserted for the other half of the participants. We found that a large network of areas identified in a separate 2-back functional localizer scan were active during the final recall of the word pair associations. Importantly, the learning strategy (retest or restudy) of the word pairs \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:NaGl4SEjCO4C",
        "num_citations": 75,
        "citedby_url": "/scholar?hl=en&cites=10473296164672278590",
        "cites_id": [
            "10473296164672278590"
        ],
        "pub_url": "https://academic.oup.com/cercor/article-abstract/24/11/3025/303489",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:PpDAMl-fWJEJ:scholar.google.com/",
        "cites_per_year": {
            "2014": 6,
            "2015": 11,
            "2016": 6,
            "2017": 4,
            "2018": 10,
            "2019": 6,
            "2020": 5,
            "2021": 10,
            "2022": 10,
            "2023": 6
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Visual imagery and perception share neural representations in the alpha frequency band",
            "pub_year": 2020,
            "citation": "Current Biology 30 (13), 2621-2627. e5, 2020",
            "author": "Siying Xie and Daniel Kaiser and Radoslaw M Cichy",
            "journal": "Current Biology",
            "volume": "30",
            "number": "13",
            "pages": "2621-2627. e5",
            "publisher": "Elsevier",
            "abstract": "To behave adaptively with sufficient flexibility, biological organisms must cognize beyond immediate reaction to a physically present stimulus. For this, humans use visual mental imagery [1, 2], the ability to conjure up a vivid internal experience from memory that stands in for the percept of the stimulus. Visually imagined contents subjectively mimic perceived contents, suggesting that imagery and perception share common neural mechanisms. Using multivariate pattern analysis on human electroencephalography (EEG) data, we compared the oscillatory time courses of mental imagery and perception of objects. We found that representations shared between imagery and perception emerged specifically in the alpha frequency band. These representations were present in posterior, but not anterior, electrodes, suggesting an origin in parieto-occipital cortex. Comparison of the shared representations to computational \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:kRWSkSYxWN8C",
        "num_citations": 73,
        "citedby_url": "/scholar?hl=en&cites=4685725829357247280",
        "cites_id": [
            "4685725829357247280"
        ],
        "pub_url": "https://www.cell.com/current-biology/pdf/S0960-9822(20)30590-X.pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:MBu21dAKB0EJ:scholar.google.com/",
        "cites_per_year": {
            "2020": 7,
            "2021": 15,
            "2022": 24,
            "2023": 27
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Can working memory be non-conscious?",
            "pub_year": 2016,
            "citation": "Neuroscience of Consciousness 2016 (1), niv011, 2016",
            "author": "Timo Stein and Daniel Kaiser and Guido Hesselmann",
            "journal": "Neuroscience of Consciousness",
            "volume": "2016",
            "number": "1",
            "pages": "niv011",
            "publisher": "Oxford University Press",
            "abstract": "Working memory (WM) is closely linked to conscious awareness: In most conceptions of WM, the inputs to WM need to be conscious. The findings of some recent studies, however, have been taken to suggest that WM can indeed operate on non-conscious inputs. Here, we argue that these findings can easily be accommodated by conventional conceptions of non-conscious perception and conscious WM. We conclude that these studies do not provide conclusive evidence for non-conscious WM. It is thus too early to dismiss the traditional view of a tight link between WM and conscious awareness."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:RYcK_YlVTxYC",
        "num_citations": 51,
        "citedby_url": "/scholar?hl=en&cites=982536953359385562",
        "cites_id": [
            "982536953359385562"
        ],
        "pub_url": "https://academic.oup.com/nc/article-abstract/2016/1/niv011/2472543",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:2kOuQyesog0J:scholar.google.com/",
        "cites_per_year": {
            "2016": 6,
            "2017": 8,
            "2018": 9,
            "2019": 10,
            "2020": 4,
            "2021": 5,
            "2022": 6,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Real-world spatial regularities affect visual working memory for objects",
            "pub_year": 2015,
            "citation": "Psychonomic Bulletin & Review 22, 1784-1790, 2015",
            "author": "Daniel Kaiser and Timo Stein and Marius V Peelen",
            "journal": "Psychonomic Bulletin & Review",
            "volume": "22",
            "pages": "1784-1790",
            "publisher": "Springer US",
            "abstract": "Traditional memory research has focused on measuring and modeling the capacity of visual working memory for simple stimuli such as geometric shapes or colored disks. Although these studies have provided important insights, it is unclear how their findings apply to memory for more naturalistic stimuli. An important aspect of real-world scenes is that they contain a high degree of regularity: For instance, lamps appear above tables, not below them. In the present study, we tested whether such real-world spatial regularities affect working memory capacity for individual objects. Using a delayed change-detection task with concurrent verbal suppression, we found enhanced visual working memory performance for objects positioned according to real-world regularities, as compared to irregularly positioned objects. This effect was specific to upright stimuli, indicating that it did not reflect low-level grouping \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:YFjsv_pBGBYC",
        "num_citations": 47,
        "citedby_url": "/scholar?hl=en&cites=16830345809965415005",
        "cites_id": [
            "16830345809965415005"
        ],
        "pub_url": "https://link.springer.com/article/10.3758/s13423-015-0833-4",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Xfr42VdmkekJ:scholar.google.com/",
        "cites_per_year": {
            "2015": 2,
            "2016": 2,
            "2017": 3,
            "2018": 8,
            "2019": 2,
            "2020": 6,
            "2021": 8,
            "2022": 8,
            "2023": 8
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Whole person-evoked fMRI activity patterns in human fusiform gyrus are accurately modeled by a linear combination of face-and body-evoked activity patterns",
            "pub_year": 2013,
            "citation": "Journal of Neurophysiology, 2013",
            "author": "Daniel Kaiser* and Lukas Strnad* and Katharina N Seidl and Sabine Kastner and Marius V Peelen",
            "journal": "Journal of Neurophysiology",
            "publisher": "The American Physiological Society",
            "abstract": "Visual cues from the face and the body provide information about another's identity, emotional state, and intentions. Previous neuroimaging studies that investigated neural responses to (bodiless) faces and (headless) bodies have reported overlapping face- and body-selective brain regions in right fusiform gyrus (FG). In daily life, however, faces and bodies are typically perceived together and are effortlessly integrated into the percept of a whole person, raising the possibility that neural responses to whole persons are qualitatively different than responses to isolated faces and bodies. The present study used fMRI to examine how FG activity in response to a whole person relates to activity in response to the same face and body but presented in isolation. Using multivoxel pattern analysis, we modeled person-evoked response patterns in right FG through a linear combination of face- and body-evoked response \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:JV2RwH3_ST0C",
        "num_citations": 46,
        "citedby_url": "/scholar?hl=en&cites=8962355581567826568",
        "cites_id": [
            "8962355581567826568"
        ],
        "pub_url": "https://journals.physiology.org/doi/abs/10.1152/jn.00371.2013",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:iPoWtuquYHwJ:scholar.google.com/",
        "cites_per_year": {
            "2014": 3,
            "2015": 7,
            "2016": 5,
            "2017": 3,
            "2018": 5,
            "2019": 4,
            "2020": 8,
            "2021": 1,
            "2022": 6,
            "2023": 4
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Neural correlates of priming and adaptation in familiar face perception",
            "pub_year": 2013,
            "citation": "Cortex 49 (7), 1963-1977, 2013",
            "author": "Christian Walther and Stefan R Schweinberger and Daniel Kaiser and Gyula Kov\u00e1cs",
            "journal": "Cortex",
            "volume": "49",
            "number": "7",
            "pages": "1963-1977",
            "publisher": "Elsevier",
            "abstract": "Priming (PR) and adaptation-related aftereffects (AEs) are two phenomena when recent perceptual experiences alter face perception. While AEs are often reflected in contrastive perceptual biases, PR typically leads to behavioural facilitation. Previous research suggests that both phenomena modulate broadly similar components of the event-related potentials (ERPs). To disentangle the underlying neural mechanisms of PR and AE, we induced both effects within the same subjects and paradigm. We presented pairs of stimuli, where the first (S1) was a famous face (identity A, B or C), a morph between two famous faces (50/50% A/B), or a Fourier phase randomized face (as a control stimulus matched for low-level visual information) and the second (S2) was a face drawn from morph continua between identity A and B. Participants' performance in matching S2s to either A or B revealed contrastive aftereffects for \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:RGFaLdJalmkC",
        "num_citations": 43,
        "citedby_url": "/scholar?hl=en&cites=1993656258517841163",
        "cites_id": [
            "1993656258517841163"
        ],
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S0010945212002535",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:C7Uw5c3jqhsJ:scholar.google.com/",
        "cites_per_year": {
            "2012": 1,
            "2013": 3,
            "2014": 5,
            "2015": 5,
            "2016": 4,
            "2017": 6,
            "2018": 4,
            "2019": 1,
            "2020": 4,
            "2021": 4,
            "2022": 3,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "MEG sensor patterns reflect perceptual but not categorical similarity of animate and inanimate objects",
            "pub_year": 2019,
            "citation": "NeuroImage 193, 167-177, 2019",
            "author": "Daria Proklova and Daniel Kaiser and Marius V Peelen",
            "journal": "NeuroImage",
            "volume": "193",
            "pages": "167-177",
            "publisher": "Academic Press",
            "abstract": "Human high-level visual cortex shows a distinction between animate and inanimate objects, as revealed by fMRI. Recent studies have shown that object animacy can similarly be decoded from MEG sensor patterns. Which object properties drive this decoding? Here, we disentangled the influence of perceptual and categorical object properties by presenting perceptually matched objects (e.g., snake and rope) that were nonetheless easily recognizable as being animate or inanimate. In a series of behavioral experiments, three aspects of perceptual dissimilarity of these objects were quantified: overall dissimilarity, outline dissimilarity, and texture dissimilarity. Neural dissimilarity of MEG sensor patterns was modeled using regression analysis, in which perceptual dissimilarity (from the behavioral experiments) and categorical dissimilarity served as predictors of neural dissimilarity. We found that perceptual \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:cFHS6HbyZ2cC",
        "num_citations": 40,
        "citedby_url": "/scholar?hl=en&cites=3812084624542888185",
        "cites_id": [
            "3812084624542888185"
        ],
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S1053811919302058",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:-XCby8Q-5zQJ:scholar.google.com/",
        "cites_per_year": {
            "2018": 3,
            "2019": 7,
            "2020": 8,
            "2021": 4,
            "2022": 10,
            "2023": 7
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Interobject grouping facilitates visual awareness",
            "pub_year": 2015,
            "citation": "Journal of Vision 15 (8), 10-10, 2015",
            "author": "Timo Stein and Daniel Kaiser and Marius V Peelen",
            "journal": "Journal of Vision",
            "volume": "15",
            "number": "8",
            "pages": "10-10",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "In organizing perception, the human visual system takes advantage of regularities in the visual input to perceptually group related image elements. Simple stimuli that can be perceptually grouped based on physical regularities, for example by forming an illusory contour, have a competitive advantage in entering visual awareness. Here, we show that regularities that arise from the relative positioning of complex, meaningful objects in the visual environment also modulate visual awareness. Using continuous flash suppression, we found that pairs of objects that were positioned according to real-world spatial regularities (eg, a lamp above a table) accessed awareness more quickly than the same object pairs shown in irregular configurations (eg, a table above a lamp). This advantage was specific to upright stimuli and abolished by stimulus inversion, meaning that it did not reflect physical stimulus confounds or the grouping of simple image elements. Thus, knowledge of the spatial configuration of objects in the environment shapes the contents of conscious perception."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:NMxIlDl6LWMC",
        "num_citations": 38,
        "citedby_url": "/scholar?hl=en&cites=5728071268516586142",
        "cites_id": [
            "5728071268516586142"
        ],
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2337697",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:nmINWHgyfk8J:scholar.google.com/",
        "cites_per_year": {
            "2015": 1,
            "2016": 4,
            "2017": 3,
            "2018": 8,
            "2019": 5,
            "2020": 3,
            "2021": 3,
            "2022": 6,
            "2023": 5
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Transformation from independent to integrative coding of multi-object arrangements in human visual cortex",
            "pub_year": 2018,
            "citation": "Neuroimage 169, 334-341, 2018",
            "author": "Daniel Kaiser and Marius V Peelen",
            "journal": "Neuroimage",
            "volume": "169",
            "pages": "334-341",
            "publisher": "Academic Press",
            "abstract": "To optimize processing, the human visual system utilizes regularities present in naturalistic visual input. One of these regularities is the relative position of objects in a scene (e.g., a sofa in front of a television), with behavioral research showing that regularly positioned objects are easier to perceive and to remember. Here we use fMRI to test how positional regularities are encoded in the visual system. Participants viewed pairs of objects that formed minimalistic two-object scenes (e.g., a \u201cliving room\u201d consisting of a sofa and television) presented in their regularly experienced spatial arrangement or in an irregular arrangement (with interchanged positions). Additionally, single objects were presented centrally and in isolation. Multi-voxel activity patterns evoked by the object pairs were modeled as the average of the response patterns evoked by the two single objects forming the pair. In two experiments, this \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:g5m5HwL7SMYC",
        "num_citations": 37,
        "citedby_url": "/scholar?hl=en&cites=14883347239752642215",
        "cites_id": [
            "14883347239752642215"
        ],
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S1053811917310893",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:py4_jnVFjM4J:scholar.google.com/",
        "cites_per_year": {
            "2018": 2,
            "2019": 4,
            "2020": 11,
            "2021": 3,
            "2022": 10,
            "2023": 7
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The neural dynamics of familiar face recognition",
            "pub_year": 2018,
            "citation": "Cerebral Cortex, 2018",
            "author": "G\u00e9za Gergely Ambrus* and Daniel Kaiser* and Radoslaw Cichy and Gyula Kov\u00e1cs",
            "journal": "Cerebral Cortex",
            "abstract": "In real-life situations, the appearance of a person\u2019s face can vary substantially across different encounters, making face recognition a challenging task for the visual system. Recent fMRI decoding studies have suggested that face recognition is supported by identity representations located in regions of the occipitotemporal cortex. Here, we used EEG to elucidate the temporal emergence of these representations. Human participants viewed a set of highly variable face images of 4 highly familiar celebrities (2 males and 2 females), while performing an orthogonal task. Univariate analyses of event-related EEG responses revealed a pronounced differentiation between male and female faces, but not between identities of the same sex. Using multivariate representational similarity analysis, we observed a gradual emergence of face identity representations, with an increasing degree of invariance. Face identity \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:OU6Ihb5iCvQC",
        "num_citations": 33,
        "citedby_url": "/scholar?hl=en&cites=15063499433035574472",
        "cites_id": [
            "15063499433035574472"
        ],
        "pub_url": "https://academic.oup.com/cercor/article-abstract/29/11/4775/5308440",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:yCxirOxMDNEJ:scholar.google.com/",
        "cites_per_year": {
            "2019": 1,
            "2020": 6,
            "2021": 7,
            "2022": 12,
            "2023": 7
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The human visual system differentially represents subjectively and objectively invisible stimuli",
            "pub_year": 2021,
            "citation": "PLoS biology 19 (5), e3001241, 2021",
            "author": "Timo Stein and Daniel Kaiser and Johannes J Fahrenfort and Simon Van Gaal",
            "journal": "PLoS biology",
            "volume": "19",
            "number": "5",
            "pages": "e3001241",
            "publisher": "Public Library of Science",
            "abstract": "The study of unconscious processing requires a measure of conscious awareness. Awareness measures can be either subjective (based on participant\u2019s report) or objective (based on perceptual performance). The preferred awareness measure depends on the theoretical position about consciousness and may influence conclusions about the extent of unconscious processing and about the neural correlates of consciousness. We obtained functional magnetic resonance imaging (fMRI) measurements from 43 subjects while they viewed masked faces and houses that were either subjectively or objectively invisible. Even for objectively invisible (perceptually indiscriminable) stimuli, we found significant category information in both early, lower-level visual areas and in higher-level visual cortex, although representations in anterior, category-selective ventrotemporal areas were less robust. For subjectively invisible stimuli, similar to visible stimuli, there was a clear posterior-to-anterior gradient in visual cortex, with stronger category information in ventrotemporal cortex than in early visual cortex. For objectively invisible stimuli, however, category information remained virtually unchanged from early visual cortex to object- and category-selective visual areas. These results demonstrate that although both objectively and subjectively invisible stimuli are represented in visual cortex, the extent of unconscious information processing is influenced by the measurement approach. Furthermore, our data show that subjective and objective approaches are associated with different neural correlates of consciousness and thus have implications for neural theories \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:olpn-zPbct0C",
        "num_citations": 28,
        "citedby_url": "/scholar?hl=en&cites=11779423642698309495,7242209840682451505",
        "cites_id": [
            "11779423642698309495",
            "7242209840682451505"
        ],
        "pub_url": "https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3001241",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:d9_emWTreKMJ:scholar.google.com/",
        "cites_per_year": {
            "2021": 4,
            "2022": 13,
            "2023": 10
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Getting to know you: emerging neural representations during face familiarization",
            "pub_year": 2021,
            "citation": "Journal of Neuroscience 41 (26), 5687-5698, 2021",
            "author": "G\u00e9za Gergely Ambrus and Charlotta Marina Eick and Daniel Kaiser and Gyula Kov\u00e1cs",
            "journal": "Journal of Neuroscience",
            "volume": "41",
            "number": "26",
            "pages": "5687-5698",
            "publisher": "Society for Neuroscience",
            "abstract": "The successful recognition of familiar persons is critical for social interactions. Despite extensive research on the neural representations of familiar faces, we know little about how such representations unfold as someone becomes familiar. In three EEG experiments on human participants of both sexes, we elucidated how representations of face familiarity and identity emerge from different qualities of familiarization: brief perceptual exposure (Experiment 1), extensive media familiarization (Experiment 2), and real-life personal familiarization (Experiment 3). Time-resolved representational similarity analysis revealed that familiarization quality has a profound impact on representations of face familiarity: they were strongly visible after personal familiarization, weaker after media familiarization, and absent after perceptual familiarization. Across all experiments, we found no enhancement of face identity representation \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:t6usbXjVLHcC",
        "num_citations": 27,
        "citedby_url": "/scholar?hl=en&cites=11776471233653766186",
        "cites_id": [
            "11776471233653766186"
        ],
        "pub_url": "https://www.jneurosci.org/content/41/26/5687?utm_source=TrendMD&utm_medium=cpc&utm_campaign=JNeurosci_TrendMD_0",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:KviJTTFubqMJ:scholar.google.com/",
        "cites_per_year": {
            "2021": 2,
            "2022": 9,
            "2023": 16
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The time course of spatial attention during naturalistic visual search",
            "pub_year": 2020,
            "citation": "Cortex 122, 225-234, 2020",
            "author": "Elisa Battistoni and Daniel Kaiser and Clayton Hickey and Marius V Peelen",
            "journal": "Cortex",
            "volume": "122",
            "pages": "225-234",
            "publisher": "Elsevier",
            "abstract": "In daily life, attention is often directed to high-level object attributes, such as when we look out for cars before crossing a road. Previous work used MEG decoding to investigate the influence of such category-based attention on the time course of object category representations. Attended object categories were more strongly represented than unattended categories from 180 msec after scene onset. In the present study, we used a similar approach to determine when attention is spatially focused on the target. Participants completed two tasks. In the first, they detected cars and people at varying locations in photographs of real-world scenes. In the second, they detected a cross that appeared at salient locations in an array of lines. Multivariate classifiers were trained on data of the artificial salience experiment and tested on data of the naturalistic visual search experiment. Results showed that the location of both target \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:dshw04ExmUIC",
        "num_citations": 24,
        "citedby_url": "/scholar?hl=en&cites=14950073354416423335,214112090681416597",
        "cites_id": [
            "14950073354416423335",
            "214112090681416597"
        ],
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S0010945218303976",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:pwEGyIFUec8J:scholar.google.com/",
        "cites_per_year": {
            "2018": 1,
            "2019": 4,
            "2020": 3,
            "2021": 2,
            "2022": 7,
            "2023": 6
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Typical visual-field locations enhance processing in object-selective channels of human occipital cortex",
            "pub_year": 2018,
            "citation": "Journal of Neurophysiology 120 (2), 848-853, 2018",
            "author": "Daniel Kaiser and Radoslaw M Cichy",
            "journal": "Journal of Neurophysiology",
            "volume": "120",
            "number": "2",
            "pages": "848-853",
            "publisher": "American Physiological Society",
            "abstract": "Natural environments consist of multiple objects, many of which repeatedly occupy similar locations within a scene. For example, hats are seen on people\u2019s heads, while shoes are most often seen close to the ground. Such positional regularities bias the distribution of objects across the visual field: hats are more often encountered in the upper visual field, while shoes are more often encountered in the lower visual field. Here we tested the hypothesis that typical visual field locations of objects facilitate cortical processing. We recorded functional MRI while participants viewed images of objects that were associated with upper or lower visual field locations. Using multivariate classification, we show that object information can be more successfully decoded from response patterns in object-selective lateral occipital cortex (LO) when the objects are presented in their typical location (e.g., shoe in the lower visual field \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:bFI3QPDXJZMC",
        "num_citations": 23,
        "citedby_url": "/scholar?hl=en&cites=2487283850852377143",
        "cites_id": [
            "2487283850852377143"
        ],
        "pub_url": "https://journals.physiology.org/doi/abs/10.1152/jn.00229.2018",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:NyKf8XubhCIJ:scholar.google.com/",
        "cites_per_year": {
            "2018": 2,
            "2019": 2,
            "2020": 7,
            "2021": 4,
            "2022": 3,
            "2023": 5
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Dissociating the neural bases of repetition-priming and adaptation in the human brain for faces",
            "pub_year": 2013,
            "citation": "Journal of Neurophysiology, 2013",
            "author": "Daniel Kaiser and Christian Walther and Stefan R Schweinberger and Gyula Kov\u00e1cs",
            "journal": "Journal of Neurophysiology",
            "publisher": "The American Physiological Society",
            "abstract": "The repetition of a given stimulus leads to the attenuation of the functional magnetic resonance imaging (fMRI) signal compared with unrepeated stimuli, a phenomenon called fMRI adaptation or repetition suppression (RS). Previous studies have related RS of the fMRI signal behaviorally both to improved performance for the repeated stimulus (priming) and to shifts of perception away from the first stimulus (adaptation-related aftereffects). Here we used identical task (sex discrimination), trial structure [stimulus 1 (S1): 3,000 ms, interstimulus interval: 600 ms, stimulus 2 (S2): 300 ms], and S2 stimuli (androgynous faces) to test how RS of the face-specific areas of the occipito-temporal cortex relates to priming and aftereffects. By varying S1, we could induce priming (significantly faster reaction times when S1 and S2 were identical compared with different images) as well as sex-specific aftereffect [an increased ratio of \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:J_g5lzvAfSwC",
        "num_citations": 22,
        "citedby_url": "/scholar?hl=en&cites=14530054317938476542",
        "cites_id": [
            "14530054317938476542"
        ],
        "pub_url": "https://journals.physiology.org/doi/abs/10.1152/jn.00277.2013",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:_oXaK2sfpckJ:scholar.google.com/",
        "cites_per_year": {
            "2015": 2,
            "2016": 2,
            "2017": 3,
            "2018": 0,
            "2019": 1,
            "2020": 3,
            "2021": 9,
            "2022": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Cortical sensitivity to natural scene structure",
            "pub_year": 2020,
            "citation": "Human Brain Mapping 41 (5), 1286-1295, 2020",
            "author": "Daniel Kaiser and Greta H\u00e4berle and Radoslaw M Cichy",
            "journal": "Human Brain Mapping",
            "volume": "41",
            "number": "5",
            "pages": "1286-1295",
            "publisher": "John Wiley & Sons, Inc.",
            "abstract": "Natural scenes are inherently structured, with meaningful objects appearing in predictable locations. Human vision is tuned to this structure: When scene structure is purposefully jumbled, perception is strongly impaired. Here, we tested how such perceptual effects are reflected in neural sensitivity to scene structure. During separate fMRI and EEG experiments, participants passively viewed scenes whose spatial structure (i.e., the position of scene parts) and categorical structure (i.e., the content of scene parts) could be intact or jumbled. Using multivariate decoding, we show that spatial (but not categorical) scene structure profoundly impacts on cortical processing: Scene\u2010selective responses in occipital and parahippocampal cortices (fMRI) and after 255\u2009ms (EEG) accurately differentiated between spatially intact and jumbled scenes. Importantly, this differentiation was more pronounced for upright than for inverted \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:l7t_Zn2s7bgC",
        "num_citations": 21,
        "citedby_url": "/scholar?hl=en&cites=15908522428626025429",
        "cites_id": [
            "15908522428626025429"
        ],
        "pub_url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.24875",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:1buWo9xsxtwJ:scholar.google.com/",
        "cites_per_year": {
            "2019": 1,
            "2020": 3,
            "2021": 5,
            "2022": 5,
            "2023": 6
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Typical retinotopic locations impact the time course of object coding",
            "pub_year": 2018,
            "citation": "NeuroImage 176, 372-379, 2018",
            "author": "Daniel Kaiser and Merle M Moeskops and Radoslaw M Cichy",
            "journal": "NeuroImage",
            "volume": "176",
            "pages": "372-379",
            "publisher": "Academic Press",
            "abstract": "In everyday visual environments, objects are non-uniformly distributed across visual space. Many objects preferentially occupy particular retinotopic locations: for example, lamps more often fall into the upper visual field, whereas carpets more often fall into the lower visual field. The long-term experience with natural environments prompts the hypothesis that the visual system is tuned to such retinotopic object locations. A key prediction is that typically positioned objects should be coded more efficiently. To test this prediction, we recorded electroencephalography (EEG) while participants viewed briefly presented objects appearing in their typical locations (e.g., an airplane in the upper visual field) or in atypical locations (e.g., an airplane in the lower visual field). Multivariate pattern analysis applied to the EEG data revealed that object classification depended on positional regularities: Objects were classified more \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:ZHo1McVdvXMC",
        "num_citations": 18,
        "citedby_url": "/scholar?hl=en&cites=4588144135261884117,16078731340041637476",
        "cites_id": [
            "4588144135261884117",
            "16078731340041637476"
        ],
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S105381191830404X",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:1Y6TMMhcrD8J:scholar.google.com/",
        "cites_per_year": {
            "2018": 4,
            "2019": 2,
            "2020": 5,
            "2021": 4,
            "2022": 0,
            "2023": 3
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Typical visual-field locations facilitate access to awareness for everyday objects",
            "pub_year": 2018,
            "citation": "Cognition 180, 118-122, 2018",
            "author": "Daniel Kaiser and Radoslaw M Cichy",
            "journal": "Cognition",
            "volume": "180",
            "pages": "118-122",
            "publisher": "Elsevier",
            "abstract": "In real-world vision, humans are constantly confronted with complex environments that contain a multitude of objects. These environments are spatially structured, so that objects have different likelihoods of appearing in specific parts of the visual space. Our massive experience with such positional regularities prompts the hypothesis that the processing of individual objects varies in efficiency across the visual field: when objects are encountered in their typical locations (e.g., we are used to seeing lamps in the upper visual field and carpets in the lower visual field), they should be more efficiently perceived than when they are encountered in atypical locations (e.g., a lamp in the lower visual field and a carpet in the upper visual field). Here, we provide evidence for this hypothesis by showing that typical positioning facilitates an object\u2019s access to awareness. In two continuous flash suppression experiments, objects \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:nb7KW1ujOQ8C",
        "num_citations": 13,
        "citedby_url": "/scholar?hl=en&cites=15845719733598236670",
        "cites_id": [
            "15845719733598236670"
        ],
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S0010027718301926",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:_i-FuyRO59sJ:scholar.google.com/",
        "cites_per_year": {
            "2018": 2,
            "2019": 1,
            "2020": 5,
            "2021": 2,
            "2022": 0,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "A neural mechanism for contextualizing fragmented inputs during naturalistic vision",
            "pub_year": 2019,
            "citation": "elife 8, e48182, 2019",
            "author": "Daniel Kaiser and Jacopo Turini and Radoslaw M Cichy",
            "journal": "elife",
            "volume": "8",
            "pages": "e48182",
            "publisher": "eLife Sciences Publications, Ltd",
            "abstract": "With every glimpse of our eyes, we sample only a small and incomplete fragment of the visual world, which needs to be contextualized and integrated into a coherent scene representation. Here we show that the visual system achieves this contextualization by exploiting spatial schemata, that is our knowledge about the composition of natural scenes. We measured fMRI and EEG responses to incomplete scene fragments and used representational similarity analysis to reconstruct their cortical representations in space and time. We observed a sorting of representations according to the fragments' place within the scene schema, which occurred during perceptual analysis in the occipital place area and within the first 200 ms of vision. This schema-based coding operates flexibly across visual features (as measured by a deep neural network model) and different types of environments (indoor and outdoor scenes). This flexibility highlights the mechanism's ability to efficiently organize incoming information under dynamic real-world conditions."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:VOx2b1Wkg3QC",
        "num_citations": 12,
        "citedby_url": "/scholar?hl=en&cites=5072324643983864746",
        "cites_id": [
            "5072324643983864746"
        ],
        "pub_url": "https://elifesciences.org/articles/48182",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:qjMermOEZEYJ:scholar.google.com/",
        "cites_per_year": {
            "2020": 3,
            "2021": 3,
            "2022": 4,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Perceived and mentally rotated contents are differentially represented in cortical depth of V1",
            "pub_year": 2021,
            "citation": "Communications Biology 4 (1), 1069, 2021",
            "author": "Polina Iamshchinina and Daniel Kaiser and Renat Yakupov and Daniel Haenelt and Alessandro Sciarra and Hendrik Mattern and Falk Luesebrink and Emrah Duezel and Oliver Speck",
            "journal": "Communications Biology",
            "volume": "4",
            "number": "1",
            "pages": "1069",
            "abstract": "Primary visual cortex (V1) in humans is known to represent both veridically perceived external input and internally-generated contents underlying imagery and mental rotation. However, it is unknown how the brain keeps these contents separate thus avoiding a mixture of the perceived and the imagined which could lead to potentially detrimental consequences. Inspired by neuroanatomical studies showing that feedforward and feedback connections in V1 terminate in different cortical layers, we hypothesized that this anatomical compartmentalization underlies functional segregation of external and internally-generated visual contents, respectively. We used high-resolution layer-specific fMRI to test this hypothesis in a mental rotation task. We found that rotated contents were predominant at outer cortical depth bins (i.e. superficial and deep). At the same time perceived contents were represented stronger at the \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:2KloaMYe4IUC",
        "num_citations": 9,
        "citedby_url": "/scholar?hl=en&cites=4613622708909845575",
        "cites_id": [
            "4613622708909845575"
        ],
        "pub_url": "https://www.nature.com/articles/s42003-021-02582-4",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Ryw_5GjhBkAJ:scholar.google.com/",
        "cites_per_year": {
            "2021": 1,
            "2022": 2,
            "2023": 6
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Rapid contextualization of fragmented scene information in the human visual system",
            "pub_year": 2020,
            "citation": "Neuroimage 219, 117045, 2020",
            "author": "Daniel Kaiser and Gabriele Inciuraite and Radoslaw M Cichy",
            "journal": "Neuroimage",
            "volume": "219",
            "pages": "117045",
            "publisher": "Academic Press",
            "abstract": "Real-world environments are extremely rich in visual information. At any given moment in time, only a fraction of this information is available to the eyes and the brain, rendering naturalistic vision a collection of incomplete snapshots. Previous research suggests that in order to successfully contextualize this fragmented information, the visual system sorts inputs according to spatial schemata, that is knowledge about the typical composition of the visual world. Here, we used a large set of 840 different natural scene fragments to investigate whether this sorting mechanism can operate across the diverse visual environments encountered during real-world vision. We recorded brain activity using electroencephalography (EEG) while participants viewed incomplete scene fragments at fixation. Using representational similarity analysis on the EEG data, we tracked the fragments\u2019 cortical representations across time. We \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:eflP2zaiRacC",
        "num_citations": 9,
        "citedby_url": "/scholar?hl=en&cites=2466696580261215065",
        "cites_id": [
            "2466696580261215065"
        ],
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S1053811920305310",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Wfsje3h3OyIJ:scholar.google.com/",
        "cites_per_year": {
            "2020": 1,
            "2021": 2,
            "2022": 3,
            "2023": 3
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Real-world structure facilitates the rapid emergence of scene category information in visual brain signals",
            "pub_year": 2020,
            "citation": "Journal of Neurophysiology 124 (1), 145-151, 2020",
            "author": "Daniel Kaiser and Greta H\u00e4berle and Radoslaw M Cichy",
            "journal": "Journal of Neurophysiology",
            "volume": "124",
            "number": "1",
            "pages": "145-151",
            "publisher": "American Physiological Society",
            "abstract": "In everyday life, our visual surroundings are not arranged randomly but structured in predictable ways. Although previous studies have shown that the visual system is sensitive to such structural regularities, it remains unclear whether the presence of an intact structure in a scene also facilitates the cortical analysis of the scene\u2019s categorical content. To address this question, we conducted an EEG experiment during which participants viewed natural scene images that were either \u201cintact\u201d (with their quadrants arranged in typical positions) or \u201cjumbled\u201d (with their quadrants arranged into atypical positions). We then used multivariate pattern analysis to decode the scenes\u2019 category from the EEG signals (e.g., whether the participant had seen a church or a supermarket). The category of intact scenes could be decoded rapidly within the first 100 ms of visual processing. Critically, within 200 ms of processing, category \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:BrmTIyaxlBUC",
        "num_citations": 9,
        "citedby_url": "/scholar?hl=en&cites=11858248285085160903",
        "cites_id": [
            "11858248285085160903"
        ],
        "pub_url": "https://journals.physiology.org/doi/abs/10.1152/jn.00164.2020",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:x9Xi0vz1kKQJ:scholar.google.com/",
        "cites_per_year": {
            "2020": 1,
            "2021": 2,
            "2022": 4,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Modelling brain representations of abstract concepts",
            "pub_year": 2022,
            "citation": "PLoS Computational Biology 18 (2), e1009837, 2022",
            "author": "Daniel Kaiser and Arthur M Jacobs and Radoslaw M Cichy",
            "journal": "PLoS Computational Biology",
            "volume": "18",
            "number": "2",
            "pages": "e1009837",
            "publisher": "Public Library of Science",
            "abstract": "conceptual representations are critical for human cognition. Despite their importance, key properties of these representations remain poorly understood. Here, we used computational models of distributional semantics to predict multivariate fMRI activity patterns during the activation and contextualization of abstract concepts. We devised a task in which participants had to embed abstract nouns into a story that they developed around a given background context. We found that representations in inferior parietal cortex were predicted by concept similarities emerging in models of distributional semantics. By constructing different model families, we reveal the models\u2019 learning trajectories and delineate how abstract and concrete training materials contribute to the formation of brain-like representations. These results inform theories about the format and emergence of abstract conceptual representations in the human brain."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:HE397vMXCloC",
        "num_citations": 8,
        "citedby_url": "/scholar?hl=en&cites=15754350569095626399",
        "cites_id": [
            "15754350569095626399"
        ],
        "pub_url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009837",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:n_7qWV-yotoJ:scholar.google.com/",
        "cites_per_year": {
            "2021": 1,
            "2022": 5,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Tracking cortical representations of facial attractiveness using time-resolved representational similarity analysis",
            "pub_year": 2020,
            "citation": "Scientific reports 10 (1), 16852, 2020",
            "author": "Daniel Kaiser and Karen Nyga",
            "journal": "Scientific reports",
            "volume": "10",
            "number": "1",
            "pages": "16852",
            "publisher": "Nature Publishing Group UK",
            "abstract": "When we see a face, we rapidly form an impression of its attractiveness. Here, we investigated how rapidly representations of facial attractiveness emerge in the human brain. In an EEG experiment, participants viewed 100 face photographs and rated them for their attractiveness. Using time-resolved representational similarity analysis on the EEG data, we reveal representations of facial attractiveness after 150\u2013200 ms of cortical processing. Interestingly, we show that these representations are related to individual participants\u2019 personal attractiveness judgments, suggesting that already early perceptual representations of facial attractiveness convey idiosyncratic attractiveness preferences. Further, we show that these early representations are genuinely related to attractiveness, as they are neither explained by other high-level face attributes, such as face sex or age, nor by features extracted by an artificial deep \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:mvPsJ3kp5DgC",
        "num_citations": 8,
        "citedby_url": "/scholar?hl=en&cites=8526354824734828081",
        "cites_id": [
            "8526354824734828081"
        ],
        "pub_url": "https://www.nature.com/articles/s41598-020-74009-9",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:MeZB3YmyU3YJ:scholar.google.com/",
        "cites_per_year": {
            "2021": 1,
            "2022": 7
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Facing a regular world: How spatial object structure shapes visual processing",
            "pub_year": 2017,
            "citation": "Journal of Neuroscience 37 (8), 1965-1967, 2017",
            "author": "Daniel Kaiser and Tristan Haselhuhn",
            "journal": "Journal of Neuroscience",
            "volume": "37",
            "number": "8",
            "pages": "1965-1967",
            "publisher": "Society for Neuroscience",
            "abstract": "In everyday environments, the visual system needs to process information from many stimuli appearing at different locations across the visual field. How can the brain optimally deal with the complexity of such inputs? Visual information processing in occipitotemporal regions of the visual cortex is separated for stimuli belonging to different categories, such as faces, bodies, scenes, or words (McCandliss et al., 2003; Downing et al., 2006). Most of these regions also contain retinotopic information and thus also separate stimulus processing with respect to location (Kravitz et al., 2013). Visual object analysis can therefore be understood as comprising specialized processing channels for distinct stimulus categories and for different retinotopic locations. As a result of this organization, when multiple stimuli need to be processed at the same time and there is a large degree of overlap in the processing channels (eg, when \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:ldfaerwXgEUC",
        "num_citations": 8,
        "citedby_url": "/scholar?hl=en&cites=15915045465213857571",
        "cites_id": [
            "15915045465213857571"
        ],
        "pub_url": "https://www.jneurosci.org/content/37/8/1965?utm_source=TrendMD&utm_medium=cpc&utm_campaign=JNeurosci_TrendMD_1",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:I29DcoeZ3dwJ:scholar.google.com/",
        "cites_per_year": {
            "2018": 4,
            "2019": 0,
            "2020": 2,
            "2021": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Semantic scene-object consistency modulates N300/400 EEG components, but does not automatically facilitate object representations",
            "pub_year": 2022,
            "citation": "Cerebral Cortex, 2022",
            "author": "Lixiang Chen and Radoslaw Martin Cichy* and Daniel* Kaiser*",
            "journal": "Cerebral Cortex",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "During natural vision, objects rarely appear in isolation, but often within a semantically related scene context. Previous studies reported that semantic consistency between objects and scenes facilitates object perception and that scene-object consistency is reflected in changes in the N300 and N400 components in EEG recordings. Here, we investigate whether these N300/400 differences are indicative of changes in the cortical representation of objects. In two experiments, we recorded EEG signals, while participants viewed semantically consistent or inconsistent objects within a scene; in Experiment 1, these objects were task-irrelevant, while in Experiment 2, they were directly relevant for behavior. In both experiments, we found reliable and comparable N300/400 differences between consistent and inconsistent scene-object combinations. To probe the quality of object representations, we performed \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:tKAzc9rXhukC",
        "num_citations": 4,
        "citedby_url": "/scholar?hl=en&cites=5914276792249559342",
        "cites_id": [
            "5914276792249559342"
        ],
        "pub_url": "https://academic.oup.com/cercor/article-abstract/32/16/3553/6458593",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:LilfSWi7E1IJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 4
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Resolving the time course of visual and auditory object categorization",
            "pub_year": 2022,
            "citation": "Journal of Neurophysiology, 2022",
            "author": "Polina Iamshchinina and Agnessa Karapetian and Daniel Kaiser* and Radoslaw Martin Cichy*",
            "journal": "Journal of Neurophysiology",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Humans can effortlessly categorize objects, both when they are conveyed through visual images and spoken words. To resolve the neural correlates of object categorization, studies have so far primarily focused on the visual modality. It is therefore still unclear how the brain extracts categorical information from auditory signals. In the current study, we used EEG (n = 48) and time-resolved multivariate pattern analysis to investigate 1) the time course with which object category information emerges in the auditory modality and 2) how the representational transition from individual object identification to category representation compares between the auditory modality and the visual modality. Our results show that 1) auditory object category representations can be reliably extracted from EEG signals and 2) a similar representational transition occurs in the visual and auditory modalities, where an initial representation at \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:_Re3VWB3Y0AC",
        "num_citations": 4,
        "citedby_url": "/scholar?hl=en&cites=16307950320764007619",
        "cites_id": [
            "16307950320764007619"
        ],
        "pub_url": "https://journals.physiology.org/doi/abs/10.1152/jn.00515.2021",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:wzTb22l6UeIJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 4
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Parts and wholes in scene processing",
            "pub_year": 2021,
            "citation": "Journal of Cognitive Neuroscience 34 (1), 4-15, 2021",
            "author": "Daniel Kaiser and Radoslaw M Cichy",
            "volume": "34",
            "number": "1",
            "pages": "4-15",
            "publisher": "MIT Press",
            "abstract": "During natural vision, our brains are constantly exposed to complex, but regularly structured, environments. Real-world scenes are defined by typical part\u2013whole relationships, where the meaning of the whole scene emerges from configurations of localized information present in individual parts of the scene. Such typical part\u2013whole relationships suggest that information from individual scene parts is not processed independently, but that there are mutual influences between the parts and the whole during scene analysis. Here, we review recent research that used a straightforward, but effective approach to study such mutual influences: By dissecting scenes into multiple arbitrary pieces, these studies provide new insights into how the processing of whole scenes is shaped by their constituent parts and, conversely, how the processing of individual parts is determined by their role within the whole scene. We \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:ZfRJV9d4-WMC",
        "num_citations": 4,
        "citedby_url": "/scholar?hl=en&cites=6728410810543461899",
        "cites_id": [
            "6728410810543461899"
        ],
        "pub_url": "https://direct.mit.edu/jocn/article-abstract/34/1/4/107823",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:C1ZXyfsdYF0J:scholar.google.com/",
        "cites_per_year": {
            "2023": 4
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Spectral brain signatures of aesthetic natural perception in the \u03b1 and \u03b2 frequency bands",
            "pub_year": 2022,
            "citation": "Journal of Neurophysiology 128 (6), 1501-1505, 2022",
            "author": "Daniel Kaiser",
            "journal": "Journal of Neurophysiology",
            "volume": "128",
            "number": "6",
            "pages": "1501-1505",
            "publisher": "American Physiological Society",
            "abstract": "During our everyday lives, visual beauty is often conveyed by sustained and dynamic visual stimulation, such as when we walk through an enchanting forest or watch our pets playing. Here, I devised an MEG experiment that mimics such situations: participants viewed 8 s videos of everyday situations and rated their beauty. Using multivariate analysis, I linked aesthetic ratings to 1) sustained MEG broadband responses and 2) spectral MEG responses in the \u03b1 and \u03b2 frequency bands. These effects were not accounted for by a set of high- and low-level visual descriptors of the videos, suggesting that they are genuinely related to aesthetic perception. My findings provide the first characterization of spectral brain signatures linked to aesthetic experiences in the real world.NEW & NOTEWORTHY In the real world, aesthetic experiences arise from complex and dynamic inputs. This study shows that such aesthetic \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:35r97b3x0nAC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=10738102903470142189",
        "cites_id": [
            "10738102903470142189"
        ],
        "pub_url": "https://journals.physiology.org/doi/abs/10.1152/jn.00385.2022",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:7bLtorJnBZUJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 3
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Characterizing dynamic neural representations of scene attractiveness",
            "pub_year": 2022,
            "citation": "Journal of Cognitive Neuroscience 34 (10), 1988-1997, 2022",
            "author": "Daniel Kaiser",
            "journal": "Journal of Cognitive Neuroscience",
            "volume": "34",
            "number": "10",
            "pages": "1988-1997",
            "publisher": "MIT Press",
            "abstract": "Aesthetic experiences during natural vision are varied: They can arise from viewing scenic landscapes, interesting architecture, or attractive people. Recent research in the field of neuroaesthetics has taught us a lot about where in the brain such aesthetic experiences are represented. Much less is known about when such experiences arise during the cortical processing cascade. Particularly, the dynamic neural representation of perceived attractiveness for rich natural scenes is not well understood. Here, I present data from an EEG experiment, in which participants provided attractiveness judgments for a set of diverse natural scenes. Using multivariate pattern analysis, I demonstrate that scene attractiveness is mirrored in early brain signals that arise within 200 msec of vision, suggesting that the aesthetic appeal of scenes is first resolved during perceptual processing. In more detailed analyses, I show that \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:fEOibwPWpKIC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=16269012337446717901",
        "cites_id": [
            "16269012337446717901"
        ],
        "pub_url": "https://direct.mit.edu/jocn/article-abstract/34/10/1988/112185",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:zYn1I4Ykx-EJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Coherent natural scene structure facilitates the extraction of task-relevant object information in visual cortex",
            "pub_year": 2021,
            "citation": "NeuroImage 240, 118365, 2021",
            "author": "Daniel Kaiser and Greta H\u00e4berle and Radoslaw M Cichy",
            "journal": "NeuroImage",
            "volume": "240",
            "pages": "118365",
            "publisher": "Academic Press",
            "abstract": "Looking for objects within complex natural environments is a task everybody performs multiple times each day. In this study, we explore how the brain uses the typical composition of real-world environments to efficiently solve this task. We recorded fMRI activity while participants performed two different categorization tasks on natural scenes. In the object task, they indicated whether the scene contained a person or a car, while in the scene task, they indicated whether the scene depicted an urban or a rural environment. Critically, each scene was presented in an \u201cintact\u201d way, preserving its coherent structure, or in a \u201cjumbled\u201d way, with information swapped across quadrants. In both tasks, participants\u2019 categorization was more accurate and faster for intact scenes. These behavioral benefits were accompanied by stronger responses to intact than to jumbled scenes across high-level visual cortex. To track the amount of \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:5ugPr518TE4C",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=1593589361184118646",
        "cites_id": [
            "1593589361184118646"
        ],
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S1053811921006418",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:dpc4rxSRHRYJ:scholar.google.com/",
        "cites_per_year": {
            "2021": 1,
            "2022": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Category-specific effects of high-level relations in visual search",
            "pub_year": 2023,
            "citation": "OSF preprints, 2023",
            "author": "Nicolas Goupil and Daniel Kaiser and Liuba Papeo",
            "journal": "OSF preprints",
            "abstract": "Recent empirical findings demonstrate that, in visual search for a target in an array of distractors, observers exploit information about object relations to increase search efficiency. We investigated how people searched for interacting people in a crowd, and how the eccentricity of the target affected the search (Experiments 1-3). Participants briefly viewed crowded arrays and had to search for an interacting dyad (two bodies face-to-face) among non-interacting dyads (back-to-back distractors) or vice versa, with the target presented in the attended central location or at peripheral locations. With central targets, we found a search asymmetry, whereby interacting people among non-interacting people were detected better than non-interacting people among interacting people. With peripheral targets, non-interacting targets were detected better than interacting targets. In Experiment 4, we asked whether these asymmetries generalized to object pairs whose spatial relations did or did not form functionally interacting sets (computer screen above keyboard). Results showed that non-interacting targets were detected better than interacting targets, whether presented in central or peripheral locations. Thus, the effect of relational information on visual search is contingent on both stimulus category and attentional focus. Across both stimulus categories (bodies and objects), search is facilitated when individual distractor-items can be organized in larger structured units (social interaction or functional set), effectively reducing the number of distractors. The presentation of social interaction at the attended (central) location breaks this search pattern by readily \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:z_wVstp3MssC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=9316523349721484676",
        "cites_id": [
            "9316523349721484676"
        ],
        "pub_url": "https://osf.io/n7uvk/download",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:hA3IIaDwSoEJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Benchmarking GE-BOLD, SE-BOLD, and SS-SI-VASO sequences for depth-dependent separation of feedforward and feedback signals in high-field MRI",
            "pub_year": 2021,
            "citation": "bioRxiv, 2021",
            "author": "Polina Iamshchinina and Daniel Haenelt and Robert Trampel and Nikolaus Weiskopf and Daniel Kaiser* and Radoslaw Martin Cichy*",
            "journal": "bioRxiv",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Recent advances in high-field fMRI have allowed differentiating feedforward and feedback information in the grey matter of the human brain. For continued progress in this endeavor, it is critical to understand how MRI data acquisition parameters impact the read-out of information from laminar response profiles. Here, we benchmarked three different MR-sequences at 7T - gradient-echo (GE), spin-echo (SE) and vascular space occupancy imaging (VASO) - in differentiating feedforward and feedback signals in human early visual cortex (V1). The experiment (N=4) consisted of two complementary tasks: a perception task that predominantly evokes feedforward signals and a working memory task that relies on feedback signals. In the perception task, participants saw flickering oriented gratings while detecting orthogonal color-changes. In the working memory task, participants memorized the precise orientation of a grating. We used multivariate pattern analysis to read out the perceived (feedforward) and memorized (feedback) grating orientation from neural signals across cortical depth. Analyses across all the MR-sequences revealed perception signals predominantly in the middle cortical compartment of area V1 and working memory signals in the deep compartment. Despite an overall consistency across sequences, SE-EPI was the only sequence where both feedforward and feedback information were differently pronounced across cortical depth in a statistically robust way. We therefore suggest that in the context of a typical cognitive neuroscience experiment as the one benchmarked here, SE-EPI may provide a favorable trade-off between \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:tzM49s52ZIMC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=13219122312225942448",
        "cites_id": [
            "13219122312225942448"
        ],
        "pub_url": "https://www.biorxiv.org/content/10.1101/2021.12.10.472064.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:sOuqfrTBc7cJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Perceived and mentally rotated contents are differentially represented in cortical layers of V1",
            "pub_year": 2020,
            "citation": "Journal of Vision 20 (11), 766-766, 2020",
            "author": "Polina Iamshchinina and Daniel Kaiser and Renat Yakupov and Daniel Haenelt and Alessandro Sciarra and Hendrik Mattern and Emrah Duezel and Oliver Speck and Nikolaus Weiskopf and Radoslaw Martin Cichy",
            "journal": "Journal of Vision",
            "volume": "20",
            "number": "11",
            "pages": "766-766",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Mental rotation typically comprises perceiving an external input and subsequently mentally transforming it in the mind\u2019s eye. These processes require feedforward and feedback information processing in visual cortex. Previous studies showed that V1 contains both the perceived and imagined representations of visual contents, posing the question how V1 can support both processes at the same time. Recent animal and human studies suggest that anatomical distinction might be key: feedforward sensory input targets the middle layer of grey matter, whereas the outer cortical layers receive feedback signals. To investigate whether perceived and mentally rotated contents are differentially represented in cortical layers of V1, we recorded 7T fMRI while participants (N= 24) were briefly presented with oriented gratings and subsequently mentally rotated them. We performed depth-specific differentiation of grey matter into \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:1qzjygNMrQYC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=9251197503260040012",
        "cites_id": [
            "9251197503260040012"
        ],
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2771763",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The temporal dynamics of target selection in real-world scenes",
            "pub_year": 2015,
            "citation": "Journal of Vision 15 (12), 740-740, 2015",
            "author": "Daniel Kaiser and Nikolaas Oosterhof and Marius Peelen",
            "journal": "Journal of Vision",
            "volume": "15",
            "number": "12",
            "pages": "740-740",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "In daily life, humans are constantly required to select behaviorally relevant targets from cluttered and complex environments. In previous neuroimaging studies, the remarkable efficiency of such selection processes has been linked to a selective enhancement of the representation of behaviorally relevant stimulus categories in visual cortex. Although these studies have revealed important insights about the neural basis of real-world search, the temporal unfolding of these effects is still unclear. Here, we recorded MEG activity while participants searched for categorical targets (persons or cars) in real-world scenes. We then tried to recover the presence and location of these two categories within a scene from MEG sensor patterns using multivariate decoding. We found that classifiers trained on patterns evoked by persons and cars in isolation could reliably distinguish between scenes containing persons or cars \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:O3NaXMp0MMsC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=16516492693400915380",
        "cites_id": [
            "16516492693400915380"
        ],
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2433848",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:tA1_tZheNuUJ:scholar.google.com/",
        "cites_per_year": {
            "2016": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "End-to-end topographic networks as models of cortical map formation and human visual behaviour: moving beyond convolutions",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2308.09431, 2023",
            "author": "Zejin Lu and Adrien Doerig and Victoria Bosch and Bas Krahmer and Daniel Kaiser and Radoslaw M Cichy and Tim C Kietzmann",
            "journal": "arXiv preprint arXiv:2308.09431",
            "abstract": "Computational models are an essential tool for understanding the origin and functions of the topographic organisation of the primate visual system. Yet, vision is most commonly modelled by convolutional neural networks that ignore topography by learning identical features across space. Here, we overcome this limitation by developing All-Topographic Neural Networks (All-TNNs). Trained on visual input, several features of primate topography emerge in All-TNNs: smooth orientation maps and cortical magnification in their first layer, and category-selective areas in their final layer. In addition, we introduce a novel dataset of human spatial biases in object recognition, which enables us to directly link models to behaviour. We demonstrate that All-TNNs significantly better align with human behaviour than previous state-of-the-art convolutional models due to their topographic nature. All-TNNs thereby mark an important step forward in understanding the spatial organisation of the visual brain and how it mediates visual behaviour."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:uc_IGeMz5qoC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2308.09431",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Individual differences in internal models explain idiosyncrasies in scene perception",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Matthew J Foxwell* and Gongting Wang* and Radoslaw M Cichy and David Pitcher and Daniel Kaiser",
            "publisher": "PsyArXiv",
            "abstract": "According to predictive processing theories, vision is facilitated by predictions derived from our internal models of what the world should look like. However, the contents of these models and how they vary across people remains unclear. Here, we use drawing to directly access the contents of the internal models of individual participants. Participants were first asked to draw typical versions of scene categories, as descriptors of their internal models. These drawings were converted into standardized 3d renders, which we used as stimuli in subsequent scene categorization experiments. Across two experiments, participants\u2019 scene categorization was more accurate for renders tailored to their own drawings compared to renders based on others\u2019 drawings or copies of scene photographs, suggesting that scene perception is determined by a match with idiosyncratic internal models. These results demonstrate that visual perception can only be fully understood through the lens of our personally unique models of the world."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:nrtMV_XWKgEC",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/98wt7/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:jCng5_Qk1GYJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "EEG decoding reveals neural predictions for naturalistic material behaviors",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.02. 15.528640, 2023",
            "author": "Daniel Kaiser and Rico Stecher and Katja Doerschner",
            "journal": "bioRxiv",
            "pages": "2023.02. 15.528640",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Material properties like softness or stickiness determine how an object can be used. Based on our real-life experience, we form strong expectations about how objects should behave under force, given their typical material properties. Such expectations have been shown to modulate perceptual processes, but we currently do not know how expectation influences the temporal dynamics of the cortical visual analysis for objects and their materials. Here, we tracked the neural representations of expected and unexpected material behaviors using time-resolved EEG decoding in a violation-of-expectation paradigm, where objects fell to the ground and deformed in expected or unexpected ways. Participants were 25 men and women. Our study yielded three key results: First, both objects and materials were represented rapidly and in a temporally sustained fashion. Second, objects exhibiting unexpected material behaviors were more successfully decoded than objects exhibiting expected behaviors within 190ms after the impact, which might indicate additional processing demands when expectations are unmet. Third, general signals of expectation fulfillment that generalize across specific objects and materials were found within the first 150ms after the impact. Together, our results provide new insights into the temporal neural processing cascade that underlies the analysis of real-world material behaviors. They reveal a sequence of predictions, with cortical signals progressing from a general signature of expectation fulfillment towards increased processing of unexpected material behaviors.In the real world, we can make accurate \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:uJ-U7cs_P_0C",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.02.15.528640.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:VQbNSel9v64J:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Alpha-frequency feedback to early visual cortex orchestrates coherent natural vision",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.02. 10.527986, 2023",
            "author": "Lixiang Chen and Radoslaw Martin Cichy* and Daniel Kaiser*",
            "journal": "bioRxiv",
            "pages": "2023.02. 10.527986",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "For coherent visual experience to emerge, the brain needs to spatially integrate the complex and dynamic information it receives from the environment. To meet this challenge, the visual system uses contextual information from one part of the visual field to create feedback signals that guide analysis in other parts of the visual field. Here, we set out to characterize the nature of this feedback across brain rhythms and cortical regions. In EEG and fMRI experiments, we experimentally recreated the spatially distributed nature of visual inputs by presenting natural videos at different visual field locations. Critically, we manipulated the spatiotemporal congruency of the videos, so that they did or did not demand integration into a coherent percept. Decoding stimulus information from frequency-specific EEG patterns revealed a shift from representations in feedforward-related gamma activity for spatiotemporally inconsistent videos to representations in feedback-related alpha activity for spatiotemporally consistent videos. Our fMRI data suggest high-level scene-selective areas as the putative source of this feedback. Combining the EEG data with spatially resolved fMRI recordings, we demonstrate that alpha-frequency feedback is directly associated with representations in early visual cortex. Together this demonstrates how the human brain orchestrates coherent visual experience across space: it uses feedback to integrate information from high-level to early visual cortex through a dedicated rhythmic code in the alpha frequency range."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:-_dYPAW6P2MC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.02.10.527986.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:fb5VqTo388UJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Your place or mine? The neural dynamics of personally familiar scene recognition suggests category independent familiarity encoding",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.06. 29.547012, 2023",
            "author": "Hannah Klink and Daniel Kaiser and Rico Stecher and Geza Gergely Ambrus and Gyula Kovacs",
            "journal": "bioRxiv",
            "pages": "2023.06. 29.547012",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Recognizing a stimulus as familiar is an important capacity in our everyday life. Recent investigation of visual processes has led to important insights into the nature of the neural representations of familiarity for human faces. Still, little is known about how familiarity affects the neural dynamics of non-face stimulus processing. Here we report the results of an EEG study, examining the representational dynamics of personally familiar scenes. Participants viewed highly variable images of their own apartments and unfamiliar ones, as well as personally familiar and unfamiliar faces. Multivariate pattern analyses were used to examine the time course of differential processing of familiar and unfamiliar stimuli. Time resolved classification revealed that familiarity is decodable from the EEG data similarly for scenes and faces. The temporal dynamics showed delayed onsets and peaks for scenes as compared to faces. Familiarity information, starting at 200 ms, generalized across stimulus categories and led to a robust familiarity effect. In addition, familiarity enhanced category representations in early (250 to 300 ms) and later (>400 ms) processing stages. Our results extend previous face familiarity results to another stimulus category and suggest that familiarity as a construct can be understood as a general, stimulus-independent processing step during recognition."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:0KyAp5RtaNEC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.06.29.547012.abstract",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Integrative processing in artificial and biological vision predicts the perceived beauty of natural images",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.05. 05.539579, 2023",
            "author": "Sanjeev Nara and Daniel Kaiser",
            "journal": "bioRxiv",
            "pages": "2023.05. 05.539579",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Previous research indicates that the beauty of natural images is already determined during perceptual analysis. However, it is still largely unclear which perceptual computations give rise to the perception of beauty. Theories of processing fluency suggest that the ease of processing for an image determines its perceived beauty. Here, we tested whether perceived beauty is related to the amount of spatial integration across an image, a perceptual computation that reduces processing demands by aggregating image elements into more efficient representations of the whole. We hypothesized that higher degrees of integration reduce processing demands in the visual system and thereby predispose the perception of beauty. We quantified integrative processing in an artificial deep neural network model of vision: We compared activations between parts of the image and the whole image, where the degree of integration was determined by the amount of deviation between activations for the whole image and its constituent parts. This quantification of integration predicted the beauty ratings for natural images across four studies, which featured different stimuli and task demands. In a complementary fMRI study, we show that integrative processing in human visual cortex predicts perceived beauty in a similar way as in artificial neural networks. Together, our results establish integration as a computational principle that facilitates perceptual analysis and thereby mediates the perception of beauty."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:yB1At4FlUx8C",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.05.05.539579.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:5WVMrLwMM9MJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "TMS disruption of the lateral prefrontal cortex increases neural activity in the default mode network when naming facial expressions",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.03. 09.531897, 2023",
            "author": "David Pitcher and Magdalena Sliwinska and Daniel Kaiser",
            "journal": "bioRxiv",
            "pages": "2023.03. 09.531897",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Recognizing facial expressions is dependent on multiple brain networks specialized for different cognitive functions. In the current study participants (N=20) were scanned using functional magnetic resonance imaging (fMRI) while they performed a covert facial expression naming task. Immediately prior to scanning thetaburst transcranial magnetic stimulation (TMS) was delivered over the right lateral prefrontal cortex (PFC), or the vertex control site. A group whole-brain analysis revealed that TMS induced opposite effects in the neural responses across different brain networks. Stimulation of the right PFC (compared to stimulation of the vertex) decreased neural activity in the left lateral PFC but increased neural activity in three nodes of the default mode network (DMN): the right superior frontal gyrus (SFG), right angular gyrus and the bilateral middle cingulate gyrus. A region of interest (ROI) analysis showed that TMS delivered over the right PFC reduced neural activity across all functionally localised face areas (including in the PFC) compared to TMS delivered over the vertex. These results causally demonstrate that visually recognizing facial expressions is dependent on the dynamic interaction of the face processing network and the DMN. Our study also demonstrates the utility of combined TMS / fMRI studies for revealing the dynamic interactions between different functional brain networks."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:t7zJ5fGR-2UC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.03.09.531897.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:hVnPRsAA4AQJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Characterizing internal models for scene vision",
            "pub_year": 2022,
            "citation": "Journal of Vision 22 (14), 4119-4119, 2022",
            "author": "Daniel Kaiser and Matthew Foxwell",
            "journal": "Journal of Vision",
            "volume": "22",
            "number": "14",
            "pages": "4119-4119",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "The visual brain is often conceptualized as a predictive system. Under this view, visual inputs are constantly matched against internal models of what the world should look like, with a higher similarity between the input and model leading to increased processing efficiency. Given our many prior expectations about the structure of everyday environments, such predictions should be very potent in natural scene perception. In a series of experiments, we asked whether perceptual performance is explained by how well scenes are matched to participants' personal internal models of natural scene categories. Participants took part in drawing tasks where they sketched their most typical versions of kitchens and lounges, which we used as descriptors for their internal models. These drawings were then converted into 3d renders. Using these renders in a scene categorization task, we observed better categorization for \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:9Nmd_mFXekcC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2784925",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Oscillatory brain signatures of dynamic visual integration in natural context",
            "pub_year": 2022,
            "citation": "Journal of Vision 22 (14), 3282-3282, 2022",
            "author": "Lixiang Chen and Radoslaw Martin Cichy and Daniel Kaiser",
            "journal": "Journal of Vision",
            "volume": "22",
            "number": "14",
            "pages": "3282-3282",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "During our daily visual experience, our eyes constantly receive complex information from the environment. This information is characterized by spatiotemporal regularities, with predictable distributions of visual features across the visual field and across time. To create our unitary experience of reality, the brain needs to integrate these inputs in an efficient way. Here, we tested whether such integration processes are mediated by oscillatory neural codes. Specifically, we hypothesized that the integration of spatiotemporally regular information is governed by low-frequency oscillations in the alpha band that were previously linked to top-down modulations of sensory processing. In an EEG experiment, participants viewed short video clips (3s) depicting everyday situations, which were shown through circular apertures in the right and left visual fields. Videos were presented (1) through the right aperture only,(2) through \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:evX43VCCuoAC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2784034",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Moving and static faces, bodies, objects and scenes are differentially represented across the three visual pathways",
            "pub_year": 2022,
            "citation": "bioRxiv, 2022.11. 30.518408, 2022",
            "author": "Emel Kucuk and Matt Foxwell and Daniel Kaiser and David Pitcher",
            "journal": "bioRxiv",
            "pages": "2022.11. 30.518408",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Models of human cortex propose the existence of neuroanatomical pathways specialised for different behavioural functions. These pathways include a ventral pathway for object recognition, a dorsal pathway for performing visually guided physical actions and a recently proposed third pathway for social perception. In the current study we tested the hypothesis that different categories of moving stimuli are differentially processed across the dorsal and third pathways according to their behavioural implications. Human participants (N=30) were scanned with functional magnetic resonance imaging (fMRI) while viewing moving and static stimuli from five categories (faces, bodies, scenes, objects, and scrambled objects). Whole brain group analyses showed that moving bodies and moving objects increased neural responses in bilateral V5/MT+ and intraparietal sulcus (IPS), parts of the dorsal pathway. In addition, moving faces and moving bodies increased neural responses in bilateral V5/MT+ and the right posterior superior temporal sulcus (rpSTS), parts of the third pathway. This pattern of results was also supported by a separate region of interest (ROI) analysis showing that moving stimuli produced more robust neural responses for all visual object categories, particularly in lateral and dorsal brain areas. Our results suggest that dynamic naturalistic stimuli from different categories are routed along specific visual pathways that process their unique behavioural implications."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:VLnqNzywnoUC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2022.11.30.518408.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:VxJlAfZ9ApoJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Similarity to internal models determines the efficiency of scene perception",
            "pub_year": 2021,
            "citation": "PERCEPTION 50 (1_ SUPPL), 212-213, 2021",
            "author": "Matthew J Foxwell and Daniel Kaiser",
            "conference": "PERCEPTION",
            "volume": "50",
            "number": "1_ SUPPL",
            "pages": "212-213",
            "publisher": "SAGE PUBLICATIONS LTD"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:XD-gHx7UXLsC",
        "num_citations": 0,
        "pub_url": "https://scholar.google.com/scholar?cluster=1323942434389213270&hl=en&oi=scholarr",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Scene-object congruency modulates N300/400 EEG components, but does not automatically facilitate object representations",
            "pub_year": 2021,
            "citation": "PERCEPTION 50 (1_ SUPPL), 28-29, 2021",
            "author": "Lixiang Chen and Radoslaw M Cichy and Daniel Kaiser",
            "conference": "PERCEPTION",
            "volume": "50",
            "number": "1_ SUPPL",
            "pages": "28-29",
            "publisher": "SAGE PUBLICATIONS LTD"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:j8SEvjWlNXcC",
        "num_citations": 0,
        "pub_url": "https://scholar.google.com/scholar?cluster=10494882037872758731&hl=en&oi=scholarr",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Spatial schemata determine cortical representations of the environment",
            "pub_year": 2019,
            "citation": "Journal of Vision 19 (10), 250a-250a, 2019",
            "author": "Daniel Kaiser and Jacopo Turini and Radoslaw M Cichy",
            "journal": "Journal of Vision",
            "volume": "19",
            "number": "10",
            "pages": "250a-250a",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "For understanding complex natural environments, the brain must efficiently extract information from a rich, ongoing stream of sensory input. Here we characterize how spatial schemata (ie, our knowledge about the structure of the world) help the visual system to make sense of these inputs. Specifically, we elucidate how schemata contribute to rapidly emerging perceptual representations of the environment. In separate EEG and fMRI experiments, we showed participants fragments of natural scene images, presented at central fixation, while they performed an orthogonal categorization task. Using multivariate analyses, we then investigated where and when neural representations of these fragments were explained by their position within the scene. We observed a sorting of incoming information according to its place in the schema in scene-selective occipital cortex and within the first 200ms of vision. This neural \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:fQNAKQ3IYiAC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2750935",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Low-frequency oscillations track the contents of visual perception and mental imagery",
            "pub_year": 2019,
            "citation": "Journal of Vision 19 (10), 171c-171c, 2019",
            "author": "Siying Xie and Daniel Kaiser and Polina Iamshchinina and Radoslaw Cichy",
            "journal": "Journal of Vision",
            "volume": "19",
            "number": "10",
            "pages": "171c-171c",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Mental imagery of objects is phenomenologically similar to veridical perception. Agreeing with phenomenology, fMRI studies showed that visual perception and imagery of objects share neural representations. However, the temporal dynamics with which these representations emerge remain elusive. To investigate this, we performed an EEG experiment, which included three conditions: participants either saw one of 12 everyday objects (visual condition) or heard the corresponding words while being instructed to imagine the object (mental imagery condition) or not (auditory-only condition). We performed multivariate classification on oscillatory responses to reveal the time courses of perception and imagery. We conducted two key analyses. Firstly, using time-and frequency-resolved classification, we found that in all three conditions object representations emerged rapidly (from around 110ms) in oscillatory \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:LPZeul_q3PIC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2750606",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Neural Dynamics of Categorical Information in Visual and Auditory Signals",
            "pub_year": 2019,
            "citation": "PERCEPTION 48, 118-119, 2019",
            "author": "Polina Iamshchinina and Agnessa Karapetian and Daniel Kaiser and Radoslaw M Cichy",
            "conference": "PERCEPTION",
            "volume": "48",
            "pages": "118-119",
            "publisher": "SAGE PUBLICATIONS LTD"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:eJXPG6dFmWUC",
        "num_citations": 0,
        "pub_url": "https://scholar.google.com/scholar?cluster=16224725080651100728&hl=en&oi=scholarr",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The Temporal Dynamics of Identity Encoding for Famous Faces",
            "pub_year": 2019,
            "citation": "PERCEPTION 48, 79-79, 2019",
            "author": "Geza Gergely Ambrus and Daniel Kaiser and Lisa-Celine Suellwold and Gyula Kovacs",
            "conference": "PERCEPTION",
            "volume": "48",
            "pages": "79-79",
            "publisher": "SAGE PUBLICATIONS LTD"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:vRqMK49ujn8C",
        "num_citations": 0,
        "pub_url": "https://scholar.google.com/scholar?cluster=12436737461679185567&hl=en&oi=scholarr",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Typical real-world locations facilitate object processing",
            "pub_year": 2018,
            "citation": "Journal of Vision 18 (10), 1152-1152, 2018",
            "author": "Daniel Kaiser and Merle Moeskops and Radoslaw Cichy",
            "journal": "Journal of Vision",
            "volume": "18",
            "number": "10",
            "pages": "1152-1152",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "The object content of most real-world scenes is structured: It is characterized both by the types of individual objects (eg, a living room typically consists of a sofa, a table, a lamp and a carpet) and by their locations (eg, a carpet typically lies on the floor, whereas a lamp is hanging from the ceiling). The repeated co-occurrence of specific object types and locations prompts the hypothesis that object processing should be most efficient when the objects appear in their typical locations (eg, a lamp in the upper visual field), relative to atypical locations (eg, a lamp in the lower visual field). Here, we present behavioral and neural data that provide converging support for this hypothesis. In a continuous flash suppression paradigm, observers were faster in detecting an object under conditions of inter-ocular suppression when the object was shown in its typical location. This benefit in behavioral performance suggests a \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:KxtntwgDAa4C",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2700135",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Positional regularity disrupts independent coding of multiple objects in visual cortex",
            "pub_year": 2017,
            "citation": "Journal of Vision 17 (10), 572-572, 2017",
            "author": "Marius Peelen and Daniel Kaiser",
            "journal": "Journal of Vision",
            "volume": "17",
            "number": "10",
            "pages": "572-572",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "The human visual system has adapted to efficiently process cluttered scenes containing dozens of objects. The regular arrangement of these objects critically contributes to the efficiency of naturalistic vision. Recent studies investigating multiple object perception have demonstrated that visual cortex responses to multi-object displays can be accurately modeled by a linear combination of responses to individual objects, revealing independent processing of simultaneously presented objects. Here we use fMRI to show that this independence breaks down when objects are positioned according to frequently experienced configurations. Participants viewed pairs of objects that formed minimalistic two-object scenes (eg, a\" living room\" consisting of a sofa and television) presented in their regularly experienced spatial arrangement or in an irregular arrangement (with the object positions interchanged). Additionally, every \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:zA6iFVUQeVQC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2651454",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Constructing scenes from objects: holistic representation of object arrangements in the parahippocampal place area",
            "pub_year": 2016,
            "citation": "PERCEPTION 45, 339-339, 2016",
            "author": "Daniel Kaiser and Marius Peelen",
            "conference": "PERCEPTION",
            "volume": "45",
            "pages": "339-339",
            "publisher": "SAGE PUBLICATIONS LTD"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:70eg2SAEIzsC",
        "num_citations": 0,
        "pub_url": "https://scholar.google.com/scholar?cluster=1757116497664032560&hl=en&oi=scholarr",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Inter-object grouping in visual processing: How the brain uses real-world regularities to carve up the environment",
            "pub_year": 2015,
            "citation": "University of Trento, 2015",
            "author": "Daniel Kaiser",
            "abstract": "In everyday situations humans are continuously confronted with complex and cluttered visual environments that contain a large number of objects. Despite this complexity, performance in real-life tasks is surprisingly efficient. As a novel explanation for this efficiency, we propose that the brain uses typical regularities between objects (e.g., lamps are typically appearing above dining tables) to group these objects to reduce complexity and thereby facilitate behavioral performance. In a series of experiments, we show that object regularities reduce competitive interactions in visual cortex, and we relate this benefit to improved detection of target objects among regular distracter groups. Furthermore, we show that this inter-object grouping also enhances performance in visual working memory and determines how fast objects enter visual awareness in the first place. Altogether, our findings demonstrate that inter-object grouping effectively reduces the number of competing objects and thus can facilitate perception in cluttered, but regular environments."
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:lSLTfruPkqcC",
        "num_citations": 0,
        "pub_url": "http://eprints-phd.biblio.unitn.it/1586/",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:qyIir-tfbIgJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Real-world regularities facilitate visual awareness of objects under continuous flash suppression",
            "pub_year": 2015,
            "citation": "Journal of Vision 15 (12), 1039-1039, 2015",
            "author": "Timo Stein and Daniel Kaiser and Marius Peelen",
            "journal": "Journal of Vision",
            "volume": "15",
            "number": "12",
            "pages": "1039-1039",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Our stable visual awareness of the world is thought to reflect the transient dominance of neural assemblies representing the conscious percept over competing assemblies representing other aspects of the visual input. These competitive dynamics can be tracked using continuous flash suppression (CFS), in which high-contrast patterns flashed into one eye can suppress the perception of stimuli presented to the other eye for several seconds. Recent work indicates that the competitive strength of a stimulus in overcoming CFS is influenced by contextual regularities in the visual input. For example, stimuli that can be perceptually grouped based on illusory contours have a competitive advantage in gaining access to awareness under CFS. Here, we show that higher-level regularities that arise from the relative positioning of natural objects in the visual environment also modulate visual awareness. In two experiments \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:35N4QoGY0k4C",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2434149",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Reduced attentional competition between objects that follow real-world regularities",
            "pub_year": 2014,
            "citation": "Journal of Vision 14 (10), 1063-1063, 2014",
            "author": "Daniel Kaiser and Timo Stein and Marius V Peelen",
            "journal": "Journal of Vision",
            "volume": "14",
            "number": "10",
            "pages": "1063-1063",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "In virtually every real-life situation humans are confronted with complex and cluttered visual environments that contain large amounts of visual information. Because of the limited capacity of the visual system, not all of this information can be processed at a given time. Consequently, items within a scene are competing for attentional resources. But what is the\" unit\" of this attentional competition? What counts as an item? Here, using fMRI and behavioral measures, we report reduced attentional competition between objects positioned according to commonly experienced configurations, such as a lamp above a table. In an fMRI study designed to measure competitive interactions between objects in visual cortex (Kastner et al., 1998), we found reduced neural competition between objects that were shown in regular configurations. Using a visual search task we then related this reduced competition to improved target \u2026"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:vV6vV6tmYwMC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2144941",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Independent face-and body-selective response patterns in human fusiform gyrus during whole-person perception",
            "pub_year": 2013,
            "citation": "PERCEPTION 42, 54-54, 2013",
            "author": "D Kaiser and L Strnad and KN Seidl and S Kastner and MV Peelen",
            "conference": "PERCEPTION",
            "volume": "42",
            "pages": "54-54",
            "publisher": "PION LTD"
        },
        "filled": true,
        "author_pub_id": "v4CvWHgAAAAJ:2P1L_qKh6hAC",
        "num_citations": 0,
        "pub_url": "https://scholar.google.com/scholar?cluster=12358502185039254240&hl=en&oi=scholarr",
        "cites_per_year": {}
    }
]