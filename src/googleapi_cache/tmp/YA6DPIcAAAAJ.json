[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Why computational complexity may set impenetrable barriers for epistemic reductionism",
            "pub_year": 2023,
            "citation": "Synthese 202 (5), 136, 2023",
            "author": "Michael H Herzog and Adrien Doerig and Christian Sachse",
            "journal": "Synthese",
            "volume": "202",
            "number": "5",
            "pages": "136",
            "publisher": "Springer Netherlands",
            "abstract": "According to physicalism, everything is physical or metaphysically connected to the physical. If physicalism were true, it seems that we should \u2013 in principle \u2013 be able to reduce the descriptions and explanations of special sciences to physical ones, for example, explaining biological regularities, via chemistry, by the laws of particle physics. The multiple realization of the property types of the special sciences is often seen to be an obstacle to such epistemic reductions. Here, we introduce another, new argument against epistemic reduction. Based on mathematical complexity, we show that, under certain conditions, there can be \u201ccomplexity barriers\u201d that make epistemic reduction \u2013 in principle \u2013 unachievable even if physicalism were true."
        },
        "filled": true,
        "author_pub_id": "YA6DPIcAAAAJ:r0BpntZqJG4C",
        "num_citations": 0,
        "pub_url": "https://link.springer.com/article/10.1007/s11229-023-04366-1",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The neuroconnectionist research programme",
            "pub_year": 2023,
            "citation": "Nature Reviews Neuroscience, 1-20, 2023",
            "author": "Adrien Doerig and Rowan P Sommers and Katja Seeliger and Blake Richards and Jenann Ismael and Grace W Lindsay and Konrad P Kording and Talia Konkle and Marcel AJ Van Gerven and Nikolaus Kriegeskorte and Tim C Kietzmann",
            "pages": "1-20",
            "publisher": "Nature Publishing Group UK",
            "abstract": "Artificial neural networks (ANNs) inspired by biology are beginning to be widely used to model behavioural and neural data, an approach we call \u2018neuroconnectionism\u2019. ANNs have been not only lauded as the current best models of information processing in the brain but also criticized for failing to account for basic cognitive functions. In this Perspective article, we propose that arguing about the successes and failures of a restricted set of current ANNs is the wrong approach to assess the promise of neuroconnectionism for brain science. Instead, we take inspiration from the philosophy of science, and in particular from Lakatos, who showed that the core of a scientific research programme is often not directly falsifiable but should be assessed by its capacity to generate novel insights. Following this view, we present neuroconnectionism as a general research programme centred around ANNs as a computational \u2026"
        },
        "filled": true,
        "author_pub_id": "YA6DPIcAAAAJ:-f6ydRqryjwC",
        "num_citations": 18,
        "citedby_url": "/scholar?hl=en&cites=3334113232536501466",
        "cites_id": [
            "3334113232536501466"
        ],
        "pub_url": "https://www.nature.com/articles/s41583-023-00705-w",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:2nxE8lEmRS4J:scholar.google.com/",
        "cites_per_year": {
            "2022": 3,
            "2023": 15
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Characterising representation dynamics in recurrent neural networks for object recognition",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2308.12435, 2023",
            "author": "Sushrut Thorat and Adrien Doerig and Tim C Kietzmann",
            "journal": "arXiv preprint arXiv:2308.12435",
            "abstract": "Recurrent neural networks (RNNs) have yielded promising results for both recognizing objects in challenging conditions and modeling aspects of primate vision. However, the representational dynamics of recurrent computations remain poorly understood, especially in large-scale visual models. Here, we studied such dynamics in RNNs trained for object classification on MiniEcoset, a novel subset of ecoset. We report two main insights. First, upon inference, representations continued to evolve after correct classification, suggesting a lack of the notion of being ``done with classification''. Second, focusing on ``readout zones'' as a way to characterize the activation trajectories, we observe that misclassified representations exhibit activation patterns with lower L2 norm, and are positioned more peripherally in the readout zones. Such arrangements help the misclassified representations move into the correct zones as time progresses. Our findings generalize to networks with lateral and top-down connections, and include both additive and multiplicative interactions with the bottom-up sweep. The results therefore contribute to a general understanding of RNN dynamics in naturalistic tasks. We hope that the analysis framework will aid future investigations of other types of RNNs, including understanding of representational dynamics in primate vision."
        },
        "filled": true,
        "author_pub_id": "YA6DPIcAAAAJ:j3f4tGmQtD8C",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2308.12435",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "End-to-end topographic networks as models of cortical map formation and human visual behaviour: moving beyond convolutions",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2308.09431, 2023",
            "author": "Zejin Lu and Adrien Doerig and Victoria Bosch and Bas Krahmer and Daniel Kaiser and Radoslaw M Cichy and Tim C Kietzmann",
            "journal": "arXiv preprint arXiv:2308.09431",
            "abstract": "Computational models are an essential tool for understanding the origin and functions of the topographic organisation of the primate visual system. Yet, vision is most commonly modelled by convolutional neural networks that ignore topography by learning identical features across space. Here, we overcome this limitation by developing All-Topographic Neural Networks (All-TNNs). Trained on visual input, several features of primate topography emerge in All-TNNs: smooth orientation maps and cortical magnification in their first layer, and category-selective areas in their final layer. In addition, we introduce a novel dataset of human spatial biases in object recognition, which enables us to directly link models to behaviour. We demonstrate that All-TNNs significantly better align with human behaviour than previous state-of-the-art convolutional models due to their topographic nature. All-TNNs thereby mark an important step forward in understanding the spatial organisation of the visual brain and how it mediates visual behaviour."
        },
        "filled": true,
        "author_pub_id": "YA6DPIcAAAAJ:RHpTSmoSYBkC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2308.09431",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Deep neural networks are not a single hypothesis but a language for expressing computational hypotheses",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Tal Golan and JohnMark Taylor and Heiko Sch\u00fctt and Benjamin Peters and Rowan Paolo Sommers and Katja Seeliger and Adrien Doerig and Paul Linton and Talia Konkle and Marcel van Gerven and Konrad Kording and Blake Richards and Tim Christian Kietzmann and Grace W Lindsay and Nikolaus Kriegeskorte",
            "publisher": "PsyArXiv",
            "abstract": "An ideal vision model accounts for behavior and neurophysiology in both naturalistic conditions and designed lab experiments. Unlike psychological theories, artificial neural networks (ANNs) actually perform visual tasks and generate testable predictions for arbitrary inputs. These advantages enable ANNs to engage the entire spectrum of the evidence. Failures of particular models drive progress in a vibrant ANN research program of human vision."
        },
        "filled": true,
        "author_pub_id": "YA6DPIcAAAAJ:e5wmG9Sq2KIC",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/tr7gx/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:1VpvSvB-icIJ:scholar.google.com/",
        "cites_per_year": {}
    }
]