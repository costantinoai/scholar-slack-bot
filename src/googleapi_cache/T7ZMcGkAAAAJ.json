[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Aligning Model and Macaque Inferior Temporal Cortex Representations Improves Model-to-Human Behavioral Alignment and Adversarial Robustness",
            "pub_year": 2023,
            "citation": "International Conference on Learning Representations (ICLR Notable Top-5%), 2023",
            "author": "Joel Dapello* and Kohitij Kar* and Martin Schrimpf and Robert Geary and Michael Ferguson and David D Cox and James DiCarlo",
            "conference": "International Conference on Learning Representations (ICLR Notable Top-5%)",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "While some state-of-the-art artificial neural network systems in computer vision are strikingly accurate models of the corresponding primate visual processing, there are still many discrepancies between these models and the behavior of primates on object recognition tasks. Many current models suffer from extreme sensitivity to adversarial attacks and often do not align well with the image-by-image behavioral error patterns observed in humans. Previous research has provided strong evidence that primate object recognition behavior can be very accurately predicted by neural population activity in the inferior temporal (IT) cortex, a brain area in the late stages of the visual processing hierarchy. Therefore, here we directly test whether making the late stage representations of models more similar to that of macaque IT produces new models that exhibit more robust, primate-like behavior. We conducted chronic, large-scale multi-electrode recordings across the IT cortex in six non-human primates (rhesus macaques). We then use these data to fine-tune (end-to-end) the model \u201cIT\u201d representations such that they are more aligned with the biological IT representations, while preserving accuracy on object recognition tasks. We generate a cohort of models with a range of IT similarity scores validated on held-out animals across two image sets with distinct statistics. Across a battery of optimization conditions, we observed a strong correlation between the models\u2019 IT-likeness and alignment with human behavior, as well as an increase in its adversarial robustness. We further assessed the limitations of this approach and find that the improvements in behavioral \u2026"
        },
        "filled": true,
        "author_pub_id": "T7ZMcGkAAAAJ:RGFaLdJalmkC",
        "num_citations": 9,
        "citedby_url": "/scholar?hl=en&cites=15450149728660711715",
        "cites_id": [
            "15450149728660711715"
        ],
        "pub_url": "https://www.biorxiv.org/content/10.1101/2022.07.01.498495.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:I2lr31H1adYJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 4,
            "2023": 5
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Multimodal investigations of human face perception in neurotypical and autistic adults",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Shuo Wang and Sai Sun and Runnan Cao and Kohitij Kar and Hongbo Yu",
            "publisher": "PsyArXiv",
            "abstract": "Faces are among the most important visual stimuli that we perceive in everyday life. Although there is a plethora of literature studying many aspects of face perception, the vast majority of them focuses on a single aspect of face perception using unimodal approaches. In this review, we advocate for studying face perception using multimodal cognitive neuroscience approaches. We highlight two case studies: the first study investigates ambiguity in facial expressions of emotion, and the second study investigates social trait judgment. In the first set of studies, we revealed an event-related potential that signals emotion ambiguity and we found convergent response to emotion ambiguity using functional neuroimaging and single-neuron recordings. In the second set of studies, we discussed recent findings about neural substrates underlying comprehensive social evaluation, and the relationship between personality factors and social trait judgements. Notably, in both sets of studies, we provided an in-depth discussion of altered face perception in people with autism spectrum disorder (ASD) and offered a computational account for the behavioral and neural markers of atypical facial processing in ASD. Finally, we suggest new perspectives for studying face perception. All data discussed in the case studies of this review are publicly available."
        },
        "filled": true,
        "author_pub_id": "T7ZMcGkAAAAJ:pqnbT2bcN3wC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=234554760078769435",
        "cites_id": [
            "234554760078769435"
        ],
        "pub_url": "https://psyarxiv.com/4g872/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Gz3fwk9OQQMJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Probing the link between dynamics of \u201cface-selectivity\u201d in macaque IT cortex and facial emotion discrimination behavior",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5507-5507, 2023",
            "author": "Maren Wehrheim and Na Yeon Kim and Ralph Adolphs and Kohitij Kar",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5507-5507",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Recognizing facial emotions constitutes a core component of human social interactions. Previous research has discovered several cortical sub-regions (\" face patches\"), primarily localized in the primate inferior temporal (IT) cortex, that respond relatively selectively to faces. However, one can build algorithms that decode faces from the responses of more heterogenous samples of IT neurons. Here we test the link between psychophysical (behavioral) facial emotion discrimination ability and decoding models constructed from neurons with varying\" face-selectivity\". Adult human participants (n= 12) discriminated the emotions (happy vs. fearful) in 80 images (8 identities) presented for 100 ms. We generated a hypothesis space linking IT activity and facial emotion behavior using convolutional neural network (CNN) models of primate vision (adapted to perform emotion discrimination). The estimate of\" face-selectivity\" for \u2026"
        },
        "filled": true,
        "author_pub_id": "T7ZMcGkAAAAJ:dfsIfKJdRG4C",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791900",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Probing the role of bypass connections in core object recognition by chemogenetic suppression of macaque V4 neurons",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5736-5736, 2023",
            "author": "Kohitij Kar",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5736-5736",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "The macaque ventral visual pathway is typically modeled as a series of hierarchically organized cortical areas that successively transform the retinal input into visual object-based linearly separable neural representations. The most behaviorally explicit form of this representation has been discovered in the macaque inferior temporal (IT) cortex. However, each stage of the ventral stream (eg, areas V1, V2) projects to multiple other areas in the brain. In addition, many projections from early visual areas (eg, V1, V2) bypass area V4 and connect directly to the IT cortex. Therefore, the underlying neural circuitry is far more complex than a feedforward architecture. Here I provide evidence for the functional relevance of such bypass connections during object recognition. I hypothesized that images that require fewer transformations to generate linearly separable object representations most benefit from bypass connections \u2026"
        },
        "filled": true,
        "author_pub_id": "T7ZMcGkAAAAJ:4OULZ7Gr8RgC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2792538",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Visual angle and image context alter the alignment between deep convolutional neural networks and the macaque ventral stream",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5539-5539, 2023",
            "author": "Sara Djambazovska and Gabriel Kreiman and Kohitij Kar",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5539-5539",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "A family of deep convolutional neural networks (DCNNs) currently best explains primate ventral stream activity that supports object recognition. Such models are often evaluated with neurobehavioral datasets where the stimuli are presented in the subjects\u2019 central field of view (FOV). However, the exact visual angle often varies widely across studies (eg, 8 degrees for Yamins et al., 2014; 2.9 degrees for Khaligh-Razavi et al., 2014; catered to V1 neuronal receptive field, 2 degrees for Cadena et al., 2019). A unified model of the primate visual system cannot have a varying FOV. Similarly, the type of images used for model evaluation vary across studies, ranging from objects embedded in randomized contexts (Yamins et al., 2014) to objects with no contexts (Khaligh-Razavi et al., 2014). Here we systematically tested how the predictivity of macaque inferior temporal (IT) neurons by DCNNs depends on the FOV and the \u2026"
        },
        "filled": true,
        "author_pub_id": "T7ZMcGkAAAAJ:fPk4N6BV_jEC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791870",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Putative excitatory and inhibitory neurons in the macaque inferior temporal cortex play distinct roles in core object recognition",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 4972-4972, 2023",
            "author": "Sachi Sanghavi and Kohitij Kar",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "4972-4972",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Distributed neural population activity in the macaque inferior temporal (IT) cortex, which lies at the apex of the visual ventral stream hierarchy, is critical in supporting an array of object recognition behavior. Previous research, however, has been agnostic to the relevance of specific cell types, inhibitory vs. excitatory, in the formation of\" behaviorally sufficient\" IT population codes that can accurately predict primate object confusion patterns. Therefore, here, we first compared the strength of behavioral predictions of neural decoding (\" readout\") models constructed from specific (putative) cell types in the IT cortex. We performed large-scale neural recordings while monkeys (n= 3) fixated images (640) presented (100ms) in their central (8 degrees) field of view. Monkeys (n= 3) also performed binary object discrimination tasks (8 objects; 640 images; 28 binary tasks). We performed PCA (and spike shape) based spike \u2026"
        },
        "filled": true,
        "author_pub_id": "T7ZMcGkAAAAJ:u_35RYKgDlwC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791539",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Leveraging computational and animal models of vision to probe atypical emotion recognition in autism",
            "pub_year": 2023,
            "citation": "Computational and Systems Neuroscience (Cosyne), Montreal (CA), 2023",
            "author": "Hamidreza Ramezanpour and Kohitij Kar",
            "conference": "Computational and Systems Neuroscience (Cosyne), Montreal (CA)",
            "abstract": "Recognizing others' emotions based on facial expressions is a core component of human social interactions. Previous studies (Wang and Adolphs 2017) have suggested that autistic individuals show differences in their facial emotion recognition compared to neurotypical adults. What are the neural mechanisms that account for these observed differences? Here we lay the groundwork for a new approach combining cutting-edge computational and empirical non-human primate work to test theories of atypical facial emotion recognition in autistic adults. In a recent study, the author (s) observed that artificial neural network (ANN) models of vision developed to achieve a myriad of visual objectives (eg, object, emotion and face identification) could be fine-tuned to perform facial emotion judgments. Interestingly, the ANNs' image-level behavioral patterns better matched the neurotypical subjects' compared to autistic \u2026"
        },
        "filled": true,
        "author_pub_id": "T7ZMcGkAAAAJ:SeFeTyx0c_EC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791716",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Leveraging Artificial Neural Networks to Enhance Diagnostic Efficiency in Autism Spectrum Disorder: A Study on Facial Emotion Recognition",
            "pub_year": 2023,
            "citation": "Conference on Cognitive Computational Neuroscience (accepted as a talk), 2023",
            "author": "Kushin Mukherjee and Na Yeon Kim and Shirin Taghian Alamooti and Ralph Adolphs and Kohitij Kar",
            "conference": "Conference on Cognitive Computational Neuroscience (accepted as a talk)"
        },
        "filled": true,
        "author_pub_id": "T7ZMcGkAAAAJ:zA6iFVUQeVQC",
        "num_citations": 0,
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Distinct roles of putative excitatory and inhibitory neurons in the macaque inferior temporal cortex in core object recognition behavior",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.08. 01.551579, 2023",
            "author": "Sachi Sanghavi and Kohitij Kar",
            "journal": "bioRxiv",
            "pages": "2023.08. 01.551579",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "A spatially distributed population of neurons in the macaque inferior temporal (IT) cortex supports object recognition behavior, but the cell-type specificity of the population in forming behaviorally sufficient object decodes remain unclear. To address this, we recorded neural signals from the macaque IT cortex and compared the object identity information and the alignment of decoding strategies derived from putative inhibitory (Inh) and excitatory (Exc) neurons to the monkeys' behavior. We observed that while Inh neurons represented significant category information, decoding strategies based on Exc neural population activity outperformed those from Inh neurons in overall accuracy and their image-level match to the monkeys' behavioral reports. Interestingly, both Exc and Inh responses explained a fraction of unique variance of the monkeys' behavior, demonstrating a distinct role of the two cell types in generating object identity solutions for a downstream readout.  We observed that current artificial neural network (ANN) models of primate ventral stream, designed with AI goals of performance optimization on image categorization, better predict Exc neurons (and its contribution to object recognition behavior) than Inh neurons. Beyond, the refinement of linking propositions between IT and object recognition behavior, our results guide the development of more biologically constrained brain models by offering novel cell-type specific neural benchmarks."
        },
        "filled": true,
        "author_pub_id": "T7ZMcGkAAAAJ:rO6llkc54NcC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.08.01.551579.abstract",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Low-cost, portable, easy-to-use kiosks to facilitate home-cage testing of non-human primates during vision-based behavioral tasks",
            "pub_year": 2023,
            "citation": "OSF Preprint, 2023",
            "author": "Christopher Giverin and Hamidreza Ramezanpour and Kohitij Kar",
            "journal": "OSF Preprint",
            "publisher": "https://osf.io/csdzv/"
        },
        "filled": true,
        "author_pub_id": "T7ZMcGkAAAAJ:ldfaerwXgEUC",
        "num_citations": 0,
        "cites_per_year": {}
    }
]