[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
<<<<<<< Updated upstream
=======
            "title": "PAM: Predictive attention mechanism for neural decoding of visual perception",
            "pub_year": 2024,
            "citation": "bioRxiv, 2024.06. 04.596589, 2024",
            "author": "Thirza Dado and Lynn Le and Marcel van Gerven and Yagmur Gucluturk and Umut Guclu",
            "journal": "bioRxiv",
            "pages": "2024.06. 04.596589",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Attention mechanisms enhance deep learning models by focusing on the most relevant parts of the input data. We introduce predictive attention mechanisms (PAMs) -- a novel approach that dynamically derives queries during training which is beneficial when predefined queries are unavailable. We applied PAMs to neural decoding, a field challenged by the inherent complexity of neural data that prevents access to queries. Concretely, we designed a PAM to reconstruct perceived images from brain activity via the latent space of a generative adversarial network (GAN). We processed stimulus-evoked brain activity from various visual areas with separate attention heads, transforming it into a latent vector which was then fed to the GAN's generator to reconstruct the visual stimulus. Driven by prediction-target discrepancies during training, PAMs optimized their queries to identify and prioritize the most relevant neural patterns that required focused attention. We validated our PAM with two datasets: the first dataset (B2G) with GAN-synthesized images, their original latents and multi-unit activity data; the second dataset (GOD) with real photographs, their inverted latents and functional magnetic resonance imaging data. Our findings demonstrate state-of-the-art reconstructions of perception and show that attention weights increasingly favor downstream visual areas. Moreover, visualizing the values from different brain areas enhanced interpretability in terms of their contribution to the final image reconstruction. Interestingly, the values from downstream areas (IT for B2G; LOC for GOD) appeared visually distinct from the stimuli despite receiving the most \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:UamA9ItEL6YC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2024.06.04.596589.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:uV-A73fvEicJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Discovering Dynamic Symbolic Policies with Genetic Programming",
            "pub_year": 2024,
            "citation": "arXiv e-prints, arXiv: 2406.02765, 2024",
            "author": "Sigur de Vries and Sander Keemink and Marcel van Gerven",
            "journal": "arXiv e-prints",
            "pages": "arXiv: 2406.02765",
            "abstract": "Artificial intelligence (AI) techniques are increasingly being applied to solve control problems. However, control systems developed in AI are often black-box methods, in that it is not clear how and why they generate their outputs. A lack of transparency can be problematic for control tasks in particular, because it complicates the identification of biases or errors, which in turn negatively influences the user's confidence in the system. To improve the interpretability and transparency in control systems, the black-box structure can be replaced with white-box symbolic policies described by mathematical expressions. Genetic programming offers a gradient-free method to optimise the structure of non-differentiable mathematical expressions. In this paper, we show that genetic programming can be used to discover symbolic control systems. This is achieved by learning a symbolic representation of a function that transforms \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:KmkpU35IWjAC",
        "num_citations": 0,
        "pub_url": "https://ui.adsabs.harvard.edu/abs/2024arXiv240602765D/abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:IIy9wwSSX5MJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Efficient deep learning with decorrelated backpropagation",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2405.02385, 2024",
            "author": "Sander Dalm and Joshua Offergeld and Nasir Ahmad and Marcel van Gerven",
            "journal": "arXiv preprint arXiv:2405.02385",
            "abstract": "The backpropagation algorithm remains the dominant and most successful method for training deep neural networks (DNNs). At the same time, training DNNs at scale comes at a significant computational cost and therefore a high carbon footprint. Converging evidence suggests that input decorrelation may speed up deep learning. However, to date, this has not yet translated into substantial improvements in training efficiency in large-scale DNNs. This is mainly caused by the challenge of enforcing fast and stable network-wide decorrelation. Here, we show for the first time that much more efficient training of very deep neural networks using decorrelated backpropagation is feasible. To achieve this goal we made use of a novel algorithm which induces network-wide input decorrelation using minimal computational overhead. By combining this algorithm with careful optimizations, we obtain a more than two-fold speed-up and higher test accuracy compared to backpropagation when training a 18-layer deep residual network. This demonstrates that decorrelation provides exciting prospects for efficient deep learning at scale."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:_9EdYq_GCQ0C",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=4649347409528212880",
        "cites_id": [
            "4649347409528212880"
        ],
        "pub_url": "https://arxiv.org/abs/2405.02385",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:kM1P7tXMhUAJ:scholar.google.com/",
        "cites_per_year": {
            "2024": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Subspace Node Pruning",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2405.17506, 2024",
            "author": "Joshua Offergeld and Marcel van Gerven and Nasir Ahmad",
            "journal": "arXiv preprint arXiv:2405.17506",
            "abstract": "A significant increase in the commercial use of deep neural network models increases the need for efficient AI. Node pruning is the art of removing computational units such as neurons, filters, attention heads, or even entire layers while keeping network performance at a maximum. This can significantly reduce the inference time of a deep network and thus enhance its efficiency. Few of the previous works have exploited the ability to recover performance by reorganizing network parameters while pruning. In this work, we propose to create a subspace from unit activations which enables node pruning while recovering maximum accuracy. We identify that for effective node pruning, a subspace can be created using a triangular transformation matrix, which we show to be equivalent to Gram-Schmidt orthogonalization, which automates this procedure. We further improve this method by reorganizing the network prior to subspace formation. Finally, we leverage the orthogonal subspaces to identify layer-wise pruning ratios appropriate to retain a significant amount of the layer-wise information. We show that this measure outperforms existing pruning methods on VGG networks. We further show that our method can be extended to other network architectures such as residual networks."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:_Xy5tTOxz_oC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2405.17506",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:S1M0EkwfH-MJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Gradient-Free Training of Recurrent Neural Networks using Random Perturbations",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2405.08967, 2024",
            "author": "Jes\u00fas Garc\u0131a Fern\u00e1ndez and Sander Keemink and Marcel van Gerven",
            "journal": "arXiv preprint arXiv:2405.08967",
            "abstract": "Recurrent neural networks (RNNs) hold immense potential for computations due to their Turing completeness and sequential processing capabilities, yet existing methods for their training encounter efficiency challenges. Backpropagation through time (BPTT), the prevailing method, extends the backpropagation (BP) algorithm by unrolling the RNN over time. However, this approach suffers from significant drawbacks, including the need to interleave forward and backward phases and store exact gradient information. Furthermore, BPTT has been shown to struggle with propagating gradient information for long sequences, leading to vanishing gradients. An alternative strategy to using gradient-based methods like BPTT involves stochastically approximating gradients through perturbation-based methods. This learning approach is exceptionally simple, necessitating only forward passes in the network and a global reinforcement signal as feedback. Despite its simplicity, the random nature of its updates typically leads to inefficient optimization, limiting its effectiveness in training neural networks. In this study, we present a new approach to perturbation-based learning in RNNs whose performance is competitive with BPTT, while maintaining the inherent advantages over gradient-based learning. To this end, we extend the recently introduced activity-based node perturbation (ANP) method to operate in the time domain, leading to more efficient learning and generalization. Subsequently, we conduct a range of experiments to validate our approach. Our results show similar performance, convergence time and scalability when compared to BPTT, strongly \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:4LC-jEhLaRQC",
        "num_citations": 0,
        "pub_url": "https://www.researchgate.net/profile/Jesus-Garcia-Fernandez/publication/380898088_Gradient-Free_Training_of_Recurrent_Neural_Networks_using_Random_Perturbations/links/66546f07479366623a166b65/Gradient-Free-Training-of-Recurrent-Neural-Networks-using-Random-Perturbations.pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:wRXtqCfJ-EMJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Perturbation-based Learning for Recurrent Neural Networks",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2405.08967, 2024",
            "author": "Jesus Garcia Fernandez and Sander Keemink and Marcel van Gerven",
            "journal": "arXiv preprint arXiv:2405.08967",
            "abstract": "Recurrent neural networks (RNNs) hold immense potential for computations due to their Turing completeness and sequential processing capabilities, yet existing methods for their training encounter efficiency challenges. Backpropagation through time (BPTT), the prevailing method, extends the backpropagation (BP) algorithm by unrolling the RNN over time. However, this approach suffers from significant drawbacks, including the need to interleave forward and backward phases and store exact gradient information. Furthermore, BPTT has been shown to struggle with propagating gradient information for long sequences, leading to vanishing gradients. An alternative strategy to using gradient-based methods like BPTT involves stochastically approximating gradients through perturbation-based methods. This learning approach is exceptionally simple, necessitating only forward passes in the network and a global reinforcement signal as feedback. Despite its simplicity, the random nature of its updates typically leads to inefficient optimization, limiting its effectiveness in training neural networks. In this study, we present a new approach to perturbation-based learning in RNNs whose performance is competitive with BPTT, while maintaining the inherent advantages over gradient-based learning. To this end, we extend the recently introduced activity-based node perturbation (ANP) method to operate in the time domain, leading to more efficient learning and generalization. Subsequently, we conduct a range of experiments to validate our approach. Our results show similar performance, convergence time and scalability when compared to BPTT, strongly \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:viYOxJONeN0C",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2405.08967",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:pBfzve6EaMsJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Brain2GAN: Feature-disentangled neural encoding and decoding of visual perception in the primate brain",
            "pub_year": 2024,
            "citation": "PLOS Computational Biology 20 (5), e1012058, 2024",
            "author": "Thirza Dado and Paolo Papale and Antonio Lozano and Lynn Le and Feng Wang and Marcel van Gerven and Pieter Roelfsema and Ya\u011fmur G\u00fc\u00e7l\u00fct\u00fcrk and Umut G\u00fc\u00e7l\u00fc",
            "journal": "PLOS Computational Biology",
            "volume": "20",
            "number": "5",
            "pages": "e1012058",
            "publisher": "Public Library of Science",
            "abstract": "A challenging goal of neural coding is to characterize the neural representations underlying visual perception. To this end, multi-unit activity (MUA) of macaque visual cortex was recorded in a passive fixation task upon presentation of faces and natural images. We analyzed the relationship between MUA and latent representations of state-of-the-art deep generative models, including the conventional and feature-disentangled representations of generative adversarial networks (GANs) (i.e., z- and w-latents of StyleGAN, respectively) and language-contrastive representations of latent diffusion networks (i.e., CLIP-latents of Stable Diffusion). A mass univariate neural encoding analysis of the latent representations showed that feature-disentangled w representations outperform both z and CLIP representations in explaining neural responses. Further, w-latent features were found to be positioned at the higher end of the complexity gradient which indicates that they capture visual information relevant to high-level neural activity. Subsequently, a multivariate neural decoding analysis of the feature-disentangled representations resulted in state-of-the-art spatiotemporal reconstructions of visual perception. Taken together, our results not only highlight the important role of feature-disentanglement in shaping high-level neural representations underlying visual perception but also serve as an important benchmark for the future of neural coding."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:H7WDvlwkmv8C",
        "num_citations": 0,
        "pub_url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1012058",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:tWabsc54HB8J:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Efficient Deep Learning with Decorrelated Backpropagation",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2405.02385, 2024",
            "author": "Sander Dalm and Joshua Offergeld and Nasir Ahmad and Marcel van Gerven",
            "journal": "arXiv preprint arXiv:2405.02385",
            "abstract": "The backpropagation algorithm remains the dominant and most successful method for training deep neural networks (DNNs). At the same time, training DNNs at scale comes at a significant computational cost and therefore a high carbon footprint. Converging evidence suggests that input decorrelation may speed up deep learning. However, to date, this has not yet translated into substantial improvements in training efficiency in large-scale DNNs. This is mainly caused by the challenge of enforcing fast and stable network-wide decorrelation. Here, we show for the first time that much more efficient training of very deep neural networks using decorrelated backpropagation is feasible. To achieve this goal we made use of a novel algorithm which induces network-wide input decorrelation using minimal computational overhead. By combining this algorithm with careful optimizations, we obtain a more than two-fold speed-up and higher test accuracy compared to backpropagation when training a 18-layer deep residual network. This demonstrates that decorrelation provides exciting prospects for efficient deep learning at scale."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:_9EdYq_GCQ0C",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2405.02385",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:kM1P7tXMhUAJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Gaze-contingent XR phosphene simulation for mobility, scene recognition and visual search",
            "pub_year": 2024,
            "citation": "Radboud Data Repository, 2024",
            "author": "J de Ruyter van Steveninck and MH Nipshagen and MAJ van Gerven and U G\u00fc\u00e7l\u00fc and Y G\u00fc\u00e7l\u00fct\u00fcrk and RJA van Wezel",
            "publisher": "Radboud Data Repository",
            "abstract": "Experimental data of the paper \"Gaze-contingent processing improves mobility,scene recognition and visual search insimulated head-steered prosthetic vision\"."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:lM7bPffmjyEC",
        "num_citations": 0,
        "pub_url": "https://repository.ubn.ru.nl/handle/2066/304562",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:R44axErNi0wJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Universal Differential Equations as a Common Modeling Language for Neuroscience",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2403.14510, 2024",
            "author": "Ahmed ElGazzar and Marcel van Gerven",
            "journal": "arXiv preprint arXiv:2403.14510",
            "abstract": "The unprecedented availability of large-scale datasets in neuroscience has spurred the exploration of artificial deep neural networks (DNNs) both as empirical tools and as models of natural neural systems. Their appeal lies in their ability to approximate arbitrary functions directly from observations, circumventing the need for cumbersome mechanistic modeling. However, without appropriate constraints, DNNs risk producing implausible models, diminishing their scientific value. Moreover, the interpretability of DNNs poses a significant challenge, particularly with the adoption of more complex expressive architectures. In this perspective, we argue for universal differential equations (UDEs) as a unifying approach for model development and validation in neuroscience. UDEs view differential equations as parameterizable, differentiable mathematical objects that can be augmented and trained with scalable deep learning techniques. This synergy facilitates the integration of decades of extensive literature in calculus, numerical analysis, and neural modeling with emerging advancements in AI into a potent framework. We provide a primer on this burgeoning topic in scientific machine learning and demonstrate how UDEs fill in a critical gap between mechanistic, phenomenological, and data-driven models in neuroscience. We outline a flexible recipe for modeling neural systems with UDEs and discuss how they can offer principled solutions to inherent challenges across diverse neuroscience applications such as understanding neural computation, controlling neural systems, neural decoding, and normative modeling."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:Ncwx4PHgTB8C",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2403.14510",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:85jO-7kGqxsJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Gaze-contingent processing improves mobility, scene recognition and visual search in simulated head-steered prosthetic vision",
            "pub_year": 2024,
            "citation": "Journal of Neural Engineering, 2024",
            "author": "Jaap de Ruyter van Steveninck and Mo Nipshagen and Marcel van Gerven and Umut G\u00fc\u00e7l\u00fc and Ya\u011fmur G\u00fc\u00e7l\u00fcturk and Richard van Wezel",
            "journal": "Journal of Neural Engineering",
            "abstract": "OBJECTIVE The enabling technology of visual prosthetics for the blind is making rapid progress. However, there are still uncertainties regarding the functional outcomes, which can depend on many design choices in the development. In visual prostheses with a head-mounted camera, a particularly challenging question is how to deal with the gaze-locked visual percept associated with spatial updating conflicts in the brain. The current study investigates a recently proposed compensation strategy based on gaze-contingent image processing with eye-tracking. Gaze-contingent processing is expected to reinforce natural-like visual scanning and reestablished spatial updating based on eye movements. The beneficial effects remain to be investigated for daily life activities in complex visual environments.  APPROACH The current study evaluates the benefits of gaze-contingent processing versus gaze-locked and gaze \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:6fs0NoO7GbkC",
        "num_citations": 0,
        "pub_url": "https://iopscience.iop.org/article/10.1088/1741-2552/ad357d/meta",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:4pBB9K6ysD8J:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "DeNovoCNN: A deep learning approach to de novo variant calling in next generation sequencing data",
            "pub_year": 2024,
            "citation": "EUROPEAN JOURNAL OF HUMAN GENETICS 32, 662-662, 2024",
            "author": "Gelana Khazeeva and Karolis Sablauskas and Bart Van der Sanden and Wouter Steyaert and Michael Kwint and Dmitrijs Rots and Max Hinne and Marcel van Gerven and Helger Yntema and Lisenka Vissers and Christian Gilissen",
            "conference": "EUROPEAN JOURNAL OF HUMAN GENETICS",
            "volume": "32",
            "pages": "662-662",
            "publisher": "SPRINGERNATURE"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:1tvASLRm6poC",
        "num_citations": 0,
        "pub_url": "https://scholar.google.com/scholar?cluster=3983757347967322127&hl=en&oi=scholarr",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:D8jxfDMmSTcJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Towards biologically plausible phosphene simulation for the differentiable optimization of visual cortical prostheses",
            "pub_year": 2024,
            "citation": "Elife 13, e85812, 2024",
            "author": "Maureen van der Grinten and Jaap de Ruyter van Steveninck and Antonio Lozano and Laura Pijnacker and Bodo Rueckauer and Pieter Roelfsema and Marcel van Gerven and Richard van Wezel and Umut G\u00fc\u00e7l\u00fc and Ya\u011fmur G\u00fc\u00e7l\u00fct\u00fcrk",
            "journal": "Elife",
            "volume": "13",
            "pages": "e85812",
            "publisher": "eLife Sciences Publications Limited",
            "abstract": "Blindness affects millions of people around the world. A promising solution to restoring a form of vision for some individuals are cortical visual prostheses, which bypass part of the impaired visual pathway by converting camera input to electrical stimulation of the visual system. The artificially induced visual percept (a pattern of localized light flashes, or \u2018phosphenes\u2019) has limited resolution, and a great portion of the field\u2019s research is devoted to optimizing the efficacy, efficiency, and practical usefulness of the encoding of visual information. A commonly exploited method is noninvasive functional evaluation in sighted subjects or with computational models by using simulated prosthetic vision (SPV) pipelines. An important challenge in this approach is to balance enhanced perceptual realism, biologically plausibility, and real-time performance in the simulation of cortical prosthetic vision. We present a biologically plausible, PyTorch-based phosphene simulator that can run in real-time and uses differentiable operations to allow for gradient-based computational optimization of phosphene encoding models. The simulator integrates a wide range of clinical results with neurophysiological evidence in humans and non-human primates. The pipeline includes a model of the retinotopic organization and cortical magnification of the visual cortex. Moreover, the quantitative effects of stimulation parameters and temporal dynamics on phosphene characteristics are incorporated. Our results demonstrate the simulator\u2019s suitability for both computational applications such as end-to-end deep learning-based prosthetic vision optimization as well as behavioral \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:HWVPSj4JXeEC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=17341316344401265165",
        "cites_id": [
            "17341316344401265165"
        ],
        "pub_url": "https://elifesciences.org/articles/85812",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:DYK2RVa7qPAJ:scholar.google.com/",
        "cites_per_year": {
            "2024": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Towards biologically plausible phosphene simulation for the differentiable optimization of visual cortical prostheses",
            "pub_year": 2024,
            "citation": "",
            "author": "M Grinten and J de Ruyter van Steveninck and A Lozano and L Pijnacker and BJ R\u00fcckauer and PR Roelfsema and MAJ van Gerven and RJA van Wezel and U G\u00fc\u00e7l\u00fc and Y G\u00fc\u00e7l\u00fct\u00fcrk",
            "abstract": "Blindness affects millions of people around the world. A promising solution to restoring a form of vision for some individuals are cortical visual prostheses, which bypass part of the impaired visual pathway by converting camera input to electrical stimulation of the visual system. The artificially induced visual percept (a pattern of localized light flashes, or 'phosphenes') has limited resolution, and a great portion of the field's research is devoted to optimizing the efficacy, efficiency, and practical usefulness of the encoding of visual information. A commonly exploited method is non-invasive functional evaluation in sighted subjects or with computational models by using simulated prosthetic vision (SPV) pipelines. An important challenge in this approach is to balance enhanced perceptual realism, biologically plausibility, and real-time performance in the simulation of cortical prosthetic vision. We present a biologically plausible, PyTorch-based phosphene simulator that can run in real-time and uses differentiable operations to allow for gradient-based computational optimization of phosphene encoding models. The simulator integrates a wide range of clinical results with neurophysiological evidence in humans and non-human primates. The pipeline includes a model of the retinotopic organization and cortical magnification of the visual cortex. Moreover, the quantitative effects of stimulation parameters and temporal dynamics on phosphene characteristics are incorporated. Our results demonstrate the simulator's suitability for both computational applications such as end-to-end deep learning-based prosthetic vision optimization as well as behavioral \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:AOeXN74AWYwC",
        "num_citations": 0,
        "pub_url": "https://repository.ubn.ru.nl/handle/2066/303598",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Bg4h8N5hmrkJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "A Dynamical Systems Approach to Optimal Foraging",
            "pub_year": 2024,
            "citation": "bioRxiv, 2024.01. 20.576399, 2024",
            "author": "Siddharth Chaturvedi and Ahmed ElGazzar and Marcel van Gerven",
            "journal": "bioRxiv",
            "pages": "2024.01. 20.576399",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Foraging for resources in an environment is a fundamental activity that must be addressed by any biological agent. Thus, modelling this phenomenon in simulations can enhance our understanding of the characteristics of natural intelligence. In this work, we present a novel approach to modelling this phenomenon in silico. We achieve this by using a continuous coupled dynamical system for modelling the system. The dynamical system is composed of three differential equations, representing the position of the agent, the agent's control policy, and the environmental resource dynamics. Crucially, the control policy is implemented as a neural differential equation which allows the control policy to adapt in order to solve the foraging task. Using this setup, we show that when these dynamics are coupled and the controller parameters are optimized to maximize the rate of reward collected, adaptive foraging emerges in the agent. We further show that the internal dynamics of the controller, as a surrogate brain model, closely resemble the dynamics of the evidence accumulation mechanism, which may be used by certain neurons of the dorsal anterior cingulate cortex region in non-human primates, for deciding when to migrate from one patch to another. Finally, we show that by modulating the resource growth rates of the environment, the emergent behaviour of the artificial agent agrees with the predictions of the optimal foraging theory."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:GYFkgKAhzLcC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2024.01.20.576399.abstract",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
>>>>>>> Stashed changes
            "title": "Oscillations in an Artificial Neural Network Convert Competing Inputs into a Temporal Code",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.11. 27.568876, 2023",
            "author": "Katharina Duecker and Marco Idiart and Marcel AJ van Gerven and Ole Jensen",
            "journal": "bioRxiv",
            "pages": "2023.11. 27.568876",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Deep convolutional neural networks (CNNs) resemble the hierarchically organised neural representations in the primate visual ventral stream. However, these models typically disregard the temporal dynamics experimentally observed in these areas. For instance, alpha oscillations dominate the dynamics of the human visual cortex, yet the computational relevance of oscillations is rarely considered in artificial neural networks (ANNs). We propose an ANN that embraces oscillatory dynamics with the computational purpose of converting simultaneous inputs, presented at two different locations, into a temporal code. The network was trained to classify three individually presented letters. Post-training, we added semi-realistic temporal dynamics to the hidden layer, introducing relaxation dynamics in the hidden units as well as pulsed inhibition mimicking neuronal alpha oscillations. Without these dynamics, the trained network correctly classified individual letters but produced a mixed output when presented with two letters simultaneously, elucidating a bottleneck problem. When introducing refraction and oscillatory inhibition, the output nodes corresponding to the two stimuli activated sequentially, ordered along the phase of the inhibitory oscillations. Our model provides a novel approach for implementing multiplexing in ANNs. It further produces experimentally testable predictions of how the primate visual system handles competing stimuli."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:bPZF39XCNPMC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.11.27.568876.abstract",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "A 128-channel real-time VPDNN stimulation system for a visual cortical neuroprosthesis",
            "pub_year": 2023,
            "citation": "Biomedical Circuits and Systems Conference (BioCAS), 2023",
            "author": "Hasan Mohamed and Bogdan Raducanu and Ilya Kiselev and Zuowen Wang and Burcu Kucukoglu and Bodo Rueckauer and Marcel van Gerven and Mora Lopez Carolina and Shih-Chii Liu",
            "journal": "Biomedical Circuits and Systems Conference (BioCAS)",
            "publisher": "Institute of Electrical and Electronics Engineers",
            "abstract": "With the recent progress in developing large-scale micro-electrodes, cortical neuroprotheses supporting hundreds of electrodes will be viable in the near future. We describe work in building a visual stimulation system that receives camera input images and produces stimulation patterns for driving a large set of electrodes. The system consists of a convolutional neural network FPGA accelerator and a recording and stimulation Application-Specific Integrated Circuit (ASIC) that produces the stimulation patterns. It is aimed at restoring visual perception in visually impaired subjects. The FPGA accelerator, VPDNN, runs a visual prosthesis network that generates an output used to create stimulation patterns, which are then converted by the ASIC into current pulses to drive a multi-electrode array. The accelerator exploits spatial sparsity and the use of reduced bit precision parameters for reduced computation, memory and power for portability. Experimental results from the VPDNN show that the 94.5K parameter 14-layer CNN receiving an input of 128 \u00d7 128 has an inference frame rate of 83 frames per sec (FPS) and uses only an incremental power of 0.1 W, which is at least 10\u00d7 lower than that measured from a Jetson Nano. The ASIC adds a maximum delay of 2ms, however it does not impact the FPS thanks to double-buffered memory.  Index Terms\u2014Visual prosthesis, convolutional neural network, FPGA Accelerator, stimulation and recording ASIC"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:ui-gComCE0IC",
        "num_citations": 0,
        "pub_url": "https://www.zora.uzh.ch/id/eprint/238168/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Feature-disentangled reconstruction of perception from multi-unit recording",
            "pub_year": 2023,
            "citation": "Sl: sn, 2023",
            "author": "TM Dado and Paolo Papale and Antonio Lozano and Lynn Le and MAJ van Gerven and PR Roelfsema and Y G\u00fc\u00e7l\u00fct\u00fcrk and U G\u00fc\u00e7l\u00fc",
            "publisher": "Sl: sn",
            "abstract": "Here, we aimed to explain neural representations of perception, for which we analyzed the relationship between multi-unit activity (MUA) recorded from the primate brain and various feature representations of visual stimuli. Our encoding analysis revealed that the -latent representations of feature-disentangled generative adversarial networks (GANs) were the most effective candidate for predicting neural responses to images. Importantly, the usage of synthesized yet photorealistic images allowed for superior control over these data as their underlying latent representations were known a priori rather than approximated post-hoc. As such, we leveraged this property in neural reconstruction of the perceived images. Taken together with the fact that the (unsupervised) generative models themselves were never optimized on neural data, these results highlight the importance of feature disentanglement and unsupervised training as driving factors in shaping neural representations."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:vq7B84E5p90C",
        "num_citations": 0,
        "pub_url": "https://repository.ubn.ru.nl/bitstream/handle/2066/297727/297727.pdf?sequence=1",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The neuroconnectionist research programme",
            "pub_year": 2023,
            "citation": "Nature Reviews Neuroscience, 1-20, 2023",
            "author": "Adrien Doerig and Rowan P Sommers and Katja Seeliger and Blake Richards and Jenann Ismael and Grace W Lindsay and Konrad P Kording and Talia Konkle and Marcel AJ Van Gerven and Nikolaus Kriegeskorte and Tim C Kietzmann",
            "pages": "1-20",
            "publisher": "Nature Publishing Group UK",
            "abstract": "Artificial neural networks (ANNs) inspired by biology are beginning to be widely used to model behavioural and neural data, an approach we call \u2018neuroconnectionism\u2019. ANNs have been not only lauded as the current best models of information processing in the brain but also criticized for failing to account for basic cognitive functions. In this Perspective article, we propose that arguing about the successes and failures of a restricted set of current ANNs is the wrong approach to assess the promise of neuroconnectionism for brain science. Instead, we take inspiration from the philosophy of science, and in particular from Lakatos, who showed that the core of a scientific research programme is often not directly falsifiable but should be assessed by its capacity to generate novel insights. Following this view, we present neuroconnectionism as a general research programme centred around ANNs as a computational \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:9Gmr9OE0IYAC",
        "num_citations": 27,
        "citedby_url": "/scholar?hl=en&cites=3334113232536501466",
        "cites_id": [
            "3334113232536501466"
        ],
        "pub_url": "https://www.nature.com/articles/s41583-023-00705-w",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:2nxE8lEmRS4J:scholar.google.com/",
        "cites_per_year": {
            "2022": 5,
            "2023": 22
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Direct speech reconstruction from sensorimotor brain activity with optimized deep learning models",
            "pub_year": 2023,
            "citation": "Journal of Neural Engineering 20 (5), 056010, 2023",
            "author": "Julia Berezutskaya and Zachary V Freudenburg and Mariska J Vansteensel and Erik J Aarnoutse and Nick F Ramsey and Marcel AJ van Gerven",
            "journal": "Journal of Neural Engineering",
            "volume": "20",
            "number": "5",
            "pages": "056010",
            "publisher": "IOP Publishing",
            "abstract": "Objective Development of brain\u2013computer interface (BCI) technology is key for enabling communication in individuals who have lost the faculty of speech due to severe motor paralysis. A BCI control strategy that is gaining attention employs speech decoding from neural data. Recent studies have shown that a combination of direct neural recordings and advanced computational models can provide promising results. Understanding which decoding strategies deliver best and directly applicable results is crucial for advancing the field. Approach In this paper, we optimized and validated a decoding approach based on speech reconstruction directly from high-density electrocorticography recordings from sensorimotor cortex during a speech production task. Main results We show that (1) dedicated machine learning optimization of reconstruction models is key for achieving the best reconstruction performance;(2 \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:YifW7xAlWS4C",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=6815437794385051817",
        "cites_id": [
            "6815437794385051817"
        ],
        "pub_url": "https://iopscience.iop.org/article/10.1088/1741-2552/ace8be/meta",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:qcAXc5BMlV4J:scholar.google.com/",
        "cites_per_year": {
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "How does artificial intelligence contribute to iEEG research?",
            "pub_year": 2023,
            "citation": "Intracranial EEG: A Guide for Cognitive Neuroscientists, 761-802, 2023",
            "author": "Julia Berezutskaya and Anne-Lise Saive and Karim Jerbi and Marcel van Gerven",
            "pages": "761-802",
            "publisher": "Springer International Publishing",
            "abstract": "Artificial intelligence (AI) is a fast-growing field focused on modeling and machine implementation of various cognitive functions with an increasing number of applications in computer vision, text processing, robotics, neurotechnology, bio-inspired computing and others. In this chapter, we describe how AI methods can be applied in the context of intracranial electroencephalography (iEEG) research. IEEG data is unique as it provides extremely high-quality signals recorded directly from brain tissue. Applying advanced AI models to this data carries the potential to further our understanding of many fundamental questions in neuroscience. At the same time, as an invasive technique, iEEG lends itself well to long-term, mobile brain-computer interface applications, particularly for communication in severely paralyzed individuals. We provide a detailed overview of these two research directions in the application of AI \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:jM2XaDTMsSgC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=3953036552226278355",
        "cites_id": [
            "3953036552226278355"
        ],
        "pub_url": "https://link.springer.com/chapter/10.1007/978-3-031-20910-9_47",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:0wuV18wB3DYJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 3
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "PhenoScore quantifies phenotypic variation for rare genetic diseases by combining facial analysis with other clinical features using a machine-learning framework",
            "pub_year": 2023,
            "citation": "Nature Genetics 55 (9), 1598-1607, 2023",
            "author": "Alexander JM Dingemans and Max Hinne and Kim MG Truijen and Lia Goltstein and Jeroen Van Reeuwijk and Nicole De Leeuw and Janneke Schuurs-Hoeijmakers and Rolph Pfundt and Illja J Diets and Joery Den Hoed and Elke De Boer and Jet Coenen-van Der Spek and Sandra Jansen and Bregje W Van Bon and Noraly Jonis and Charlotte W Ockeloen and Anneke T Vulto-van Silfhout and Tjitske Kleefstra and David A Koolen and Philippe M Campeau and Elizabeth E Palmer and Hilde Van Esch and Gholson J Lyon and Fowzan S Alkuraya and Anita Rauch and Ronit Marom and Diana Baralle and Pleuntje J Van Der Sluijs and Gijs WE Santen and R Frank Kooy and Marcel AJ Van Gerven and Lisenka ELM Vissers and Bert BA de Vries",
            "journal": "Nature Genetics",
            "volume": "55",
            "number": "9",
            "pages": "1598-1607",
            "publisher": "Nature Publishing Group US",
            "abstract": "Several molecular and phenotypic algorithms exist that establish genotype\u2013phenotype correlations, including facial recognition tools. However, no unified framework that investigates both facial data and other phenotypic data directly from individuals exists. We developed PhenoScore: an open-source, artificial intelligence-based phenomics framework, combining facial recognition technology with Human Phenotype Ontology data analysis to quantify phenotypic similarity. Here we show PhenoScore\u2019s ability to recognize distinct phenotypic entities by establishing recognizable phenotypes for 37 of 40 investigated syndromes against clinical features observed in individuals with other neurodevelopmental disorders and show it is an improvement on existing approaches. PhenoScore provides predictions for individuals with variants of unknown significance and enables sophisticated genotype\u2013phenotype studies by \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:yWe6nybXSkwC",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=2969395117191689818",
        "cites_id": [
            "2969395117191689818"
        ],
        "pub_url": "https://www.nature.com/articles/s41588-023-01469-w",
        "cites_per_year": {
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "An In-Silico Framework for Modeling Optimal Control of Neural Systems",
            "pub_year": 2023,
            "citation": "Frontiers in Neuroscience 17, 332, 2023",
            "author": "Bodo Rueckauer and Marcel van Gerven",
            "journal": "Frontiers in Neuroscience",
            "volume": "17",
            "pages": "332",
            "publisher": "Frontiers",
            "abstract": "Brain-machine interfaces have reached an unprecedented capacity to measure and drive activity in the brain, allowing restoration of impaired sensory, cognitive or motor function. Classical control theory is pushed to its limit when aiming to design control laws that are suitable for large-scale, complex neural systems. This work proposes a scalable, data-driven, unified approach to study brain-machine-environment interaction using established tools from dynamical systems, optimal control theory, and deep learning. To unify the methodology, we define the environment, neural system, and prosthesis in terms of differential equations with learnable parameters, which effectively reduce to recurrent neural networks in the discrete-time case. Drawing on tools from optimal control, we describe three ways to train the system: Direct optimization of an objective function, oracle-based learning, and reinforcement learning. These approaches are adapted to different assumptions about knowledge of system equations, linearity, differentiability, and observability. We apply the proposed framework to train an in-silico neural system to perform tasks in a linear and a nonlinear environment, namely particle stabilization and pole balancing. After training, this model is perturbed to simulate impairment of sensor and motor function. We show how a prosthetic controller can be trained to restore the behavior of the neural system under increasing levels of perturbation. We expect that the proposed framework will enable rapid and flexible synthesis of control algorithms for neural prostheses that reduce the need for in-vivo testing. We further highlight implications for sparse \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:JpYjwmnXVqYC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=17315527689099129839",
        "cites_id": [
            "17315527689099129839"
        ],
        "pub_url": "https://www.frontiersin.org/articles/10.3389/fnins.2023.1141884/full",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:77MxD7EcTfAJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Behavioral assessment of the quality of speech reconstructions from intracranial neural activity",
            "pub_year": 2023,
            "citation": "Radboud Data Repository, 2023",
            "author": "Y Berezutskaya and MAJ van Gerven",
            "publisher": "Radboud Data Repository",
            "abstract": "The collection contains behavioral data for the manuscript \"Direct Speech Reconstruction from Sensorimotor Brain Activity with Optimized Deep Learning Models\". Behavioral data was collected from three experiments: a word recognition experiment (I), a speaker recognition experiment (II) and an audio quality assessment (III). The aim of the experiments was to collect human perceptual judgments of speech reconstructed from sensorimotor human brain activity."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:IyMil-iDmu0C",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=3930837870646611512",
        "cites_id": [
            "3930837870646611512"
        ],
        "pub_url": "https://repository.ubn.ru.nl/handle/2066/289544",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Gradient-adjusted incremental target propagation provides effective credit assignment in deep neural networks",
            "pub_year": 2023,
            "citation": "",
            "author": "SJPJ Dalm and Nasir Ahmad and Luca Ambrogioni and MAJ van Gerven",
            "abstract": "Many of the recent advances in the field of artificial intelligence have been fueled by the highly successful backpropagation of error (BP) algorithm, which efficiently solves the credit assignment problem in artificial neural networks. However, it is unlikely that BP is implemented in its usual form within biological neural networks, because of its reliance on non-local information in propagating error gradients. Since biological neural networks are capable of highly efficient learning and responses from BP trained models can be related to neural responses, it seems reasonable that a biologically viable approximation of BP underlies synaptic plasticity in the brain. Gradient-adjusted incremental target propagation (GAIT-prop or GP for short) has recently been derived directly from BP and has been shown to successfully train networks in a more biologically plausible manner. However, so far, GP has only been shown to work on relatively low-dimensional problems, such as handwritten-digit recognition. This work addresses some of the scaling issues in GP and shows it to perform effective multi-layer credit assignment in deeper networks and on the much more challenging ImageNet dataset."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:T-SPRlcIgBMC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=13981516798980506664",
        "cites_id": [
            "13981516798980506664"
        ],
        "pub_url": "https://repository.ubn.ru.nl/bitstream/handle/2066/292165/292165.pdf?sequence=1",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:KMRjkHNTCMIJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Advancements in spiking neural network communication and synchronization techniques for event-driven neuromorphic systems",
            "pub_year": 2023,
            "citation": "Array 20, 100323, 2023",
            "author": "Mahyar Shahsavari and David Thomas and Marcel van Gerven and Andrew Brown and Wayne Luk",
            "journal": "Array",
            "volume": "20",
            "pages": "100323",
            "publisher": "Elsevier",
            "abstract": "Neuromorphic event-driven systems emulate the computational mechanisms of the brain through the utilization of spiking neural networks (SNN). Neuromorphic systems serve two primary application domains: simulating neural information processing in neuroscience and acting as accelerators for cognitive computing in engineering applications. A distinguishing characteristic of neuromorphic systems is their asynchronous or event-driven nature, but even event-driven systems require some synchronous time management of the neuron populations to guarantee sufficient time for the proper delivery of spiking messages. In this study, we assess three distinct algorithms proposed for adding a synchronization capability to asynchronous event-driven compute systems. We run these algorithms on POETS (Partially Ordered Event-Triggered Systems), a custom-built FPGA-based hardware platform, as a neuromorphic \u2026"
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:KxNY-X0OflYC",
        "num_citations": 0,
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S2590005623000486",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Effective Learning with Node Perturbation in Deep Neural Networks",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2310.00965, 2023",
            "author": "Sander Dalm and Marcel van Gerven and Nasir Ahmad",
            "journal": "arXiv preprint arXiv:2310.00965",
            "abstract": "Backpropagation (BP) is the dominant and most successful method for training parameters of deep neural network models. However, BP relies on two computationally distinct phases, does not provide a satisfactory explanation of biological learning, and can be challenging to apply for training of networks with discontinuities or noisy node dynamics. By comparison, node perturbation (NP) proposes learning by the injection of noise into the network activations, and subsequent measurement of the induced loss change. NP relies on two forward (inference) passes, does not make use of network derivatives, and has been proposed as a model for learning in biological systems. However, standard NP is highly data inefficient and unstable due to its unguided, noise-based, activity search. In this work, we investigate different formulations of NP and relate it to the concept of directional derivatives as well as combining it with a decorrelating mechanism for layer-wise inputs. We find that a closer alignment with directional derivatives, and induction of decorrelation of inputs at every layer significantly enhances performance of NP learning making it competitive with BP."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:OVe_t5h5bhEC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2310.00965",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Deep neural networks are not a single hypothesis but a language for expressing computational hypotheses",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Tal Golan and JohnMark Taylor and Heiko Sch\u00fctt and Benjamin Peters and Rowan Paolo Sommers and Katja Seeliger and Adrien Doerig and Paul Linton and Talia Konkle and Marcel van Gerven and Konrad Kording and Blake Richards and Tim Christian Kietzmann and Grace W Lindsay and Nikolaus Kriegeskorte",
            "publisher": "PsyArXiv",
            "abstract": "An ideal vision model accounts for behavior and neurophysiology in both naturalistic conditions and designed lab experiments. Unlike psychological theories, artificial neural networks (ANNs) actually perform visual tasks and generate testable predictions for arbitrary inputs. These advantages enable ANNs to engage the entire spectrum of the evidence. Failures of particular models drive progress in a vibrant ANN research program of human vision."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:d9ydBXnamCkC",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/tr7gx/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:1VpvSvB-icIJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "End-to-end reconstruction of natural images from multi-unit recordings with Brain2Pix",
            "pub_year": 2023,
            "citation": "Sl: sn, 2023",
            "author": "L Le and P Papale and A Lozano and TM Dado and F Wang and MAJ van Gerven and PR Roelfsema and Y G\u00fc\u00e7l\u00fct\u00fcrk and U G\u00fc\u00e7l\u00fc",
            "publisher": "Sl: sn",
            "abstract": "Reconstructing naturalistic images from brain signals has been a challenging task for scientists, with successful results largely limited to large human fMRI datasets. In this study, we apply the brain2pix reconstruction model to multi-unit activity (MUA) data from the macaque brain, providing a novel extension of the model. This approach allows for investigation of information representation in different brain regions and time windows with greater spatial and temporal precision. Our results offer insights into the neural basis of visual perception, showing that V1 neurons represent texture and color, V4 neurons exhibit symmetric representations, and IT neurons reveal concept-like features. We also demonstrate that the model can be used to decode features at different layers of a neural network, with V1 more strongly correlated with initial layers and V4 and IT with deeper layers. Overall, our approach provides a valuable tool for studying brain representations in high temporal and spatial detail."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:h0mLeC6b6wcC",
        "num_citations": 0,
        "pub_url": "https://repository.ubn.ru.nl/handle/2066/297726",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Gaze-contingent processing improves mobility performance and visual orientation in simulated head-steered prosthetic vision",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.09. 18.558225, 2023",
            "author": "Jaap de Ruyter van Steveninck and Mo Nipshagen and Marcel van Gerven and Umut Guclu and Yagmur Gucluturk and Richard van Wezel",
            "journal": "bioRxiv",
            "pages": "2023.09. 18.558225",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "The enabling technology of visual prosthetics for the blind is making rapid progress. However, there are still uncertainties regarding the functional outcomes, which can depend on many design choices in the development. In visual prostheses with a head-mounted camera, a particularly challenging question is how to deal with the gaze-locked visual percept associated with spatial updating conflicts in the brain. A recently proposed compensation strategy is gaze-contingent image processing with eye-tracking, which enables natural visual scanning and reestablished spatial updating based on eye movements. The current study evaluates the benefits of gaze-contingent processing versus gaze-locked and gaze-ignored simulations in the context of mobility and orientation, using a simulated prosthetic vision paradigm with sighted subjects. Compared to gaze-locked vision, gaze-contingent processing was found to improve the speed in all experimental tasks, as well as the subjective quality of vision. Similar or further improvements were found in a control condition that ignores gaze-depended effects, a simulation that is unattainable in the clinical reality. Our results suggest that gaze-locked vision and spatial updating conflicts can be debilitating for complex visually-guided activities of daily living such as mobility and orientation. Therefore, for prospective users of head-steered prostheses with an unimpaired oculomotor system, the inclusion of a compensatory eye-tracking system is strongly endorsed."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:he8YCnfqqkoC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.09.18.558225.abstract",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Disentangling rodent behaviors to improve automated behavior recognition",
            "pub_year": 2023,
            "citation": "Frontiers in Neuroscience 17, 2023",
            "author": "Elsbeth A Van Dam and Lucas PJJ Noldus and Marcel AJ Van Gerven",
            "journal": "Frontiers in Neuroscience",
            "volume": "17",
            "publisher": "Frontiers Media SA",
            "abstract": "Automated observation and analysis of behavior is important to facilitate progress in many fields of science. Recent developments in deep learning have enabled progress in object detection and tracking, but rodent behavior recognition struggles to exceed 75\u201380% accuracy for ethologically relevant behaviors. We investigate the main reasons why and distinguish three aspects of behavior dynamics that are difficult to automate. We isolate these aspects in an artificial dataset and reproduce effects with the state-of-the-art behavior recognition models. Having an endless amount of labeled training data with minimal input noise and representative dynamics will enable research to optimize behavior recognition architectures and get closer to human-like recognition performance for behaviors with challenging dynamics."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:gQbQcM3rmFsC",
        "num_citations": 0,
        "pub_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10366600/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Brain2GAN: Feature-disentangled neural coding of visual perception in the primate brain",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.04. 26.537962, 2023",
            "author": "Thirza Dado and Paolo Papale and Antonio Lozano and Lynn Le and Feng Wang and Marcel van Gerven and Pieter Roelfsema and Ya\u011fmur G\u00fc\u00e7l\u00fct\u00fcrk and Umut G\u00fc\u00e7l\u00fc",
            "journal": "bioRxiv",
            "pages": "2023.04. 26.537962",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "A challenging goal of neural coding is to characterize the neural representations underlying visual perception. To this end, we analyzed the relationship between multi-unit activity of macaque visual cortex and latent representations of state-of-the-art deep generative models, including feature-disentangled representations of generative adversarial networks (i.e., w-latents of StyleGAN) and language-contrastive representations of latent diffusion networks (i.e., CLIP-latents of Stable Diffusion). A mass univariate neural encoding analysis of the latent representations showed that feature-disentangled representations explain increasingly more variance than the alternative representations over the ventral stream. Subsequently, a multivariate neural decoding analysis of the feature-disentangled representations resulted in state-of-the-art spatiotemporal reconstructions of visual perception. Taken together, our results not only highlight the important role of feature-disentanglement in shaping high-level neural representations underlying visual perception but also serve as an important benchmark for the future of neural coding."
        },
        "filled": true,
        "author_pub_id": "sX0ZypwAAAAJ:lrH_6YXCPtsC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.04.26.537962.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:u3DnD1Aw34wJ:scholar.google.com/",
        "cites_per_year": {}
    }
]