[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Learning Class and Domain Augmentations for Single-Source Open-Domain Generalization",
            "pub_year": 2024,
            "citation": "IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024), 2024",
            "author": "Prathmesh Bele and Valay Bundele and Avigyan Bhattacharya and Ankit Jha and Gemma Roig and Biplab Banerjee",
            "conference": "IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024)",
            "abstract": "Single-source open-domain generalization (SS-ODG) addresses the challenge of labeled source domains with supervision during training and unlabeled novel target domains during testing. The target domain includes both known classes from the source domain and samples from previously unseen classes. Existing techniques for SS-ODG primarily focus on calibrating source-domain classifiers to identify open samples in the target domain. However, these methods struggle with visually fine-grained open-closed data, often misclassifying open samples as closed-set classes. Moreover, relying solely on a single source domain restricts the model's ability to generalize. To overcome these limitations, we propose a novel framework called SODG-NET that simultaneously synthesizes novel domains and generates pseudo-open samples using a learning-based objective, in contrast to the ad-hoc mixing strategies commonly found in the literature. Our approach enhances generalization by diversifying the styles of known class samples using a novel metric criterion and generates diverse pseudo-open samples to train a unified and confident multiclass classifier capable of handling both open and closed-set data. Extensive experimental evaluations conducted on multiple benchmarks consistently demonstrate the superior performance of SODG-NET compared to the literature."
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:LPZeul_q3PIC",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=11623768662499945829",
        "cites_id": [
            "11623768662499945829"
        ],
        "pub_url": "https://openaccess.thecvf.com/content/WACV2024/html/Bele_Learning_Class_and_Domain_Augmentations_for_Single-Source_Open-Domain_Generalization_WACV_2024_paper.html",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:ZW2gXwPsT6EJ:scholar.google.com/",
        "cites_per_year": {
            "2024": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Learning Object Semantic Similarity with Self-Supervision",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2405.05143, 2024",
            "author": "Arthur Aubret and Timothy Schauml\u00f6ffel and Gemma Roig and Jochen Triesch",
            "journal": "arXiv preprint arXiv:2405.05143",
            "abstract": "Humans judge the similarity of two objects not just based on their visual appearance but also based on their semantic relatedness. However, it remains unclear how humans learn about semantic relationships between objects and categories. One important source of semantic knowledge is that semantically related objects frequently co-occur in the same context. For instance, forks and plates are perceived as similar, at least in part, because they are often experienced together in a ``kitchen\" or ``eating'' context. Here, we investigate whether a bio-inspired learning principle exploiting such co-occurrence statistics suffices to learn a semantically structured object representation {\\em de novo} from raw visual or combined visual and linguistic input. To this end, we simulate temporal sequences of visual experience by binding together short video clips of real-world scenes showing objects in different contexts. A bio-inspired neural network model aligns close-in-time visual representations while also aligning visual and category label representations to simulate visuo-language alignment. Our results show that our model clusters object representations based on their context, e.g. kitchen or bedroom, in particular in high-level layers of the network, akin to humans. In contrast, lower-level layers tend to better reflect object identity or category. To achieve this, the model exploits two distinct strategies: the visuo-language alignment ensures that different objects of the same category are represented similarly, whereas the temporal alignment leverages that objects from the same context are frequently seen in succession to make their representations more similar \u2026"
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:bnK-pcrLprsC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2405.05143",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Rrh2pJS9U5gJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Large Language Model-Informed X-ray Photoelectron Spectroscopy Data Analysis",
            "pub_year": 2024,
            "citation": "Signals 5 (2), 181-201, 2024",
            "author": "J de Curt\u00f2 and I de Zarz\u00e0 and Gemma Roig and Carlos T Calafate",
            "journal": "Signals",
            "volume": "5",
            "number": "2",
            "pages": "181-201",
            "publisher": "MDPI",
            "abstract": "X-ray photoelectron spectroscopy (XPS) remains a fundamental technique in materials science, offering invaluable insights into the chemical states and electronic structure of a material. However, the interpretation of XPS spectra can be complex, requiring deep expertise and often sophisticated curve-fitting methods. In this study, we present a novel approach to the analysis of XPS data, integrating the utilization of large language models (LLMs), specifically OpenAI\u2019s GPT-3.5/4 Turbo to provide insightful guidance during the data analysis process. Working in the framework of the CIRCE-NAPP beamline at the CELLS ALBA Synchrotron facility where data are obtained using ambient pressure X-ray photoelectron spectroscopy (APXPS), we implement robust curve-fitting techniques on APXPS spectra, highlighting complex cases including overlapping peaks, diverse chemical states, and noise presence. Post curve fitting, we engage the LLM to facilitate the interpretation of the fitted parameters, leaning on its extensive training data to simulate an interaction corresponding to expert consultation. The manuscript presents also a real use case utilizing GPT-4 and Meta\u2019s LLaMA-2 and describes the integration of the functionality into the TANGO control system. Our methodology not only offers a fresh perspective on XPS data analysis, but also introduces a new dimension of artificial intelligence (AI) integration into scientific research. It showcases the power of LLMs in enhancing the interpretative process, particularly in scenarios wherein expert knowledge may not be immediately available. Despite the inherent limitations of LLMs, their potential in the realm \u2026"
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:q3oQSFYPqjQC",
        "num_citations": 0,
        "pub_url": "https://repositorio.comillas.edu/xmlui/handle/11531/88134",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:YHV1UUyYUYoJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Visual features are processed before navigational affordances in the human brain",
            "pub_year": 2024,
            "citation": "Scientific Reports 14 (1), 5573, 2024",
            "author": "Kshitij Dwivedi and Sari Sadiya and Marta P Balode and Gemma Roig and Radoslaw M Cichy",
            "journal": "Scientific Reports",
            "volume": "14",
            "number": "1",
            "pages": "5573",
            "publisher": "Nature Publishing Group UK",
            "abstract": "To navigate through their immediate environment humans process scene information rapidly. How does the cascade of neural processing elicited by scene viewing to facilitate navigational planning unfold over time? To investigate, we recorded human brain responses to visual scenes with electroencephalography and related those to computational models that operationalize three aspects of scene processing (2D, 3D, and semantic information), as well as to a behavioral model capturing navigational affordances. We found a temporal processing hierarchy: navigational affordance is processed later than the other scene features (2D, 3D, and semantic) investigated. This reveals the temporal order with which the human brain computes complex scene information and suggests that the brain leverages these pieces of information to plan navigation."
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:K3LRdlH-MEoC",
        "num_citations": 0,
        "pub_url": "https://www.nature.com/articles/s41598-024-55652-y",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:n4m83mKPkEkJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Generative Adversarial Collaborations: A practical guide for conference organizers and participating scientists",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2402.12604, 2024",
            "author": "Gunnar Blohm and Benjamin Peters and Ralf Haefner and Leyla Isik and Nikolaus Kriegeskorte and Jennifer S Lieberman and Carlos R Ponce and Gemma Roig and Megan AK Peters",
            "journal": "arXiv preprint arXiv:2402.12604",
            "abstract": "Generative adversarial collaborations (GACs) are a form of formal teamwork between groups of scientists with diverging views. The goal of GACs is to identify and ultimately resolve the most important challenges, controversies, and exciting theoretical and empirical debates in a given research field. A GAC team would develop specific, agreed-upon avenues to resolve debates in order to move a field of research forward in a collaborative way. Such adversarial collaborations have many benefits and opportunities but also come with challenges. Here, we use our experience from (1) creating and running the GAC program for the Cognitive Computational Neuroscience (CCN) conference and (2) implementing and leading GACs on particular scientific problems to provide a practical guide for future GAC program organizers and leaders of individual GACs."
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:BrmTIyaxlBUC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2402.12604",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:uxFImCCXViEJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Position: An Inner Interpretability Framework for AI Inspired by Lessons from Cognitive Neuroscience",
            "pub_year": 2024,
            "citation": "Forty-first International Conference on Machine Learning, 2024",
            "author": "Martina G Vilas and Federico Adolfi and David Poeppel and Gemma Roig",
            "conference": "Forty-first International Conference on Machine Learning",
            "abstract": "Inner Interpretability is a promising emerging field tasked with uncovering the inner mechanisms of AI systems, though how to develop these mechanistic theories is still much debated. Moreover, recent critiques raise issues that question its usefulness to advance the broader goals of AI. However, it has been overlooked that these issues resemble those that have been grappled with in another field: Cognitive Neuroscience. Here we draw the relevant connections and highlight lessons that can be transferred productively between fields. Based on these, we propose a general conceptual framework and give concrete methodological strategies for building mechanistic explanations in AI inner interpretability research. With this conceptual framework, Inner Interpretability can fend off critiques and position itself on a productive path to explain AI systems."
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:AXPGKjj_ei8C",
        "num_citations": 0,
        "pub_url": "https://openreview.net/forum?id=66KmnMhGU5",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:pKAMPZ0qGV0J:scholar.google.com/",
        "cites_per_year": {}
    }
]