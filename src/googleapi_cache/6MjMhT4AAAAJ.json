[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The algonauts project 2023 challenge: How the human brain makes sense of natural scenes",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2301.03198, 2023",
            "author": "Alessandro T Gifford and Benjamin Lahner and Sari Saba-Sadiya and Martina G Vilas and Alex Lascelles and Aude Oliva and Kendrick Kay and Gemma Roig and Radoslaw M Cichy",
            "journal": "arXiv preprint arXiv:2301.03198",
            "abstract": "The sciences of biological and artificial intelligence are ever more intertwined. Neural computational principles inspire new intelligent machines, which are in turn used to advance theoretical understanding of the brain. To promote further exchange of ideas and collaboration between biological and artificial intelligence researchers, we introduce the 2023 installment of the Algonauts Project challenge: How the Human Brain Makes Sense of Natural Scenes (http://algonauts.csail.mit.edu). This installment prompts the fields of artificial and biological intelligence to come together towards building computational models of the visual brain using the largest and richest dataset of fMRI responses to visual scenes, the Natural Scenes Dataset (NSD). NSD provides high-quality fMRI responses to ~73,000 different naturalistic colored scenes, making it the ideal candidate for data-driven model building approaches promoted by the 2023 challenge. The challenge is open to all and makes results directly comparable and transparent through a public leaderboard automatically updated after each submission, thus allowing for rapid model development. We believe that the 2023 installment will spark symbiotic collaborations between biological and artificial intelligence scientists, leading to a deeper understanding of the brain through cutting-edge computational models and to novel ways of engineering artificial intelligent agents through inductive biases from biological systems."
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:KxtntwgDAa4C",
        "num_citations": 7,
        "citedby_url": "/scholar?hl=en&cites=1174422521076802658",
        "cites_id": [
            "1174422521076802658"
        ],
        "pub_url": "https://arxiv.org/abs/2301.03198",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:YmQAgQ9jTBAJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 7
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "EmoMV: Affective Music-Video Correspondence Learning Datasets for Classification and Retrieval",
            "pub_year": 2023,
            "citation": "Information Fusion 91, 64-79, 2023",
            "author": "Ha Thi Phuong Thao and Dorien Herremans and Gemma Roig",
            "journal": "Information Fusion",
            "volume": "91",
            "pages": "64-79",
            "publisher": "Elsevier",
            "abstract": "Studies in affective audio\u2013visual correspondence learning require ground-truth data to train, validate, and test models. The number of available datasets together with benchmarks, however, is still limited. In this paper, we create a collection of three datasets (called EmoMV) for affective correspondence learning between music and video modalities. The first two datasets (called EmoMV-A, and EmoMV-B, respectively) are constructed by making use of music video segments from other available datasets. The third one called EmoMV-C is created from music videos that we self-collected from YouTube. The music-video pairs in our datasets are annotated as matched or mismatched in terms of the emotions they are conveying. The emotions are annotated by humans in the EmoMV-A dataset, while in the EmoMV-B and EmoMV-C datasets they are predicted using a pretrained deep neural network. A user study is carried \u2026"
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:CHSYGLWDkRkC",
        "num_citations": 5,
        "citedby_url": "/scholar?hl=en&cites=10100485155605414894",
        "cites_id": [
            "10100485155605414894"
        ],
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S1566253522001725",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:7oP3_rshLIwJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 4
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Emergent Cooperation and Strategy Adaptation in Multi-Agent Systems: An Extended Coevolutionary Theory with LLMs",
            "pub_year": 2023,
            "citation": "Electronics 12 (12), 2722, 2023",
            "author": "I de Zarz\u00e0 and J de Curt\u00f2 and Gemma Roig and Pietro Manzoni and Carlos T Calafate",
            "journal": "Electronics",
            "volume": "12",
            "number": "12",
            "pages": "2722",
            "publisher": "MDPI",
            "abstract": "The increasing complexity of Multi-Agent Systems (MASs), coupled with the emergence of Artificial Intelligence (AI) and Large Language Models (LLMs), have highlighted significant gaps in our understanding of the behavior and interactions of diverse entities within dynamic environments. Traditional game theory approaches have often been employed in this context, but their utility is limited by the static and homogenous nature of their models. With the transformative influence of AI and LLMs on business and society, a more dynamic and nuanced theoretical framework is necessary to guide the design and management of MASs. In response to this pressing need, we propose an Extended Coevolutionary (EC) Theory in this paper. This alternative framework incorporates key aspects of coevolutionary dynamics, adaptive learning, and LLM-based strategy recommendations to model and analyze the strategic interactions among heterogeneous agents in MASs. It goes beyond game theory by acknowledging and addressing the diverse interactions (economic transactions, social relationships, information exchange) and the variability in risk aversion, social preferences, and learning capabilities among entities. To validate the effectiveness of the EC framework, we developed a simulation environment that enabled us to explore the emergence of cooperation and defection patterns in MASs. The results demonstrated the potential of our framework to promote cooperative behavior and maintain robustness in the face of disruptions. The dynamics and evolution of the Multi-Agent System over time were also visualized using advanced techniques. Our \u2026"
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:u9iWguZQMMsC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=10624256355472113045",
        "cites_id": [
            "10624256355472113045"
        ],
        "pub_url": "https://www.mdpi.com/2079-9292/12/12/2722",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:lf2Zlt3wcJMJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 3
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Signature and log-signature for the study of empirical distributions generated with GANs",
            "pub_year": 2023,
            "citation": "Electronics 12 (10), 2192, 2023",
            "author": "Joaquim de Curt\u00f2 and Irene de Zarz\u00e0 and Gemma Roig and Carlos T Calafate",
            "journal": "Electronics",
            "volume": "12",
            "number": "10",
            "pages": "2192",
            "publisher": "MDPI",
            "abstract": "In this paper, we address the research gap in efficiently assessing Generative Adversarial Network (GAN) convergence and goodness of fit by introducing the application of the Signature Transform to measure similarity between image distributions. Specifically, we propose the novel use of Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) Signature, along with Log-Signature, as alternatives to existing methods such as Fr\u00e9chet Inception Distance (FID) and Multi-Scale Structural Similarity Index Measure (MS-SSIM). Our approach offers advantages in terms of efficiency and effectiveness, providing a comprehensive understanding and extensive evaluations of GAN convergence and goodness of fit. Furthermore, we present innovative analytical measures based on statistics by means of Kruskal\u2013Wallis to evaluate the goodness of fit of GAN sample distributions. Unlike existing GAN measures, which are based on deep neural networks and require extensive GPU computations, our approach significantly reduces computation time and is performed on the CPU while maintaining the same level of accuracy. Our results demonstrate the effectiveness of the proposed method in capturing the intrinsic structure of the generated samples, providing meaningful insights into GAN performance. Lastly, we evaluate our approach qualitatively using Principal Component Analysis (PCA) and adaptive t-Distributed Stochastic Neighbor Embedding (t-SNE) for data visualization, illustrating the plausibility of our method."
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:WbkHhVStYXYC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=14142471096293437390",
        "cites_id": [
            "14142471096293437390"
        ],
        "pub_url": "https://www.mdpi.com/2079-9292/12/10/2192",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:zq_MNIgmRMQJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 2,
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "LLM-Informed Multi-Armed Bandit Strategies for Non-Stationary Environments",
            "pub_year": 2023,
            "citation": "Electronics 12 (13), 2814, 2023",
            "author": "J de Curt\u00f2 and I de Zarz\u00e0 and Gemma Roig and Juan Carlos Cano and Pietro Manzoni and Carlos T Calafate",
            "journal": "Electronics",
            "volume": "12",
            "number": "13",
            "pages": "2814",
            "publisher": "MDPI",
            "abstract": "In this paper, we introduce an innovative approach to handling the multi-armed bandit (MAB) problem in non-stationary environments, harnessing the predictive power of large language models (LLMs). With the realization that traditional bandit strategies, including epsilon-greedy and upper confidence bound (UCB), may struggle in the face of dynamic changes, we propose a strategy informed by LLMs that offers dynamic guidance on exploration versus exploitation, contingent on the current state of the bandits. We bring forward a new non-stationary bandit model with fluctuating reward distributions and illustrate how LLMs can be employed to guide the choice of bandit amid this variability. Experimental outcomes illustrate the potential of our LLM-informed strategy, demonstrating its adaptability to the fluctuating nature of the bandit problem, while maintaining competitive performance against conventional strategies. This study provides key insights into the capabilities of LLMs in enhancing decision-making processes in dynamic and uncertain scenarios."
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:738O_yMBCRsC",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=14955449359568500186",
        "cites_id": [
            "14955449359568500186"
        ],
        "pub_url": "https://www.mdpi.com/2079-9292/12/13/2814",
        "cites_per_year": {
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "LLM Adaptive PID Control for B5G Truck Platooning Systems",
            "pub_year": 2023,
            "citation": "Sensors 23 (13), 5899, 2023",
            "author": "I de Zarz\u00e0 and J de Curt\u00f2 and Gemma Roig and Carlos T Calafate",
            "journal": "Sensors",
            "volume": "23",
            "number": "13",
            "pages": "5899",
            "publisher": "MDPI",
            "abstract": "This paper presents an exploration into the capabilities of an adaptive PID controller within the realm of truck platooning operations, situating the inquiry within the context of Cognitive Radio and AI-enhanced 5G and Beyond 5G (B5G) networks. We developed a Deep Learning (DL) model that emulates an adaptive PID controller, taking into account the implications of factors such as communication latency, packet loss, and communication range, alongside considerations of reliability, robustness, and security. Furthermore, we harnessed a Large Language Model (LLM), GPT-3.5-turbo, to deliver instantaneous performance updates to the PID system, thereby elucidating its potential for incorporation into AI-enabled radio and networks. This research unveils crucial insights for augmenting the performance and safety parameters of vehicle platooning systems within B5G networks, concurrently underlining the prospective applications of LLMs within such technologically advanced communication environments."
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:Tiz5es2fbqcC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=8511345799558055843",
        "cites_id": [
            "8511345799558055843"
        ],
        "pub_url": "https://www.mdpi.com/1424-8220/23/13/5899",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Summarization of Videos with the Signature Transform",
            "pub_year": 2023,
            "citation": "Electronics 12 (7), 1735, 2023",
            "author": "Joaquim de Curt\u00f2 and Irene de Zarz\u00e0 and Gemma Roig and Carlos T Calafate",
            "journal": "Electronics",
            "volume": "12",
            "number": "7",
            "pages": "1735",
            "publisher": "MDPI",
            "abstract": "This manuscript presents a new benchmark for assessing the quality of visual summaries without the need for human annotators. It is based on the Signature Transform, specifically focusing on the RMSE and the MAE Signature and Log-Signature metrics, and builds upon the assumption that uniform random sampling can offer accurate summarization capabilities. We provide a new dataset comprising videos from Youtube and their corresponding automatic audio transcriptions. Firstly, we introduce a preliminary baseline for automatic video summarization, which has at its core a Vision Transformer, an image\u2013text model pre-trained with Contrastive Language\u2013Image Pre-training (CLIP), as well as a module of object detection. Following that, we propose an accurate technique grounded in the harmonic components captured by the Signature Transform, which delivers compelling accuracy. The analytical measures are extensively evaluated, and we conclude that they strongly correlate with the notion of a good summary."
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:p2g8aNsByqUC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=11618654879579509463",
        "cites_id": [
            "11618654879579509463"
        ],
        "pub_url": "https://www.mdpi.com/2079-9292/12/7/1735",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:1xIyAQ7BPaEJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Visual features are processed before navigational affordances in the human brain",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.06. 27.546695, 2023",
            "author": "Kshitij Dwivedi and Sari Sadiya and Marta P Balode and Gemma Roig and Radoslaw Cichy",
            "journal": "bioRxiv",
            "pages": "2023.06. 27.546695",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "To navigate through their immediate environment humans process scene information rapidly. How does the cascade of neural processing elicited by scene viewing to facilitate navigational planning unfold over time? To investigate, we recorded human brain responses to visual scenes with electroencephalography (EEG) and related those to computational models that operationalize three aspects of scene processing (2D, 3D, and semantic information), as well as to a behavioral model capturing navigational affordances. We found a temporal processing hierarchy: navigational affordance is processed later than the other scene features (2D, 3D, and semantic) investigated. This reveals the temporal order with which the human brain computes complex scene information and suggests that the brain leverages these pieces of information to plan navigation."
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:K3LRdlH-MEoC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.06.27.546695.abstract",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "BOLD Moments: modeling short visual events through a video fMRI dataset and metadata",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.03. 12.530887, 2023",
            "author": "Benjamin Lahner and Kshitij Dwivedi and Polina Iamshchinina and Monika Graumann and Alex Lascelles and Gemma Roig and Alessandro Thomas Gifford and Bowen Pan and SouYoung Jin and N Apurva Ratan Murty and Kendrick Kay and Aude Oliva and Radoslaw Cichy",
            "journal": "bioRxiv",
            "pages": "2023.03. 12.530887",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Grasping the meaning of everyday visual events is a fundamental feat of human intelligence that hinges on diverse neural processes ranging from vision to higher-level cognition. Deciphering the neural basis of visual event understanding requires rich, extensive, and appropriately designed experimental data. However, this type of data is hitherto missing. To fill this gap, we introduce the BOLD Moments Dataset (BMD), a large dataset of whole-brain fMRI responses to over 1,000 short (3s) naturalistic video clips and accompanying metadata. We show visual events interface with an array of processes, extending even to memory, and we reveal a match in hierarchical processing between brains and video-computable deep neural networks. Furthermore, we showcase that BMD successfully captures temporal dynamics of visual events at second resolution. BMD thus establishes a critical groundwork for investigations of the neural basis of visual event understanding."
        },
        "filled": true,
        "author_pub_id": "6MjMhT4AAAAJ:OU6Ihb5iCvQC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.03.12.530887.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:jESFCRR-e_wJ:scholar.google.com/",
        "cites_per_year": {}
    }
]