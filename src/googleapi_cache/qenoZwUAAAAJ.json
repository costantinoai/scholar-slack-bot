[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Robustified anns reveal wormholes between human category percepts",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2308.06887, 2023",
            "author": "Guy Gaziv and Michael J Lee and James J DiCarlo",
            "journal": "arXiv preprint arXiv:2308.06887",
            "abstract": "The visual object category reports of artificial neural networks (ANNs) are notoriously sensitive to tiny, adversarial image perturbations. Because human category reports (aka human percepts) are thought to be insensitive to those same small-norm perturbations -- and locally stable in general -- this argues that ANNs are incomplete scientific models of human visual perception. Consistent with this, we show that when small-norm image perturbations are generated by standard ANN models, human object category percepts are indeed highly stable. However, in this very same \"human-presumed-stable\" regime, we find that robustified ANNs reliably discover low-norm image perturbations that strongly disrupt human percepts. These previously undetectable human perceptual disruptions are massive in amplitude, approaching the same level of sensitivity seen in robustified ANNs. Further, we show that robustified ANNs support precise perceptual state interventions: they guide the construction of low-norm image perturbations that strongly alter human category percepts toward specific prescribed percepts. These observations suggest that for arbitrary starting points in image space, there exists a set of nearby \"wormholes\", each leading the subject from their current category perceptual state into a semantically very different state. Moreover, contemporary ANN models of biological visual processing are now accurate enough to consistently guide us to those portals."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:uc_IGeMz5qoC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=2862317547848986815",
        "cites_id": [
            "2862317547848986815"
        ],
        "pub_url": "https://arxiv.org/abs/2308.06887",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "How well do rudimentary plasticity rules predict adult visual object learning?",
            "pub_year": 2023,
            "citation": "PLOS Computational Biology 19 (12), e1011713, 2023",
            "author": "Michael J Lee and James J DiCarlo",
            "journal": "PLOS Computational Biology",
            "volume": "19",
            "number": "12",
            "pages": "e1011713",
            "publisher": "Public Library of Science",
            "abstract": "A core problem in visual object learning is using a finite number of images of a new object to accurately identify that object in future, novel images.One longstanding, conceptual hypothesis asserts that this core problem is solved by adult brains through two connected mechanisms: 1) the re-representation of incoming retinal images as points in a fixed, multidimensional neural space, and 2) the optimization of linear decision boundaries in that space, via simple plasticity rules applied to a single downstream layer.Though this scheme is biologically plausible, the extent to which it explains learning behavior in humans has been unclear\u2014in part because of a historical lack of image-computable models of the putative neural space, and in part because of a lack of measurements of human learning behaviors in difficult, naturalistic settings.Here, we addressed these gaps by 1) drawing from contemporary, image-computable models of the primate ventral visual stream to create a large set of testable learning models (n = 2,408 models), and 2) using online psychophysics to measure human learning trajectories over a varied set of tasks involving novel 3D objects (n = 371,000 trials), which we then used to develop (and publicly release) empirical benchmarks for comparing learning models to humans.We evaluated each learning model on these benchmarks, and found those based on deep, high-level representations from neural networks were surprisingly aligned with human behavior. While no tested model explained the entirety of replicable human behavior, these results establish that rudimentary plasticity rules, when combined with appropriate \u2026"
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:vDijr-p_gm4C",
        "num_citations": 0,
        "pub_url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011713",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The Quest for an Integrated Set of Neural Mechanisms Underlying Object Recognition in Primates",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2312.05956, 2023",
            "author": "Kohitij Kar and James J DiCarlo",
            "journal": "arXiv preprint arXiv:2312.05956",
            "abstract": "Visual object recognition -- the behavioral ability to rapidly and accurately categorize many visually encountered objects -- is core to primate cognition. This behavioral capability is algorithmically impressive because of the myriad identity-preserving viewpoints and scenes that dramatically change the visual image produced by the same object. Until recently, the brain mechanisms that support that capability were deeply mysterious. However, over the last decade, this scientific mystery has been illuminated by the discovery and development of brain-inspired, image-computable, artificial neural network (ANN) systems that rival primates in this behavioral feat. Apart from fundamentally changing the landscape of artificial intelligence (AI), modified versions of these ANN systems are the current leading scientific hypotheses of an integrated set of mechanisms in the primate ventral visual stream that support object recognition. What separates brain-mapped versions of these systems from prior conceptual models is that they are Sensory-computable, Mechanistic, Anatomically Referenced, and Testable (SMART). Here, we review and provide perspective on the brain mechanisms that the currently leading SMART models address. We review the empirical brain and behavioral alignment successes and failures of those current models. Given ongoing advances in neurobehavioral measurements and AI, we discuss the next frontiers for even more accurate mechanistic understanding. And we outline the likely applications of that SMART-model-based understanding."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:uWiczbcajpAC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2312.05956",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Probing Biological and Artificial Neural Networks with Task-dependent Neural Manifolds",
            "pub_year": 2023,
            "citation": "Conference on Parsimony and Learning (Proceedings Track), 2023",
            "author": "Michael Kuoch and Chi-Ning Chou and Nikhil Parthasarathy and Joel Dapello and James J DiCarlo and Haim Sompolinsky and SueYeon Chung",
            "conference": "Conference on Parsimony and Learning (Proceedings Track)",
            "abstract": "In recent years, growth in our understanding of the computations performed in both biological and artificial neural networks has largely been driven by either low-level mechanistic studies or global normative approaches. However, concrete methodologies for bridging the gap between these levels of abstraction remain elusive. In this work, we investigate the internal mechanisms of neural networks through the lens of neural population geometry, aiming to provide understanding at an intermediate level of abstraction, as a way to bridge that gap. Utilizing manifold capacity theory (MCT) from statistical physics and manifold alignment analysis (MAA) from high-dimensional statistics, we probe the underlying organization of task-dependent manifolds in deep neural networks and neural recordings from the macaque visual cortex. Specifically, we quantitatively characterize how different learning objectives lead to differences in the organizational strategies of these models and demonstrate how these geometric analyses are connected to the decodability of task-relevant information. Furthermore, these metrics show that macaque visual cortex data are more similar to unsupervised DNNs in terms of geometrical properties such as manifold position and manifold alignment. These analyses present a strong direction for bridging mechanistic and normative theories in neural networks through neural population geometry, potentially opening up many future research avenues in both machine learning and neuroscience."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:epqYDVWIO7EC",
        "num_citations": 0,
        "pub_url": "https://openreview.net/forum?id=MxBS6aw5Gd",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Let's move forward: Image-computable models and a common model evaluation scheme are prerequisites for a scientific understanding of human vision",
            "pub_year": 2023,
            "citation": "Behavioral and Brain Sciences 46, e390, 2023",
            "author": "James J DiCarlo and Daniel LK Yamins and Michael E Ferguson and Evelina Fedorenko and Matthias Bethge and Tyler Bonnen and Martin Schrimpf",
            "journal": "Behavioral and Brain Sciences",
            "volume": "46",
            "pages": "e390",
            "publisher": "Cambridge University Press",
            "abstract": "In the target article, Bowers et al. dispute deep artificial neural network (ANN) models as the currently leading models of human vision without producing alternatives. They eschew the use of public benchmarking platforms to compare vision models with the brain and behavior, and they advocate for a fragmented, phenomenon-specific modeling approach. These are unconstructive to scientific progress. We outline how the Brain-Score community is moving forward to add new model-to-human comparisons to its community-transparent suite of benchmarks."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:zLWjf1WUPmwC",
        "num_citations": 0,
        "pub_url": "https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/lets-move-forward-imagecomputable-models-and-a-common-model-evaluation-scheme-are-prerequisites-for-a-scientific-understanding-of-human-vision/F2302912C8652DC2582F0E159C1BB6AB",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Software and methods for controlling neural responses in deep brain regions",
            "pub_year": 2023,
            "citation": "US Patent 11,813,406, 2023",
            "author": "James Dicarlo and Pouya Bashivan and Kohitij Kar",
            "abstract": "Techniques for non-invasively controlling targeted neural activity of a subject are provided herein. The techniques include applying a stimulus input to the subject, the stimulus input being formed by a deep artificial neural network (ANN) model and being configured to elicit targeted neural activity within a brain of the subject. The stimulus input may be a pattern of luminous power generated by the deep ANN model and applied to retinae of the subject. The stimulus input may be generated by the deep ANN model based on a mapping of the subject's neural responses to neurons of the deep ANN model."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:1qzjygNMrQYC",
        "num_citations": 0,
        "pub_url": "https://patents.google.com/patent/US11813406B2/en",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Catalyzing next-generation artificial intelligence through neuroai",
            "pub_year": 2023,
            "citation": "Nature communications 14 (1), 1597, 2023",
            "author": "Anthony Zador and Sean Escola and Blake Richards and Bence \u00d6lveczky and Yoshua Bengio and Kwabena Boahen and Matthew Botvinick and Dmitri Chklovskii and Anne Churchland and Claudia Clopath and James DiCarlo and Surya Ganguli and Jeff Hawkins and Konrad K\u00f6rding and Alexei Koulakov and Yann LeCun and Timothy Lillicrap and Adam Marblestone and Bruno Olshausen and Alexandre Pouget and Cristina Savin and Terrence Sejnowski and Eero Simoncelli and Sara Solla and David Sussillo and Andreas S Tolias and Doris Tsao",
            "volume": "14",
            "number": "1",
            "pages": "1597",
            "publisher": "Nature Publishing Group UK",
            "abstract": "Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities \u2013 inherited from over 500 million years of evolution \u2013 that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:VLnqNzywnoUC",
        "num_citations": 45,
        "citedby_url": "/scholar?hl=en&cites=7012396176970419900",
        "cites_id": [
            "7012396176970419900"
        ],
        "pub_url": "https://www.nature.com/articles/s41467-023-37180-x",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:vA6hcCsJUWEJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 42
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "A Unifying Principle for the Functional Organization of Visual Cortex",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.05. 18.541361, 2023",
            "author": "Eshed Margalit and Hyodong Lee and Dawn Finzi and James J DiCarlo and Kalanit Grill-Spector and Daniel LK Yamins",
            "journal": "bioRxiv",
            "pages": "2023.05. 18.541361",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "A key feature of many cortical systems is functional organization: the arrangement of neurons with specific functional properties in characteristic spatial patterns across the cortical surface. However, the principles underlying the emergence and utility of functional organization are poorly understood. Here we develop the Topographic Deep Artificial Neural Network (TDANN), the first unified model to accurately predict the functional organization of multiple cortical areas in the primate visual system. We analyze the key factors responsible for the TDANN's success and find that it strikes a balance between two specific objectives: achieving a task-general sensory representation that is self-supervised, and maximizing the smoothness of responses across the cortical sheet according to a metric that scales relative to cortical surface area. In turn, the representations learned by the TDANN are lower dimensional and more brain-like than those in models that lack a spatial smoothness constraint. Finally, we provide evidence that the TDANN's functional organization balances performance with inter-area connection length, and use the resulting models for a proof-of-principle optimization of cortical prosthetic design. Our results thus offer a unified principle for understanding functional organization and a novel view of the functional role of the visual system in particular."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:nrtMV_XWKgEC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=615012094074270269",
        "cites_id": [
            "615012094074270269"
        ],
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.05.18.541361.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:PbLdtz32iAgJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "An empirical assay of view-invariant object learning in humans and comparison with baseline image-computable models",
            "pub_year": 2023,
            "citation": "bioRxiv, 2022.12. 31.522402, 2023",
            "author": "Michael J Lee and James J DiCarlo",
            "journal": "bioRxiv",
            "pages": "2022.12. 31.522402",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "How humans learn new visual objects is a longstanding scientific problem. Previous work has led to a diverse collection of models for how it is accomplished, but a current limitation in the field is a lack of empirical benchmarks which can be used to evaluate and compare specific models against each other. Here, we use online psychophysics to measure human behavioral learning trajectories over a set of tasks involving novel 3D objects. Consistent with intuition, these results show that humans generally require very few images (~ 6) to approach their asymptotic accuracy, find some object discriminations more easy to learn than others, and generalize quite well over a range of image transformations after even one view of each object. We then use those data to develop benchmarks that may be used to evaluate a learning model's similarity to humans. We make these data and benchmarks publicly available [http://www.github.com/mlee3142/hobj], and, to our knowledge, they are currently the largest publicly-available collection of learning-related psychophysics data in humans. Additionally, to serve as baselines for those benchmarks, we implement and test a large number of baseline models (n=1,932), each based on a standard cognitive theory of learning: that humans re-represent images in a fixed, Euclidean space, then learn linear decision boundaries in that space to identify objects in future images. We find some of these baseline models make surprisingly accurate predictions. However, we also find reliable prediction gaps between all baseline models and humans, particularly in the few-shot learning setting."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:fEOibwPWpKIC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=11538048138746159234",
        "cites_id": [
            "11538048138746159234"
        ],
        "pub_url": "https://www.biorxiv.org/content/10.1101/2022.12.31.522402.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:gmBSp6ZhH6AJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Strong and Precise Modulation of Human Percepts via Robustified ANNs",
            "pub_year": 2023,
            "citation": "Thirty-seventh Conference on Neural Information Processing Systems, 2023",
            "author": "Guy Gaziv and Michael J Lee and James J DiCarlo",
            "conference": "Thirty-seventh Conference on Neural Information Processing Systems",
            "abstract": "The visual object category reports of artificial neural networks (ANNs) are notoriously sensitive to tiny, adversarial image perturbations. Because human category reports (aka human percepts) are thought to be insensitive to those same small-norm perturbations -- and locally stable in general -- this argues that ANNs are incomplete scientific models of human visual perception. Consistent with this, we show that when small-norm image perturbations are generated by standard ANN models, human object category percepts are indeed highly stable.  However, in this very same \"human-presumed-stable\" regime, we find that robustified ANNs reliably discover low-norm image perturbations that strongly disrupt human percepts. These previously undetectable human perceptual disruptions are massive in amplitude, approaching the same level of sensitivity seen in robustified ANNs.  Further, we show that robustified ANNs support precise perceptual state interventions: they guide the construction of low-norm image perturbations that strongly alter human category percepts toward specific prescribed percepts.  In sum, these contemporary models of biological visual processing are now accurate enough to guide strong and precise interventions on human perception."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:EkHepimYqZsC",
        "num_citations": 0,
        "pub_url": "https://openreview.net/forum?id=5GmTI4LNqX",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Robustified ANNs Reveal Wormholes Between Human Category Percepts",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2308.06887, 2023",
            "author": "Guy Gaziv and Michael J Lee and James J DiCarlo",
            "journal": "arXiv preprint arXiv:2308.06887",
            "abstract": "The visual object category reports of artificial neural networks (ANNs) are notoriously sensitive to tiny, adversarial image perturbations. Because human category reports (aka human percepts) are thought to be insensitive to those same small-norm perturbations -- and locally stable in general -- this argues that ANNs are incomplete scientific models of human visual perception. Consistent with this, we show that when small-norm image perturbations are generated by standard ANN models, human object category percepts are indeed highly stable. However, in this very same \"human-presumed-stable\" regime, we find that robustified ANNs reliably discover low-norm image perturbations that strongly disrupt human percepts. These previously undetectable human perceptual disruptions are massive in amplitude, approaching the same level of sensitivity seen in robustified ANNs. Further, we show that robustified ANNs support precise perceptual state interventions: they guide the construction of low-norm image perturbations that strongly alter human category percepts toward specific prescribed percepts. These observations suggest that for arbitrary starting points in image space, there exists a set of nearby \"wormholes\", each leading the subject from their current category perceptual state into a semantically very different state. Moreover, contemporary ANN models of biological visual processing are now accurate enough to consistently guide us to those portals."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:uc_IGeMz5qoC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2308.06887",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "fROI-level computational models enable broad-scale experimental testing and expose key divergences between models and brains",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5788-5788, 2023",
            "author": "Elizabeth Mieczkowski and Alex Abate and Willian De Faria and Kirsten Lydic and James DiCarlo and Nancy Kanwisher and N Apurva Ratan Murty",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5788-5788",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Deep convolutional neural network (DNN)-based models have emerged as our leading hypotheses of human vision. Here we describe, and expand upon, our latest effort to use DNN models of brain regions to explain key results from previous cognitive neuroscience and psychology experiments. Many stimuli in these prior experiments were highly manipulated (eg scrambled body parts, face parts, re-arranged spatial positions) often outside the domain of natural stimuli. These results can therefore be considered as tests of model generalization beyond naturalistic stimuli. We first performed these tests on the fusiform face area (FFA), parahippocampal place area (PPA) and the extrastriate body area (EBA). Our previous results (presented in VSS2022) showed that our fROI-level models recapitulate several key results from prior studies. We also observed that models did not perform as well on non-naturalistic stimuli \u2026"
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:ipzZ9siozwsC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2792491",
        "cites_per_year": {}
    }
]