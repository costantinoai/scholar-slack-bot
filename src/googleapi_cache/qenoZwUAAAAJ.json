[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
<<<<<<< Updated upstream
=======
            "title": "Strong and precise modulation of human percepts via robustified ANNs",
            "pub_year": 2024,
            "citation": "Advances in Neural Information Processing Systems 36, 2024",
            "author": "Guy Gaziv and Michael Lee and James J DiCarlo",
            "journal": "Advances in Neural Information Processing Systems",
            "volume": "36",
            "abstract": "The visual object category reports of artificial neural networks (ANNs) are notoriously sensitive to tiny, adversarial image perturbations. Because human category reports (aka human percepts) are thought to be insensitive to those same small-norm perturbations--and locally stable in general--this argues that ANNs are incomplete scientific models of human visual perception. Consistent with this, we show that when small-norm image perturbations are generated by standard ANN models, human object category percepts are indeed highly stable. However, in this very same\" human-presumed-stable\" regime, we find that robustified ANNs reliably discover low-norm image perturbations that strongly disrupt human percepts. These previously undetectable human perceptual disruptions are massive in amplitude, approaching the same level of sensitivity seen in robustified ANNs. Further, we show that robustified ANNs support precise perceptual state interventions: they guide the construction of low-norm image perturbations that strongly alter human category percepts toward specific prescribed percepts. In sum, these contemporary models of biological visual processing are now accurate enough to guide strong and precise interventions on human perception."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:EkHepimYqZsC",
        "num_citations": 0,
        "pub_url": "https://proceedings.neurips.cc/paper_files/paper/2023/hash/d00904cebc0d5b69fada8ad33d0f1422-Abstract-Conference.html",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:APXw6_mt-vIJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "A unifying framework for functional organization in early and higher ventral visual cortex",
            "pub_year": 2024,
            "citation": "Neuron, 2024",
            "author": "Eshed Margalit and Hyodong Lee and Dawn Finzi and James J DiCarlo and Kalanit Grill-Spector and Daniel LK Yamins",
            "journal": "Neuron",
            "publisher": "Elsevier",
            "abstract": "A key feature of cortical systems is functional organization: the arrangement of functionally distinct neurons in characteristic spatial patterns. However, the principles underlying the emergence of functional organization in the cortex are poorly understood. Here, we develop the topographic deep artificial neural network (TDANN), the first model to predict several aspects of the functional organization of multiple cortical areas in the primate visual system. We analyze the factors driving the TDANN's success and find that it balances two objectives: learning a task-general sensory representation and maximizing the spatial smoothness of responses according to a metric that scales with cortical surface area. In turn, the representations learned by the TDANN are more brain-like than in spatially unconstrained models. Finally, we provide evidence that the TDANN's functional organization balances performance with between \u2026"
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:p__nRnzSRKYC",
        "num_citations": 0,
        "pub_url": "https://www.cell.com/neuron/abstract/S0896-6273(24)00279-4",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:z1sG3uKMzgIJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Software and Methods for Controlling Neural Responses in Deep Brain Regions",
            "pub_year": 2024,
            "citation": "US Patent App. 18/482,806, 2024",
            "author": "James Dicarlo and Pouya Bashivan and Kohitij Kar",
            "abstract": "Techniques for non-invasively controlling targeted neural activity of a subject are provided herein. The techniques include applying a stimulus input to the subject, the stimulus input being formed by a deep artificial neural network (ANN) model and being configured to elicit targeted neural activity within a brain of the subject. The stimulus input may be a pattern of luminous power generated by the deep ANN model and applied to retinae of the subject. The stimulus input may be generated by the deep ANN model based on a mapping of the subject's neural responses to neurons of the deep ANN model."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:4MWp96NkSFoC",
        "num_citations": 0,
        "pub_url": "https://patents.google.com/patent/US20240082534A1/en",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:GiNnVVNRPToJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Learning only a handful of latent variables produces neural-aligned CNN models of the ventral stream",
            "pub_year": 2024,
            "citation": "",
            "author": "Yudi Xie and Esther Alter and Jeremy Schwartz and James J DiCarlo",
            "abstract": "Image-computable modeling of primate ventral stream visual processing has made great strides via brainmapped versions of convolutional neural networks (CNNs) that are optimized on thousands of object categories (ImageNet), the performance of which strongly predicts CNNs\u2019 neural alignment. However, human and primate visual intelligence extends far beyond object categorization, encompassing a diverse range of tasks, such as estimating the latent variables of object position or pose in the image. The influence of task choice on neural alignment in CNNs, compared to CNN architecture, remains underexplored, partly due to the scarcity of largescale datasets with rich known labels beyond categories. 3D graphic engines, capable of creating training images with detailed information on various latent variables, offer a solution. Here, we asked how the choice of visual tasks that are used to train CNNs (ie, the set of latent variables to be estimated) affects their ventral stream neural alignment. We focused on the estimation of variables such as object position and pose, and we tested CNNs\u2019 neural alignment via the Brain-Score open science platform. We found some of these CNNs had neural alignment scores that were very close to those trained on ImageNet, even though their entire training experience has been on synthetic images. Additionally, we found training models on just a handful of latent variables achieved the same level of neural alignment as models trained on a much larger number of categories, suggesting that latent variable training is more efficient than category training in driving model-neural alignment. Moreover, we found \u2026"
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:ML0RJ9NH7IQC",
        "num_citations": 0,
        "pub_url": "https://dspace.mit.edu/bitstream/handle/1721.1/153744/COSYNE2024_multitask_vision_dspace.pdf?sequence=1&isAllowed=y",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:bnIyS89ZQzcJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Let's move forward: Image-computable models and a common model evaluation scheme are prerequisites for a scientific understanding of human vision\u2013CORRIGENDUM",
            "pub_year": 2024,
            "citation": "Behavioral and Brain Sciences 47, e66, 2024",
            "author": "James J DiCarlo and Daniel LK Yamins and Michael E Ferguson and Evelina Fedorenko and Matthias Bethge and Tyler Bonnen and Martin Schrimpf",
            "journal": "Behavioral and Brain Sciences",
            "volume": "47",
            "pages": "e66",
            "publisher": "Cambridge University Press",
            "abstract": "DiCarlo, JJ, Yamins, DLK, Ferguson, ME, Fedorenko, E., Bethge, M., Bonnen, T., & Schrimpf, M.(2023). Let's move forward: Image-computable models and a common model evaluation scheme are prerequisites for a scientific understanding of human vision. Behavioral and Brain Sciences, 46, e390. Google Scholar"
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:BUYA1_V_uYcC",
        "num_citations": 0,
        "pub_url": "https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/lets-move-forward-imagecomputable-models-and-a-common-model-evaluation-scheme-are-prerequisites-for-a-scientific-understanding-of-human-vision-corrigendum/4CC1766D3C5337FD5F46B825AF74D597",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:R_Qj6o1IBjoJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "How does the primate brain combine generative and discriminative computations in vision?",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2401.06005, 2024",
            "author": "Benjamin Peters and James J DiCarlo and Todd Gureckis and Ralf Haefner and Leyla Isik and Joshua Tenenbaum and Talia Konkle and Thomas Naselaris and Kimberly Stachenfeld and Zenna Tavares and Doris Tsao and Ilker Yildirim and Nikolaus Kriegeskorte",
            "journal": "arXiv preprint arXiv:2401.06005",
            "abstract": "Vision is widely understood as an inference problem. However, two contrasting conceptions of the inference process have each been influential in research on biological vision as well as the engineering of machine vision. The first emphasizes bottom-up signal flow, describing vision as a largely feedforward, discriminative inference process that filters and transforms the visual information to remove irrelevant variation and represent behaviorally relevant information in a format suitable for downstream functions of cognition and behavioral control. In this conception, vision is driven by the sensory data, and perception is direct because the processing proceeds from the data to the latent variables of interest. The notion of \"inference\" in this conception is that of the engineering literature on neural networks, where feedforward convolutional neural networks processing images are said to perform inference. The alternative conception is that of vision as an inference process in Helmholtz's sense, where the sensory evidence is evaluated in the context of a generative model of the causal processes giving rise to it. In this conception, vision inverts a generative model through an interrogation of the evidence in a process often thought to involve top-down predictions of sensory data to evaluate the likelihood of alternative hypotheses. The authors include scientists rooted in roughly equal numbers in each of the conceptions and motivated to overcome what might be a false dichotomy between them and engage the other perspective in the realm of theory and experiment. The primate brain employs an unknown algorithm that may combine the advantages of \u2026"
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:AvfA0Oy_GE0C",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2401.06005",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Do Topographic Deep ANN Models of the Primate Ventral Stream Predict the Perceptual Effects of Direct IT Cortical Interventions?",
            "pub_year": 2024,
            "citation": "bioRxiv, 2024.01. 09.572970, 2024",
            "author": "Martin Schrimpf and Paul McGrath and Eshed Margalit and James J DiCarlo",
            "journal": "bioRxiv",
            "pages": "2024.01. 09.572970",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Ever-advancing artificial neural network (ANN) models of the ventral visual stream capture core object recognition behavior and the neural mechanisms underlying it with increasing precision. These models take images as input, propagate through simulated neural representations that resemble biological neural representations at all stages of the primate ventral stream, and produce simulated behavioral choices that resemble primate behavioral choices. We here extend this modeling approach to make and test predictions of neural intervention experiments. Specifically, we enable a new prediction regime for topographic deep ANN (TDANN) models of primate visual processing through the development of perturbation modules that translate micro-stimulation, optogenetic suppression, and muscimol suppression into changes in model neural activity. This unlocks the ability to predict the behavioral effects from particular neural perturbations. We compare these predictions with the key results from the primate IT perturbation experimental literature via a suite of nine corresponding benchmarks. Without any fitting to the benchmarks, we find that TDANN models generated via co-training with both a spatial correlation loss and a standard categorization task qualitatively predict all nine behavioral results. In contrast, TDANN models generated via random topography or via topographic unit arrangement after classification training predict less than half of those results. However, the models' quantitative predictions are consistently misaligned with experimental data, over-predicting the magnitude of some behavioral effects and under-predicting others. None \u2026"
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:URolC5Kub84C",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2024.01.09.572970.abstract",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
>>>>>>> Stashed changes
            "title": "Robustified anns reveal wormholes between human category percepts",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2308.06887, 2023",
            "author": "Guy Gaziv and Michael J Lee and James J DiCarlo",
            "journal": "arXiv preprint arXiv:2308.06887",
            "abstract": "The visual object category reports of artificial neural networks (ANNs) are notoriously sensitive to tiny, adversarial image perturbations. Because human category reports (aka human percepts) are thought to be insensitive to those same small-norm perturbations -- and locally stable in general -- this argues that ANNs are incomplete scientific models of human visual perception. Consistent with this, we show that when small-norm image perturbations are generated by standard ANN models, human object category percepts are indeed highly stable. However, in this very same \"human-presumed-stable\" regime, we find that robustified ANNs reliably discover low-norm image perturbations that strongly disrupt human percepts. These previously undetectable human perceptual disruptions are massive in amplitude, approaching the same level of sensitivity seen in robustified ANNs. Further, we show that robustified ANNs support precise perceptual state interventions: they guide the construction of low-norm image perturbations that strongly alter human category percepts toward specific prescribed percepts. These observations suggest that for arbitrary starting points in image space, there exists a set of nearby \"wormholes\", each leading the subject from their current category perceptual state into a semantically very different state. Moreover, contemporary ANN models of biological visual processing are now accurate enough to consistently guide us to those portals."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:uc_IGeMz5qoC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=2862317547848986815",
        "cites_id": [
            "2862317547848986815"
        ],
        "pub_url": "https://arxiv.org/abs/2308.06887",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "How well do rudimentary plasticity rules predict adult visual object learning?",
            "pub_year": 2023,
            "citation": "PLOS Computational Biology 19 (12), e1011713, 2023",
            "author": "Michael J Lee and James J DiCarlo",
            "journal": "PLOS Computational Biology",
            "volume": "19",
            "number": "12",
            "pages": "e1011713",
            "publisher": "Public Library of Science",
            "abstract": "A core problem in visual object learning is using a finite number of images of a new object to accurately identify that object in future, novel images.One longstanding, conceptual hypothesis asserts that this core problem is solved by adult brains through two connected mechanisms: 1) the re-representation of incoming retinal images as points in a fixed, multidimensional neural space, and 2) the optimization of linear decision boundaries in that space, via simple plasticity rules applied to a single downstream layer.Though this scheme is biologically plausible, the extent to which it explains learning behavior in humans has been unclear\u2014in part because of a historical lack of image-computable models of the putative neural space, and in part because of a lack of measurements of human learning behaviors in difficult, naturalistic settings.Here, we addressed these gaps by 1) drawing from contemporary, image-computable models of the primate ventral visual stream to create a large set of testable learning models (n = 2,408 models), and 2) using online psychophysics to measure human learning trajectories over a varied set of tasks involving novel 3D objects (n = 371,000 trials), which we then used to develop (and publicly release) empirical benchmarks for comparing learning models to humans.We evaluated each learning model on these benchmarks, and found those based on deep, high-level representations from neural networks were surprisingly aligned with human behavior. While no tested model explained the entirety of replicable human behavior, these results establish that rudimentary plasticity rules, when combined with appropriate \u2026"
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:vDijr-p_gm4C",
        "num_citations": 0,
        "pub_url": "https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1011713",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The Quest for an Integrated Set of Neural Mechanisms Underlying Object Recognition in Primates",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2312.05956, 2023",
            "author": "Kohitij Kar and James J DiCarlo",
            "journal": "arXiv preprint arXiv:2312.05956",
            "abstract": "Visual object recognition -- the behavioral ability to rapidly and accurately categorize many visually encountered objects -- is core to primate cognition. This behavioral capability is algorithmically impressive because of the myriad identity-preserving viewpoints and scenes that dramatically change the visual image produced by the same object. Until recently, the brain mechanisms that support that capability were deeply mysterious. However, over the last decade, this scientific mystery has been illuminated by the discovery and development of brain-inspired, image-computable, artificial neural network (ANN) systems that rival primates in this behavioral feat. Apart from fundamentally changing the landscape of artificial intelligence (AI), modified versions of these ANN systems are the current leading scientific hypotheses of an integrated set of mechanisms in the primate ventral visual stream that support object recognition. What separates brain-mapped versions of these systems from prior conceptual models is that they are Sensory-computable, Mechanistic, Anatomically Referenced, and Testable (SMART). Here, we review and provide perspective on the brain mechanisms that the currently leading SMART models address. We review the empirical brain and behavioral alignment successes and failures of those current models. Given ongoing advances in neurobehavioral measurements and AI, we discuss the next frontiers for even more accurate mechanistic understanding. And we outline the likely applications of that SMART-model-based understanding."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:uWiczbcajpAC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2312.05956",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Probing Biological and Artificial Neural Networks with Task-dependent Neural Manifolds",
            "pub_year": 2023,
            "citation": "Conference on Parsimony and Learning (Proceedings Track), 2023",
            "author": "Michael Kuoch and Chi-Ning Chou and Nikhil Parthasarathy and Joel Dapello and James J DiCarlo and Haim Sompolinsky and SueYeon Chung",
            "conference": "Conference on Parsimony and Learning (Proceedings Track)",
            "abstract": "In recent years, growth in our understanding of the computations performed in both biological and artificial neural networks has largely been driven by either low-level mechanistic studies or global normative approaches. However, concrete methodologies for bridging the gap between these levels of abstraction remain elusive. In this work, we investigate the internal mechanisms of neural networks through the lens of neural population geometry, aiming to provide understanding at an intermediate level of abstraction, as a way to bridge that gap. Utilizing manifold capacity theory (MCT) from statistical physics and manifold alignment analysis (MAA) from high-dimensional statistics, we probe the underlying organization of task-dependent manifolds in deep neural networks and neural recordings from the macaque visual cortex. Specifically, we quantitatively characterize how different learning objectives lead to differences in the organizational strategies of these models and demonstrate how these geometric analyses are connected to the decodability of task-relevant information. Furthermore, these metrics show that macaque visual cortex data are more similar to unsupervised DNNs in terms of geometrical properties such as manifold position and manifold alignment. These analyses present a strong direction for bridging mechanistic and normative theories in neural networks through neural population geometry, potentially opening up many future research avenues in both machine learning and neuroscience."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:epqYDVWIO7EC",
        "num_citations": 0,
        "pub_url": "https://openreview.net/forum?id=MxBS6aw5Gd",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Let's move forward: Image-computable models and a common model evaluation scheme are prerequisites for a scientific understanding of human vision",
            "pub_year": 2023,
            "citation": "Behavioral and Brain Sciences 46, e390, 2023",
            "author": "James J DiCarlo and Daniel LK Yamins and Michael E Ferguson and Evelina Fedorenko and Matthias Bethge and Tyler Bonnen and Martin Schrimpf",
            "journal": "Behavioral and Brain Sciences",
            "volume": "46",
            "pages": "e390",
            "publisher": "Cambridge University Press",
            "abstract": "In the target article, Bowers et al. dispute deep artificial neural network (ANN) models as the currently leading models of human vision without producing alternatives. They eschew the use of public benchmarking platforms to compare vision models with the brain and behavior, and they advocate for a fragmented, phenomenon-specific modeling approach. These are unconstructive to scientific progress. We outline how the Brain-Score community is moving forward to add new model-to-human comparisons to its community-transparent suite of benchmarks."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:zLWjf1WUPmwC",
        "num_citations": 0,
        "pub_url": "https://www.cambridge.org/core/journals/behavioral-and-brain-sciences/article/lets-move-forward-imagecomputable-models-and-a-common-model-evaluation-scheme-are-prerequisites-for-a-scientific-understanding-of-human-vision/F2302912C8652DC2582F0E159C1BB6AB",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Software and methods for controlling neural responses in deep brain regions",
            "pub_year": 2023,
            "citation": "US Patent 11,813,406, 2023",
            "author": "James Dicarlo and Pouya Bashivan and Kohitij Kar",
            "abstract": "Techniques for non-invasively controlling targeted neural activity of a subject are provided herein. The techniques include applying a stimulus input to the subject, the stimulus input being formed by a deep artificial neural network (ANN) model and being configured to elicit targeted neural activity within a brain of the subject. The stimulus input may be a pattern of luminous power generated by the deep ANN model and applied to retinae of the subject. The stimulus input may be generated by the deep ANN model based on a mapping of the subject's neural responses to neurons of the deep ANN model."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:1qzjygNMrQYC",
        "num_citations": 0,
        "pub_url": "https://patents.google.com/patent/US11813406B2/en",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Catalyzing next-generation artificial intelligence through neuroai",
            "pub_year": 2023,
            "citation": "Nature communications 14 (1), 1597, 2023",
            "author": "Anthony Zador and Sean Escola and Blake Richards and Bence \u00d6lveczky and Yoshua Bengio and Kwabena Boahen and Matthew Botvinick and Dmitri Chklovskii and Anne Churchland and Claudia Clopath and James DiCarlo and Surya Ganguli and Jeff Hawkins and Konrad K\u00f6rding and Alexei Koulakov and Yann LeCun and Timothy Lillicrap and Adam Marblestone and Bruno Olshausen and Alexandre Pouget and Cristina Savin and Terrence Sejnowski and Eero Simoncelli and Sara Solla and David Sussillo and Andreas S Tolias and Doris Tsao",
            "volume": "14",
            "number": "1",
            "pages": "1597",
            "publisher": "Nature Publishing Group UK",
            "abstract": "Neuroscience has long been an essential driver of progress in artificial intelligence (AI). We propose that to accelerate progress in AI, we must invest in fundamental research in NeuroAI. A core component of this is the embodied Turing test, which challenges AI animal models to interact with the sensorimotor world at skill levels akin to their living counterparts. The embodied Turing test shifts the focus from those capabilities like game playing and language that are especially well-developed or uniquely human to those capabilities \u2013 inherited from over 500 million years of evolution \u2013 that are shared with all animals. Building models that can pass the embodied Turing test will provide a roadmap for the next generation of AI."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:VLnqNzywnoUC",
        "num_citations": 45,
        "citedby_url": "/scholar?hl=en&cites=7012396176970419900",
        "cites_id": [
            "7012396176970419900"
        ],
        "pub_url": "https://www.nature.com/articles/s41467-023-37180-x",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:vA6hcCsJUWEJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 42
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "A Unifying Principle for the Functional Organization of Visual Cortex",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.05. 18.541361, 2023",
            "author": "Eshed Margalit and Hyodong Lee and Dawn Finzi and James J DiCarlo and Kalanit Grill-Spector and Daniel LK Yamins",
            "journal": "bioRxiv",
            "pages": "2023.05. 18.541361",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "A key feature of many cortical systems is functional organization: the arrangement of neurons with specific functional properties in characteristic spatial patterns across the cortical surface. However, the principles underlying the emergence and utility of functional organization are poorly understood. Here we develop the Topographic Deep Artificial Neural Network (TDANN), the first unified model to accurately predict the functional organization of multiple cortical areas in the primate visual system. We analyze the key factors responsible for the TDANN's success and find that it strikes a balance between two specific objectives: achieving a task-general sensory representation that is self-supervised, and maximizing the smoothness of responses across the cortical sheet according to a metric that scales relative to cortical surface area. In turn, the representations learned by the TDANN are lower dimensional and more brain-like than those in models that lack a spatial smoothness constraint. Finally, we provide evidence that the TDANN's functional organization balances performance with inter-area connection length, and use the resulting models for a proof-of-principle optimization of cortical prosthetic design. Our results thus offer a unified principle for understanding functional organization and a novel view of the functional role of the visual system in particular."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:nrtMV_XWKgEC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=615012094074270269",
        "cites_id": [
            "615012094074270269"
        ],
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.05.18.541361.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:PbLdtz32iAgJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "An empirical assay of view-invariant object learning in humans and comparison with baseline image-computable models",
            "pub_year": 2023,
            "citation": "bioRxiv, 2022.12. 31.522402, 2023",
            "author": "Michael J Lee and James J DiCarlo",
            "journal": "bioRxiv",
            "pages": "2022.12. 31.522402",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "How humans learn new visual objects is a longstanding scientific problem. Previous work has led to a diverse collection of models for how it is accomplished, but a current limitation in the field is a lack of empirical benchmarks which can be used to evaluate and compare specific models against each other. Here, we use online psychophysics to measure human behavioral learning trajectories over a set of tasks involving novel 3D objects. Consistent with intuition, these results show that humans generally require very few images (~ 6) to approach their asymptotic accuracy, find some object discriminations more easy to learn than others, and generalize quite well over a range of image transformations after even one view of each object. We then use those data to develop benchmarks that may be used to evaluate a learning model's similarity to humans. We make these data and benchmarks publicly available [http://www.github.com/mlee3142/hobj], and, to our knowledge, they are currently the largest publicly-available collection of learning-related psychophysics data in humans. Additionally, to serve as baselines for those benchmarks, we implement and test a large number of baseline models (n=1,932), each based on a standard cognitive theory of learning: that humans re-represent images in a fixed, Euclidean space, then learn linear decision boundaries in that space to identify objects in future images. We find some of these baseline models make surprisingly accurate predictions. However, we also find reliable prediction gaps between all baseline models and humans, particularly in the few-shot learning setting."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:fEOibwPWpKIC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=11538048138746159234",
        "cites_id": [
            "11538048138746159234"
        ],
        "pub_url": "https://www.biorxiv.org/content/10.1101/2022.12.31.522402.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:gmBSp6ZhH6AJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Strong and Precise Modulation of Human Percepts via Robustified ANNs",
            "pub_year": 2023,
            "citation": "Thirty-seventh Conference on Neural Information Processing Systems, 2023",
            "author": "Guy Gaziv and Michael J Lee and James J DiCarlo",
            "conference": "Thirty-seventh Conference on Neural Information Processing Systems",
            "abstract": "The visual object category reports of artificial neural networks (ANNs) are notoriously sensitive to tiny, adversarial image perturbations. Because human category reports (aka human percepts) are thought to be insensitive to those same small-norm perturbations -- and locally stable in general -- this argues that ANNs are incomplete scientific models of human visual perception. Consistent with this, we show that when small-norm image perturbations are generated by standard ANN models, human object category percepts are indeed highly stable.  However, in this very same \"human-presumed-stable\" regime, we find that robustified ANNs reliably discover low-norm image perturbations that strongly disrupt human percepts. These previously undetectable human perceptual disruptions are massive in amplitude, approaching the same level of sensitivity seen in robustified ANNs.  Further, we show that robustified ANNs support precise perceptual state interventions: they guide the construction of low-norm image perturbations that strongly alter human category percepts toward specific prescribed percepts.  In sum, these contemporary models of biological visual processing are now accurate enough to guide strong and precise interventions on human perception."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:EkHepimYqZsC",
        "num_citations": 0,
        "pub_url": "https://openreview.net/forum?id=5GmTI4LNqX",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Robustified ANNs Reveal Wormholes Between Human Category Percepts",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2308.06887, 2023",
            "author": "Guy Gaziv and Michael J Lee and James J DiCarlo",
            "journal": "arXiv preprint arXiv:2308.06887",
            "abstract": "The visual object category reports of artificial neural networks (ANNs) are notoriously sensitive to tiny, adversarial image perturbations. Because human category reports (aka human percepts) are thought to be insensitive to those same small-norm perturbations -- and locally stable in general -- this argues that ANNs are incomplete scientific models of human visual perception. Consistent with this, we show that when small-norm image perturbations are generated by standard ANN models, human object category percepts are indeed highly stable. However, in this very same \"human-presumed-stable\" regime, we find that robustified ANNs reliably discover low-norm image perturbations that strongly disrupt human percepts. These previously undetectable human perceptual disruptions are massive in amplitude, approaching the same level of sensitivity seen in robustified ANNs. Further, we show that robustified ANNs support precise perceptual state interventions: they guide the construction of low-norm image perturbations that strongly alter human category percepts toward specific prescribed percepts. These observations suggest that for arbitrary starting points in image space, there exists a set of nearby \"wormholes\", each leading the subject from their current category perceptual state into a semantically very different state. Moreover, contemporary ANN models of biological visual processing are now accurate enough to consistently guide us to those portals."
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:uc_IGeMz5qoC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2308.06887",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "fROI-level computational models enable broad-scale experimental testing and expose key divergences between models and brains",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5788-5788, 2023",
            "author": "Elizabeth Mieczkowski and Alex Abate and Willian De Faria and Kirsten Lydic and James DiCarlo and Nancy Kanwisher and N Apurva Ratan Murty",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5788-5788",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Deep convolutional neural network (DNN)-based models have emerged as our leading hypotheses of human vision. Here we describe, and expand upon, our latest effort to use DNN models of brain regions to explain key results from previous cognitive neuroscience and psychology experiments. Many stimuli in these prior experiments were highly manipulated (eg scrambled body parts, face parts, re-arranged spatial positions) often outside the domain of natural stimuli. These results can therefore be considered as tests of model generalization beyond naturalistic stimuli. We first performed these tests on the fusiform face area (FFA), parahippocampal place area (PPA) and the extrastriate body area (EBA). Our previous results (presented in VSS2022) showed that our fROI-level models recapitulate several key results from prior studies. We also observed that models did not perform as well on non-naturalistic stimuli \u2026"
        },
        "filled": true,
        "author_pub_id": "qenoZwUAAAAJ:ipzZ9siozwsC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2792491",
        "cites_per_year": {}
    }
]