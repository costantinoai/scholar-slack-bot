[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
<<<<<<< Updated upstream
=======
            "title": "Perceived Stereo Depth reflects Retinal Disparities, not 3D Geometry",
            "pub_year": 2024,
            "citation": "",
            "author": "Paul Linton and Nikolaus Kriegeskorte",
            "abstract": "We present a new illusion that challenges our traditional understanding of stereo vision. Traditional \u2018Triangulation\u2019accounts of stereo vision back-project from points on the retina to points in the world. This requires that stereo vision incorporates how binocular disparities fall off with the viewing distance squared. By contrast, Linton 2023 Phil Trans R Soc B 378: 20210455 proposes a \u2018Minimal Model\u2019of stereo vision where perceived stereo depth is simply a function (most likely a linear function) of the amount of disparity on the retina. We present a new illusion (the \u2018Linton Stereo Illusion\u2019) to adjudicate between these two approaches. The illusion consists of a smaller circle (at 40cm) in front of a larger circle (at 50cm), with constant angular sizes throughout. We move the larger circle forward by 10cm (to 40cm) and then back again (to 50cm). The question is, what distance should we move the smaller circle forward and back to maintain a constant perceived separation between the circles? Constant physical distance (10cm)(\u2018Triangulation\u2019) or constant disparity (6.7 cm)(\u2018Minimal Model\u2019)? Observers choose constant disparity. This leads us to four conclusions: First, perceived stereo depth appears to be best captured by the \u2018Minimal Model\u2019. Second, doubling disparity appears to double perceived depth, suggesting that perceived stereo depth is proportional to disparity. Third, changes in vergence appear to have no effect on perceived depth. Fourth, stereo \u2018depth constancy\u2019appears to be a cognitive (not perceptual) phenomenon, reflecting our experience of a world distorted in perceived stereo depth."
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:c6chOJGeGucC",
        "num_citations": 0,
        "pub_url": "https://europepmc.org/article/ppr/ppr813527",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:JEmRuESlaaEJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Source Invariance and Probabilistic Transfer: A Testable Theory of Probabilistic Neural Representations",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2404.08101, 2024",
            "author": "Samuel Lippl and Raphael Gerraty and John Morrison and Nikolaus Kriegeskorte",
            "journal": "arXiv preprint arXiv:2404.08101",
            "abstract": "As animals interact with their environments, they must infer properties of their surroundings. Some animals, including humans, can represent uncertainty about those properties. But when, if ever, do they use probability distributions to represent their uncertainty? It depends on which definition we choose. In this paper, we argue that existing definitions are inadequate because they are untestable. We then propose our own definition. There are two reasons why existing definitions are untestable. First, they do not distinguish between representations of uncertainty and representations of variables merely related to uncertainty ('representational indeterminacy'). Second, they do not distinguish between probabilistic representations of uncertainty and merely \"heuristic\" representations of uncertainty. We call this 'model indeterminacy' because the underlying problem is that we do not have access to the animal's generative model. We define probabilistic representations by two properties: 1) they encode uncertainty regardless of the source of the uncertainty ('source invariance'), 2) they support the efficient learning of new tasks that would be more difficult to learn given non-probabilistic representations ('probabilistic task transfer'). Source invariance indicates that they are representations of uncertainty rather than variables merely related to uncertainty, thereby solving representational indeterminacy. Probabilistic task transfer indicates that they are probabilistic representations of uncertainty rather than merely heuristic representations, thereby solving model indeterminacy."
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:DxlTmyU89zoC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2404.08101",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:KAC-r4zp43EJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Can neural networks benefit from objectives that encourage iterative convergent computations? A case study of ResNets and object classification",
            "pub_year": 2024,
            "citation": "Plos one 19 (3), e0293440, 2024",
            "author": "Samuel Lippl and Benjamin Peters and Nikolaus Kriegeskorte",
            "journal": "Plos one",
            "volume": "19",
            "number": "3",
            "pages": "e0293440",
            "publisher": "Public Library of Science",
            "abstract": "Recent work has suggested that feedforward residual neural networks (ResNets) approximate iterative recurrent computations. Iterative computations are useful in many domains, so they might provide good solutions for neural networks to learn. However, principled methods for measuring and manipulating iterative convergence in neural networks remain lacking. Here we address this gap by 1) quantifying the degree to which ResNets learn iterative solutions and 2) introducing a regularization approach that encourages the learning of iterative solutions. Iterative methods are characterized by two properties: iteration and convergence. To quantify these properties, we define three indices of iterative convergence. Consistent with previous work, we show that, even though ResNets can express iterative solutions, they do not learn them when trained conventionally on computer-vision tasks. We then introduce regularizations to encourage iterative convergent computation and test whether this provides a useful inductive bias. To make the networks more iterative, we manipulate the degree of weight sharing across layers using soft gradient coupling. This new method provides a form of recurrence regularization and can interpolate smoothly between an ordinary ResNet and a \u201crecurrent\u201d ResNet (i.e., one that uses identical weights across layers and thus could be physically implemented with a recurrent network computing the successive stages iteratively across time). To make the networks more convergent we impose a Lipschitz constraint on the residual functions using spectral normalization. The three indices of iterative convergence reveal that the \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:Z610oKUqOA4C",
        "num_citations": 0,
        "pub_url": "https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0293440",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:0VW4k9qEm10J:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Generative Adversarial Collaborations: A practical guide for conference organizers and participating scientists",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2402.12604, 2024",
            "author": "Gunnar Blohm and Benjamin Peters and Ralf Haefner and Leyla Isik and Nikolaus Kriegeskorte and Jennifer S Lieberman and Carlos R Ponce and Gemma Roig and Megan AK Peters",
            "journal": "arXiv preprint arXiv:2402.12604",
            "abstract": "Generative adversarial collaborations (GACs) are a form of formal teamwork between groups of scientists with diverging views. The goal of GACs is to identify and ultimately resolve the most important challenges, controversies, and exciting theoretical and empirical debates in a given research field. A GAC team would develop specific, agreed-upon avenues to resolve debates in order to move a field of research forward in a collaborative way. Such adversarial collaborations have many benefits and opportunities but also come with challenges. Here, we use our experience from (1) creating and running the GAC program for the Cognitive Computational Neuroscience (CCN) conference and (2) implementing and leading GACs on particular scientific problems to provide a practical guide for future GAC program organizers and leaders of individual GACs."
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:1n-LKbgTOzoC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2402.12604",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:uxFImCCXViEJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "How does the primate brain combine generative and discriminative computations in vision?",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2401.06005, 2024",
            "author": "Benjamin Peters and James J DiCarlo and Todd Gureckis and Ralf Haefner and Leyla Isik and Joshua Tenenbaum and Talia Konkle and Thomas Naselaris and Kimberly Stachenfeld and Zenna Tavares and Doris Tsao and Ilker Yildirim and Nikolaus Kriegeskorte",
            "journal": "arXiv preprint arXiv:2401.06005",
            "abstract": "Vision is widely understood as an inference problem. However, two contrasting conceptions of the inference process have each been influential in research on biological vision as well as the engineering of machine vision. The first emphasizes bottom-up signal flow, describing vision as a largely feedforward, discriminative inference process that filters and transforms the visual information to remove irrelevant variation and represent behaviorally relevant information in a format suitable for downstream functions of cognition and behavioral control. In this conception, vision is driven by the sensory data, and perception is direct because the processing proceeds from the data to the latent variables of interest. The notion of \"inference\" in this conception is that of the engineering literature on neural networks, where feedforward convolutional neural networks processing images are said to perform inference. The alternative conception is that of vision as an inference process in Helmholtz's sense, where the sensory evidence is evaluated in the context of a generative model of the causal processes giving rise to it. In this conception, vision inverts a generative model through an interrogation of the evidence in a process often thought to involve top-down predictions of sensory data to evaluate the likelihood of alternative hypotheses. The authors include scientists rooted in roughly equal numbers in each of the conceptions and motivated to overcome what might be a false dichotomy between them and engage the other perspective in the realm of theory and experiment. The primate brain employs an unknown algorithm that may combine the advantages of \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:N8RR74vhTp4C",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2401.06005",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "How to optimize neuroscience data utilization and experiment design for advancing primate visual and linguistic brain models?",
            "pub_year": 2024,
            "citation": "arXiv preprint arXiv:2401.03376, 2024",
            "author": "Greta Tuckute and Dawn Finzi and Eshed Margalit and Joel Zylberberg and SueYeon Chung and Alona Fyshe and Evelina Fedorenko and Nikolaus Kriegeskorte and Jacob Yates and Kalanit Grill Spector and Kohitij Kar",
            "journal": "arXiv preprint arXiv:2401.03376",
            "abstract": "In recent years, neuroscience has made significant progress in building large-scale artificial neural network (ANN) models of brain activity and behavior. However, there is no consensus on the most efficient ways to collect data and design experiments to develop the next generation of models. This article explores the controversial opinions that have emerged on this topic in the domain of vision and language. Specifically, we address two critical points. First, we weigh the pros and cons of using qualitative insights from empirical results versus raw experimental data to train models. Second, we consider model-free (intuition-based) versus model-based approaches for data collection, specifically experimental design and stimulus selection, for optimal model development. Finally, we consider the challenges of developing a synergistic approach to experimental design and model building, including encouraging data and model sharing and the implications of iterative additions to existing models. The goal of the paper is to discuss decision points and propose directions for both experimenters and model developers in the quest to understand the brain."
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:N0GlzNNR4l8C",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2401.03376",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
>>>>>>> Stashed changes
            "title": "The neuroconnectionist research programme",
            "pub_year": 2023,
            "citation": "Nature Reviews Neuroscience, 1-20, 2023",
            "author": "Adrien Doerig and Rowan P Sommers and Katja Seeliger and Blake Richards and Jenann Ismael and Grace W Lindsay and Konrad P Kording and Talia Konkle and Marcel AJ Van Gerven and Nikolaus Kriegeskorte and Tim C Kietzmann",
            "pages": "1-20",
            "publisher": "Nature Publishing Group UK",
            "abstract": "Artificial neural networks (ANNs) inspired by biology are beginning to be widely used to model behavioural and neural data, an approach we call \u2018neuroconnectionism\u2019. ANNs have been not only lauded as the current best models of information processing in the brain but also criticized for failing to account for basic cognitive functions. In this Perspective article, we propose that arguing about the successes and failures of a restricted set of current ANNs is the wrong approach to assess the promise of neuroconnectionism for brain science. Instead, we take inspiration from the philosophy of science, and in particular from Lakatos, who showed that the core of a scientific research programme is often not directly falsifiable but should be assessed by its capacity to generate novel insights. Following this view, we present neuroconnectionism as a general research programme centred around ANNs as a computational \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:HfY9tUF4VgMC",
        "num_citations": 27,
        "citedby_url": "/scholar?hl=en&cites=3334113232536501466",
        "cites_id": [
            "3334113232536501466"
        ],
        "pub_url": "https://www.nature.com/articles/s41583-023-00705-w",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:2nxE8lEmRS4J:scholar.google.com/",
        "cites_per_year": {
            "2022": 5,
            "2023": 22
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Statistical inference on representational geometries",
            "pub_year": 2023,
            "citation": "Elife 12, e82566, 2023",
            "author": "Heiko H Sch\u00fctt and Alexander D Kipnis and J\u00f6rn Diedrichsen and Nikolaus Kriegeskorte",
            "journal": "Elife",
            "volume": "12",
            "pages": "e82566",
            "publisher": "eLife Sciences Publications Limited",
            "abstract": "Neuroscience has recently made much progress, expanding the complexity of both neural activity measurements and brain-computational models. However, we lack robust methods for connecting theory and experiment by evaluating our new big models with our new big data. Here, we introduce new inference methods enabling researchers to evaluate and compare models based on the accuracy of their predictions of representational geometries: A good model should accurately predict the distances among the neural population representations (eg of a set of stimuli). Our inference methods combine novel 2-factor extensions of crossvalidation (to prevent overfitting to either subjects or conditions from inflating our estimates of model accuracy) and bootstrapping (to enable inferential model comparison with simultaneous generalization to both new subjects and new conditions). We validate the inference methods on data where the ground-truth model is known, by simulating data with deep neural networks and by resampling of calcium-imaging and functional MRI data. Results demonstrate that the methods are valid and conclusions generalize correctly. These data analysis methods are available in an open-source Python toolbox (rsatoolbox. readthedocs. io)."
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:-3_NAp5WSNkC",
        "num_citations": 6,
        "citedby_url": "/scholar?hl=en&cites=13540717859312847037",
        "cites_id": [
            "13540717859312847037"
        ],
        "pub_url": "https://elifesciences.org/articles/82566",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:vUghuCZL6rsJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 5
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The selfish scientist's guide to preprint posting",
            "pub_year": 2023,
            "citation": "Authorea Preprints, 2023",
            "author": "Nikolaus Kriegeskorte",
            "journal": "Authorea Preprints",
            "publisher": "Authorea",
            "abstract": "The selfish scientist\u2019s guide to preprint posting Page 1 P osted on 17 Apr 2023 \u2014 The cop yrigh t \nholder is the author/funder. All righ ts reserv ed. No reuse without p ermission. \u2014 h \nttps://doi.org/10.15200/winn.145838.88372 \u2014 This a preprin t and has not b een p ee r review ed. \nData ma y b e preliminary . The selfish scientist\u2019s guide to preprint posting Nikolaus \nKriegeskorte1 1Affiliation not available April 17, 2023 1 Page 2 READ REVIEWS WRITE A \nREVIEW CORRESPONDENCE: nikokriegeskorte@gmail.com DATE RECEIVED: March 18, 2016 \nDOI: 10.15200/winn.145838.88372 ARCHIVED: March 19, 2016 KEYWORDS: preprints, open \naccess, scholarly communication CITATION: Nikolaus Kriegeskorte, The selfish scientist\u2019s guide \nto preprint posting, The Winnower 3:e145838.88372 , 2016 , DOI: 10.15200/winn.145838.88372 \n\u00a9 Kriegeskorte This article is distributed under the terms of the Creative Commons \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:H2XcuePHLsAC",
        "num_citations": 6,
        "citedby_url": "/scholar?hl=en&cites=399328248193780758",
        "cites_id": [
            "399328248193780758"
        ],
        "pub_url": "https://www.authorea.com/doi/pdf/10.15200/winn.145838.88372",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:FoxeDu2yigUJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 3
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Testing the limits of natural language models for predicting human language judgements",
            "pub_year": 2023,
            "citation": "Nature Machine Intelligence, 1-13, 2023",
            "author": "Tal Golan and Matthew Siegelman and Nikolaus Kriegeskorte and Christopher Baldassano",
            "journal": "Nature Machine Intelligence",
            "pages": "1-13",
            "publisher": "Nature Publishing Group UK",
            "abstract": "Neural network language models appear to be increasingly aligned with how humans process and generate language, but identifying their weaknesses through adversarial examples is challenging due to the discrete nature of language and the complexity of human language perception. We bypass these limitations by turning the models against each other. We generate controversial sentence pairs where two language models disagree about which sentence is more likely to occur. Considering nine language models (including n-gram, recurrent neural networks and transformers), we created hundreds of controversial sentence pairs through synthetic optimization or by selecting sentences from a corpus. Controversial sentence pairs proved highly effective at revealing model failures and identifying models that aligned most closely with human judgements of which sentence is more likely. The most human \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:rMiSbtrAJs8C",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=16742959179608825855",
        "cites_id": [
            "16742959179608825855"
        ],
        "pub_url": "https://www.nature.com/articles/s42256-023-00718-1",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:_x9zdarwWugJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Deep neural networks and visuo-semantic models explain complementary components of human ventral-stream representational dynamics",
            "pub_year": 2023,
            "citation": "Journal of Neuroscience 43 (10), 1731-1741, 2023",
            "author": "Kamila M Jozwik and Tim C Kietzmann and Radoslaw M Cichy and Nikolaus Kriegeskorte and Marieke Mur",
            "journal": "Journal of Neuroscience",
            "volume": "43",
            "number": "10",
            "pages": "1731-1741",
            "publisher": "Society for Neuroscience",
            "abstract": "Deep neural networks (DNNs) are promising models of the cortical computations supporting human object recognition. However, despite their ability to explain a significant portion of variance in neural data, the agreement between models and brain representational dynamics is far from perfect. We address this issue by asking which representational features are currently unaccounted for in neural time series data, estimated for multiple areas of the ventral stream via source-reconstructed magnetoencephalography data acquired in human participants (nine females, six males) during object viewing. We focus on the ability of visuo-semantic models, consisting of human-generated labels of object features and categories, to explain variance beyond the explanatory power of DNNs alone. We report a gradual reversal in the relative importance of DNN versus visuo-semantic features as ventral-stream object \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:P7PM_jyRRcwC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=16634044447513850",
        "cites_id": [
            "16634044447513850"
        ],
        "pub_url": "https://www.jneurosci.org/content/43/10/1731.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:-tx4RpMYOwAJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The Topology and Geometry of Neural Representations",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2309.11028, 2023",
            "author": "Baihan Lin and Nikolaus Kriegeskorte",
            "journal": "arXiv preprint arXiv:2309.11028",
            "abstract": "A central question for neuroscience is how to characterize brain representations of perceptual and cognitive content. An ideal characterization should distinguish different functional regions with robustness to noise and idiosyncrasies of individual brains that do not correspond to computational differences. Previous studies have characterized brain representations by their representational geometry, which is defined by the representational dissimilarity matrix (RDM), a summary statistic that abstracts from the roles of individual neurons (or responses channels) and characterizes the discriminability of stimuli. Here we explore a further step of abstraction: from the geometry to the topology of brain representations. We propose topological representational similarity analysis (tRSA), an extension of representational similarity analysis (RSA) that uses a family of geo-topological summary statistics that generalizes the RDM to characterize the topology while de-emphasizing the geometry. We evaluate this new family of statistics in terms of the sensitivity and specificity for model selection using both simulations and functional MRI (fMRI) data. In the simulations, the ground truth is a data-generating layer representation in a neural network model and the models are the same and other layers in different model instances (trained from different random seeds). In fMRI, the ground truth is a visual area and the models are the same and other areas measured in different subjects. Results show that topology-sensitive characterizations of population codes are robust to noise and interindividual variability and maintain excellent sensitivity to the unique representational \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:UCVoGz2p8ukC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=12634262868688151801",
        "cites_id": [
            "12634262868688151801"
        ],
        "pub_url": "https://arxiv.org/abs/2309.11028",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Experientially-grounded and distributional semantic vectors uncover dissociable representations of conceptual categories",
            "pub_year": 2023,
            "citation": "Language, Cognition and Neuroscience, 1-25, 2023",
            "author": "Francesca Carota and Hamed Nili and Nikolaus Kriegeskorte and Friedemann Pulverm\u00fcller",
            "journal": "Language, Cognition and Neuroscience",
            "pages": "1-25",
            "publisher": "Routledge",
            "abstract": "Neuronal populations code similar concepts by similar activity patterns across the human brain's semantic networks. However, it is unclear to what extent such meaning-to-symbol mapping reflects distributional statistics, or experiential information grounded in sensorimotor and emotional knowledge. We asked whether integrating distributional and experiential data better distinguished conceptual categories than each method taken separately. We examined the similarity structure of fMRI patterns elicited by visually presented action- and object-related words using representational similarity analysis (RSA). We found that the distributional and experiential/integrative models respectively mapped the high-dimensional semantic space in left inferior frontal, anterior temporal, and in left precentral, posterior inferior/middle temporal cortex. Furthermore, results from model comparisons uncovered category-specific similarity \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:LHWLPdAD5FMC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=3395810221058183308",
        "cites_id": [
            "3395810221058183308"
        ],
        "pub_url": "https://www.tandfonline.com/doi/abs/10.1080/23273798.2023.2232481",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Affinity-based Attention in Self-supervised Transformers Predicts Dynamics of Object Grouping in Humans",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2306.00294, 2023",
            "author": "Hossein Adeli and Seoyoung Ahn and Nikolaus Kriegeskorte and Gregory Zelinsky",
            "journal": "arXiv preprint arXiv:2306.00294",
            "abstract": "The spreading of attention has been proposed as a mechanism for how humans group features to segment objects. However, such a mechanism has not yet been implemented and tested in naturalistic images. Here, we leverage the feature maps from self-supervised vision Transformers and propose a model of human object-based attention spreading and segmentation. Attention spreads within an object through the feature affinity signal between different patches of the image. We also collected behavioral data on people grouping objects in natural images by judging whether two dots are on the same object or on two different objects. We found that our models of affinity spread that were built on feature maps from the self-supervised Transformers showed significant improvement over baseline and CNN based models on predicting reaction time patterns of humans, despite not being trained on the task or with any other object labels. Our work provides new benchmarks for evaluating models of visual representation learning including Transformers."
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:jYy9R3AkpWgC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=11016673895008731220",
        "cites_id": [
            "11016673895008731220"
        ],
        "pub_url": "https://arxiv.org/abs/2306.00294",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:VIBQ5okW45gJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Predicting brain activity using Transformers",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.08. 02.551743, 2023",
            "author": "Hossein Adeli and Sun Minni and Nikolaus Kriegeskorte",
            "journal": "bioRxiv",
            "pages": "2023.08. 02.551743",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "The Algonauts challenge (Gifford et al. [2023]) called on the community to provide novel solutions for predicting brain activity of humans viewing natural scenes. This report provides an overview and technical details of our submitted solution. We use a general transformer encoder-decoder model to map images to fMRI responses. The encoder model is a vision transformer trained using self-supervised methods (DINOv2). The decoder uses queries corresponding to different brain regions of interests (ROI) in different hemispheres to gather relevant information from the encoder output for predicting neural activity in each ROI. The output tokens from the decoder are then linearly mapped to the fMRI activity. The predictive success (challenge score: 63.5229, rank 2) suggests that features from self-supervised transformers may deserve consideration as models of human visual brain representations and shows the effectiveness of transformer mechanisms (self and cross-attention) to learn the mapping from features to brain responses."
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:OWslULmvb_UC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=12489228320654659643",
        "cites_id": [
            "12489228320654659643"
        ],
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.08.02.551743.abstract",
        "cites_per_year": {
            "2023": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Human-like multiple object tracking through occlusion via gaze-following",
            "pub_year": 2023,
            "citation": "NeuRIPS 2023 Workshop on Gaze Meets ML, 2023",
            "author": "Benjamin Peters and Eivinas Butkus and Nikolaus Kriegeskorte",
            "conference": "NeuRIPS 2023 Workshop on Gaze Meets ML",
            "abstract": "State-of-the art multiple object tracking (MOT) models have recently been shown to behave in qualitatively different ways from human observers. They exhibit superhuman performance for large numbers of targets and subhuman performance when targets disappear behind occluders. Here we investigate whether human gaze behavior can help explain differences in human and model behavior. Human subjects watched scenes with objects of various appearances. They tracked a designated subset of the objects, which moved continuously and frequently disappeared behind static black-bar occluders, reporting the designated objects at the end of each trial. We measured eye movements during tracking and tracking accuracy. We found that human gaze behavior is clearly guided by task-relevance: designated objects were preferentially fixated. We compared human performance to that of cognitive models inspired by state-of-the art MOT models with object slots, where each slot represents model's probabilistic belief about the location and appearance of one object. In our model, incoming observations are unambiguously assigned to slots using the Hungarian algorithm. Locations are tracked probabilistically (given the hard assignment) with one Kalman filter per slot. We equipped the computational models with a fovea, yielding high-precision observations at the center and low-precision observations in the periphery. We found that constraining models to follow the same gaze behavior as humans (imposing the human measured fixation sequences) yields best captures human behavioral phenomena. These results demonstrate the importance of \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:zG6RlwjYRPQC",
        "num_citations": 0,
        "pub_url": "https://openreview.net/forum?id=arfdjgKyhz",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Extracting and visualizing hidden activations and computational graphs of PyTorch models with TorchLens",
            "pub_year": 2023,
            "citation": "Scientific Reports 13 (1), 14375, 2023",
            "author": "JohnMark Taylor and Nikolaus Kriegeskorte",
            "journal": "Scientific Reports",
            "volume": "13",
            "number": "1",
            "pages": "14375",
            "publisher": "Nature Publishing Group UK",
            "abstract": "Deep neural network models (DNNs) are essential to modern AI and provide powerful models of information processing in biological neural networks. Researchers in both neuroscience and engineering are pursuing a better understanding of the internal representations and operations that undergird the successes and failures of DNNs. Neuroscientists additionally evaluate DNNs as models of brain computation by comparing their internal representations to those found in brains. It is therefore essential to have a method to easily and exhaustively extract and characterize the results of the internal operations of any DNN. Many models are implemented in PyTorch, the leading framework for building DNN models. Here we introduce TorchLens, a new open-source Python package for extracting and characterizing hidden-layer activations in PyTorch models. Uniquely among existing approaches to this problem \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:SkU8VjQp03IC",
        "num_citations": 0,
        "pub_url": "https://www.nature.com/articles/s41598-023-40807-0",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Neural representation of occluded objects in visual cortex",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 4594-4594, 2023",
            "author": "Courtney Mansfield and Tim Kietzmann and Jasper van den Bosch and Ian Charest and Marieke Mur and Nikolaus Kriegeskorte and Fraser Smith",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "4594-4594",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "The ability of the human visual system to recognize occluded objects is striking, yet current models of vision struggle to account for this successfully. Previous studies investigating occlusion at both the behavioural and neural levels typically used simple shapes or cut outs as occluders, rather than other objects. The goal of the present study was to understand what best explains neural representations of occluded objects under more realistic occlusion ie, when objects occlude other objects. We approached this by explicitly relating activity patterns of occluded objects (eg a cup occluding a face) with those generated when viewing the same objects in isolation (the cup or the face). In an event-related fMRI design, participants (N= 12) performed a one-back task while being presented with objects presented in isolation (un-occluded), occluded by another object, or cut out by a corresponding object silhouette. We \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:eK4aujBuqBIC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791854",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Torchlens: A Python package for extracting and visualizing all hidden layer activations from arbitrary PyTorch models with minimal code",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5769-5769, 2023",
            "author": "JohnMark Taylor and Nikolaus Kriegeskorte",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5769-5769",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Deep neural networks (DNNs) remain the dominant AI models at many visual tasks, and as models for biological vision, making it crucial to better understand the internal representations and operations undergirding their successes and failures, and to carefully compare these processing stages to those found in the brain. PyTorch has emerged as the leading framework for building DNN models; it would thus be highly desirable to have a method for easily and exhaustively extracting and characterizing the results of the internal operations of any arbitrary PyTorch model. Here we introduce Torchlens, a new open source Python package for extracting and characterizing hidden layer activations from PyTorch models. Uniquely among existing approaches for this task, Torchlens has the following features: 1) it exhaustively extracts the results of all intermediate operations, not just those associated with PyTorch module \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:x9HjRiAMpasC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2792507",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Modeling the dynamics of spreading attention in objects: Do transformers behave like humans?",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5978-5978, 2023",
            "author": "Hossein Adeli and Seoyoung Ahn and Nikolaus Kriegeskorte and Gregory Zelinsky",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5978-5978",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Transformers have recently achieved state-of-the-art performance in many domains, including in solving the problems of object detection and grouping in images. However, despite their success, transformers are controversial as models of the human brain. Importantly, these models have not been shown to capture the way humans group and perceive objects. Here we explore the potential for the attention mechanism in transformers to map onto the dynamics of human object-based attention and grouping. We probe the mechanisms of object-based attention using a two-dot paradigm, where two markers are placed on an image and the task is to indicate whether they are on the same or different objects. Previous related work found that human reaction time in this task varies with the difficulty of object grouping and the spread of attention within an object. Our model first processes images through a convolutional \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:fXbrI0tPCuEC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2792319",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Experientially-grounded and distributional semantic vectors uncover dissociable representations of semantic categories",
            "pub_year": 2023,
            "citation": "Language, Cognition and Neuroscience. Advance online publication, 2023",
            "author": "Francesca Carota and Hamed Nili and Nikolaus Kriegeskorte and Friedemann Pulverm\u00fcller",
            "journal": "Language, Cognition and Neuroscience. Advance online publication",
            "publisher": "Routledge",
            "abstract": "Neuronal populations code similar concepts by similar activity patterns across the human brain's semantic networks. However, it is unclear to what extent such meaning-to-symbol mapping reflects distributional statistics, or experiential information grounded in sensorimotor and emotional knowledge. We asked whether integrating distributional and experiential data better distinguished conceptual categories than each method taken separately. We examined the similarity structure of fMRI patterns elicited by visually presented action-and object-related words using representational similarity analysis (RSA). We found that the distributional and experiential/integrative models respectively mapped the high-dimensional semantic space in left inferior frontal, anterior temporal, and in left precentral, posterior inferior/middle temporal cortex. Furthermore, results from model comparisons uncovered category-specific similarity patterns, as both distributional and experiential models matched the similarity patterns for action concepts in left fronto-temporal cortex, whilst the experiential/integrative (but not distributional) models matched the similarity patterns for object concepts in left fusiform and angular gyrus."
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:USX2HHcnDqcC",
        "num_citations": 0,
        "pub_url": "https://pure.mpg.de/pubman/faces/ViewItemOverviewPage.jsp?itemId=item_3517871",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "TorchLens: A Python package for extracting and visualizing hidden activations of PyTorch models",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023",
            "author": "JohnMark Taylor and Nikolaus Kriegeskorte",
            "journal": "bioRxiv",
            "publisher": "Cold Spring Harbor Laboratory Preprints",
            "abstract": "Deep neural network models (DNNs) are essential to modern AI and provide powerful models of information processing in biological neural networks. Researchers in both neuroscience and engineering are pursuing a better understanding of the internal representations and operations that undergird the successes and failures of DNNs. Neuroscientists additionally evaluate DNNs as models of brain computation by comparing their internal representations to those found in brains. It is therefore essential to have a method to easily and exhaustively extract and characterize the results of the internal operations of any DNN. Many models are implemented in PyTorch, the leading framework for building DNN models. Here we introduce TorchLens, a new open-source Python package for extracting and characterizing hidden-layer activations in PyTorch models. Uniquely among existing approaches to this problem \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:ealulPZkXgsC",
        "num_citations": 0,
        "pub_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10055035/",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:kIx1MolL5-MJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Deep neural networks are not a single hypothesis but a language for expressing computational hypotheses",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Tal Golan and JohnMark Taylor and Heiko Sch\u00fctt and Benjamin Peters and Rowan Paolo Sommers and Katja Seeliger and Adrien Doerig and Paul Linton and Talia Konkle and Marcel van Gerven and Konrad Kording and Blake Richards and Tim Christian Kietzmann and Grace W Lindsay and Nikolaus Kriegeskorte",
            "publisher": "PsyArXiv",
            "abstract": "An ideal vision model accounts for behavior and neurophysiology in both naturalistic conditions and designed lab experiments. Unlike psychological theories, artificial neural networks (ANNs) actually perform visual tasks and generate testable predictions for arbitrary inputs. These advantages enable ANNs to engage the entire spectrum of the evidence. Failures of particular models drive progress in a vibrant ANN research program of human vision."
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:Z98IfIjqAwMC",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/tr7gx/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:1VpvSvB-icIJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Iterative convergent computation may not be a useful inductive bias for residual neural networks",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.10. 13.562196, 2023",
            "author": "Samuel Lippl and Benjamin Peters and Nikolaus Kriegeskorte",
            "journal": "bioRxiv",
            "pages": "2023.10. 13.562196",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Recent work has suggested that feedforward residual neural networks (ResNets) approximate iterative recurrent computations. Iterative computations are useful in many domains, so they might provide good solutions for neural networks to learn. Here we quantify the degree to which ResNets learn iterative solutions and introduce a regularization approach that encourages learning of iterative solutions. Iterative methods are characterized by two properties: iteration and convergence. To quantify these properties, we define three indices of iterative convergence. Consistent with previous work, we show that, even though ResNets can express iterative solutions, they do not learn them when trained conventionally on computer vision tasks. We then introduce regularizations to encourage iterative convergent computation and test whether this provides a useful inductive bias. To make the networks more iterative, we manipulate the degree of weight sharing across layers using soft gradient coupling. This new method provides a form of recurrence regularization and can interpolate smoothly between an ordinary ResNet and a \u201crecurrent\u201d ResNet (i.e., one that uses identical weights across layers and thus could be physically implemented with a recurrent network computing the successive stages iteratively across time). To make the networks more convergent we impose a Lipschitz constraint on the residual functions using spectral normalization. The three indices of iterative convergence reveal that the gradient coupling and the Lipschitz constraint succeed at making the networks iterative and convergent, respectively. However, neither recurrence \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:KtrhGiDecpEC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.10.13.562196.abstract",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Experientially-grounded and distributional semantic vectors uncover dissociable representations of semantic with conceptual categories",
            "pub_year": 2023,
            "citation": "",
            "author": "Francesca Carota and Hamed Nili and Nikolaus Kriegeskorte and Friedemann Pulvermueller",
            "abstract": "Neuronal populations code similar concepts by similar activity patterns across the human brain\u2019s semantic networks. However, it is unclear to what extent such meaning-to-symbol mapping reflects distributional statistics, or experiential information grounded in sensorimotor and emotional knowledge. We asked whether integrating distributional and experiential data better distinguished conceptual categories than each method taken separately. We examined the similarity structure of fMRI patterns elicited by visually presented action-and object-related words using representational similarity analysis (RSA). We found that the distributional and experiential/integrative models respectively mapped the high-dimensional semantic space in left inferior frontal, anterior temporal, and in left precentral, posterior inferior/middle temporal cortex. Furthermore, results from model comparisons uncovered category-specific similarity patterns, as both distributional and experiential models matched the similarity patterns for action concepts in left fronto-temporal cortex, whilst the experiential/integrative (but not distributional) models matched the similarity patterns for object concepts in left fusiform and angular gyrus."
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:q2HS4OCVtYIC",
        "num_citations": 0,
        "pub_url": "https://repository.ubn.ru.nl/bitstream/handle/2066/295392/295392.pdf?sequence=1",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Emergence of brain-like mirror-symmetric viewpoint tuning in convolutional neural networks",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.01. 05.522909, 2023",
            "author": "Amirhossein Farzmahdi and Wilbert Zarco and Winrich Freiwald and Nikolaus Kriegeskorte and Tal Golan",
            "journal": "bioRxiv",
            "pages": "2023.01. 05.522909",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Primates can recognize objects despite 3D geometric variations such as in-depth rotations. The computational mechanisms that give rise to such invariances are yet to be fully understood. A curious case of partial invariance occurs in the macaque face-patch AL and in fully connected layers of deep convolutional networks in which neurons respond similarly to mirror-symmetric views (e.g., left and right profiles). Why does this tuning develop? Here, we propose a simple learning-driven explanation for mirror-symmetric viewpoint tuning. We show that mirror-symmetric viewpoint tuning for faces emerges in the fully connected layers of convolutional deep neural networks trained on object recognition tasks, even when the training dataset does not include faces. First, using 3D objects rendered from multiple views as test stimuli, we demonstrate that mirror-symmetric viewpoint tuning in convolutional neural network models is not unique to faces: it emerges for multiple object categories with bilateral symmetry. Second, we show why this invariance emerges in the models. Learning to discriminate among bilaterally symmetric object categories induces reflection-equivariant intermediate representations. AL-like mirror-symmetric tuning is achieved when such equivariant responses are spatially pooled by downstream units with sufficiently large receptive fields. These results explain how mirror-symmetric viewpoint tuning can emerge in neural networks, providing a theory of how they might emerge in the primate brain. Our theory predicts that mirror-symmetric viewpoint tuning can emerge as a consequence of exposure to bilaterally symmetric objects \u2026"
        },
        "filled": true,
        "author_pub_id": "w6M4YN4AAAAJ:JjBZBFkNMTQC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.01.05.522909.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:W2e38C0w7IsJ:scholar.google.com/",
        "cites_per_year": {}
    }
]