[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The neuroconnectionist research programme",
            "pub_year": 2023,
            "citation": "Nature Reviews Neuroscience, 1-20, 2023",
            "author": "Adrien Doerig and Rowan P Sommers and Katja Seeliger and Blake Richards and Jenann Ismael and Grace W Lindsay and Konrad P Kording and Talia Konkle and Marcel AJ Van Gerven and Nikolaus Kriegeskorte and Tim C Kietzmann",
            "pages": "1-20",
            "publisher": "Nature Publishing Group UK",
            "abstract": "Artificial neural networks (ANNs) inspired by biology are beginning to be widely used to model behavioural and neural data, an approach we call \u2018neuroconnectionism\u2019. ANNs have been not only lauded as the current best models of information processing in the brain but also criticized for failing to account for basic cognitive functions. In this Perspective article, we propose that arguing about the successes and failures of a restricted set of current ANNs is the wrong approach to assess the promise of neuroconnectionism for brain science. Instead, we take inspiration from the philosophy of science, and in particular from Lakatos, who showed that the core of a scientific research programme is often not directly falsifiable but should be assessed by its capacity to generate novel insights. Following this view, we present neuroconnectionism as a general research programme centred around ANNs as a computational \u2026"
        },
        "filled": true,
        "author_pub_id": "JXcWFkgAAAAJ:sszUF3NjhM4C",
        "num_citations": 18,
        "citedby_url": "/scholar?hl=en&cites=3334113232536501466",
        "cites_id": [
            "3334113232536501466"
        ],
        "pub_url": "https://www.nature.com/articles/s41583-023-00705-w",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:2nxE8lEmRS4J:scholar.google.com/",
        "cites_per_year": {
            "2022": 3,
            "2023": 15
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Deep neural networks and visuo-semantic models explain complementary components of human ventral-stream representational dynamics",
            "pub_year": 2023,
            "citation": "Journal of Neuroscience 43 (10), 1731-1741, 2023",
            "author": "Kamila M Jozwik and Tim C Kietzmann and Radoslaw M Cichy and Nikolaus Kriegeskorte and Marieke Mur",
            "journal": "Journal of Neuroscience",
            "volume": "43",
            "number": "10",
            "pages": "1731-1741",
            "publisher": "Society for Neuroscience",
            "abstract": "Deep neural networks (DNNs) are promising models of the cortical computations supporting human object recognition. However, despite their ability to explain a significant portion of variance in neural data, the agreement between models and brain representational dynamics is far from perfect. We address this issue by asking which representational features are currently unaccounted for in neural time series data, estimated for multiple areas of the ventral stream via source-reconstructed magnetoencephalography data acquired in human participants (nine females, six males) during object viewing. We focus on the ability of visuo-semantic models, consisting of human-generated labels of object features and categories, to explain variance beyond the explanatory power of DNNs alone. We report a gradual reversal in the relative importance of DNN versus visuo-semantic features as ventral-stream object \u2026"
        },
        "filled": true,
        "author_pub_id": "JXcWFkgAAAAJ:QyXJ3EUuO1IC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=16634044447513850",
        "cites_id": [
            "16634044447513850"
        ],
        "pub_url": "https://www.jneurosci.org/content/43/10/1731.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:-tx4RpMYOwAJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Characterising representation dynamics in recurrent neural networks for object recognition",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2308.12435, 2023",
            "author": "Sushrut Thorat and Adrien Doerig and Tim C Kietzmann",
            "journal": "arXiv preprint arXiv:2308.12435",
            "abstract": "Recurrent neural networks (RNNs) have yielded promising results for both recognizing objects in challenging conditions and modeling aspects of primate vision. However, the representational dynamics of recurrent computations remain poorly understood, especially in large-scale visual models. Here, we studied such dynamics in RNNs trained for object classification on MiniEcoset, a novel subset of ecoset. We report two main insights. First, upon inference, representations continued to evolve after correct classification, suggesting a lack of the notion of being ``done with classification''. Second, focusing on ``readout zones'' as a way to characterize the activation trajectories, we observe that misclassified representations exhibit activation patterns with lower L2 norm, and are positioned more peripherally in the readout zones. Such arrangements help the misclassified representations move into the correct zones as time progresses. Our findings generalize to networks with lateral and top-down connections, and include both additive and multiplicative interactions with the bottom-up sweep. The results therefore contribute to a general understanding of RNN dynamics in naturalistic tasks. We hope that the analysis framework will aid future investigations of other types of RNNs, including understanding of representational dynamics in primate vision."
        },
        "filled": true,
        "author_pub_id": "JXcWFkgAAAAJ:w1MjKQ0l0TYC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2308.12435",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "End-to-end topographic networks as models of cortical map formation and human visual behaviour: moving beyond convolutions",
            "pub_year": 2023,
            "citation": "arXiv preprint arXiv:2308.09431, 2023",
            "author": "Zejin Lu and Adrien Doerig and Victoria Bosch and Bas Krahmer and Daniel Kaiser and Radoslaw M Cichy and Tim C Kietzmann",
            "journal": "arXiv preprint arXiv:2308.09431",
            "abstract": "Computational models are an essential tool for understanding the origin and functions of the topographic organisation of the primate visual system. Yet, vision is most commonly modelled by convolutional neural networks that ignore topography by learning identical features across space. Here, we overcome this limitation by developing All-Topographic Neural Networks (All-TNNs). Trained on visual input, several features of primate topography emerge in All-TNNs: smooth orientation maps and cortical magnification in their first layer, and category-selective areas in their final layer. In addition, we introduce a novel dataset of human spatial biases in object recognition, which enables us to directly link models to behaviour. We demonstrate that All-TNNs significantly better align with human behaviour than previous state-of-the-art convolutional models due to their topographic nature. All-TNNs thereby mark an important step forward in understanding the spatial organisation of the visual brain and how it mediates visual behaviour."
        },
        "filled": true,
        "author_pub_id": "JXcWFkgAAAAJ:F2UWTTQJPOcC",
        "num_citations": 0,
        "pub_url": "https://arxiv.org/abs/2308.09431",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Empirically Identifying and Computationally Modelling the Brain\u2013Behavior Relationship for Human Scene Categorization",
            "pub_year": 2023,
            "citation": "Journal of Cognitive Neuroscience, 1-19, 2023",
            "author": "Agnessa Karapetian and Antoniya Boyanova and Muthukumar Pandaram and Klaus Obermayer and Tim C Kietzmann and Radoslaw M Cichy",
            "journal": "Journal of Cognitive Neuroscience",
            "pages": "1-19",
            "abstract": "Humans effortlessly make quick and accurate perceptual decisions about the nature of their immediate visual environment, such as the category of the scene they face. Previous research has revealed a rich set of cortical representations potentially underlying this feat. However, it remains unknown which of these representations are suitably formatted for decision-making. Here, we approached this question empirically and computationally, using neuroimaging and computational modelling. For the empirical part, we collected EEG data and RTs from human participants during a scene categorization task (natural vs. man-made). We then related neural representations to behavior using a multivariate extension of signal detection theory. We observed a correlation specifically between\u223c 100 msec and\u223c 200 msec after stimulus onset, suggesting that the neural scene representations in this time period are suitably \u2026"
        },
        "filled": true,
        "author_pub_id": "JXcWFkgAAAAJ:3bvyWxjaHKcC",
        "num_citations": 0,
        "pub_url": "https://direct.mit.edu/jocn/article/doi/10.1162/jocn_a_02043/117201",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Neural representation of occluded objects in visual cortex",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 4594-4594, 2023",
            "author": "Courtney Mansfield and Tim Kietzmann and Jasper van den Bosch and Ian Charest and Marieke Mur and Nikolaus Kriegeskorte and Fraser Smith",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "4594-4594",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "The ability of the human visual system to recognize occluded objects is striking, yet current models of vision struggle to account for this successfully. Previous studies investigating occlusion at both the behavioural and neural levels typically used simple shapes or cut outs as occluders, rather than other objects. The goal of the present study was to understand what best explains neural representations of occluded objects under more realistic occlusion ie, when objects occlude other objects. We approached this by explicitly relating activity patterns of occluded objects (eg a cup occluding a face) with those generated when viewing the same objects in isolation (the cup or the face). In an event-related fMRI design, participants (N= 12) performed a one-back task while being presented with objects presented in isolation (un-occluded), occluded by another object, or cut out by a corresponding object silhouette. We \u2026"
        },
        "filled": true,
        "author_pub_id": "JXcWFkgAAAAJ:mUJArPsKIAAC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791854",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Scene representations underlying categorization behaviour emerge 100 to 200 ms after stimulus onset",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 4689-4689, 2023",
            "author": "Agnessa Karapetian and Antoniya Boyanova and Muthukumar Pandaram and Klaus Obermayer and Tim C Kietzmann and Radoslaw M Cichy",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "4689-4689",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Humans are constantly processing scene information from their environment, requiring quick and accurate decision-making and behavioural responses. Despite the importance of this process, it remains unknown which cortical representations might underlie this function. Additionally, to date there is no unifying model of scene categorization which can predict both neural and behavioural correlates as well as their relationship. Here, we approached these questions empirically and via computational modelling using deep neural networks. First, to determine which scene representations are suitably formatted for behaviour, we collected electroencephalography (EEG) data and reaction times from human subjects during a scene categorization task (natural vs. man-made) and an orthogonal task (fixation cross colour discrimination). Then, we linked the neural representations with reaction times in a within-task or a \u2026"
        },
        "filled": true,
        "author_pub_id": "JXcWFkgAAAAJ:oi2SiIJ9l4AC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791806",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Deep neural networks are not a single hypothesis but a language for expressing computational hypotheses",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Tal Golan and JohnMark Taylor and Heiko Sch\u00fctt and Benjamin Peters and Rowan Paolo Sommers and Katja Seeliger and Adrien Doerig and Paul Linton and Talia Konkle and Marcel van Gerven and Konrad Kording and Blake Richards and Tim Christian Kietzmann and Grace W Lindsay and Nikolaus Kriegeskorte",
            "publisher": "PsyArXiv",
            "abstract": "An ideal vision model accounts for behavior and neurophysiology in both naturalistic conditions and designed lab experiments. Unlike psychological theories, artificial neural networks (ANNs) actually perform visual tasks and generate testable predictions for arbitrary inputs. These advantages enable ANNs to engage the entire spectrum of the evidence. Failures of particular models drive progress in a vibrant ANN research program of human vision."
        },
        "filled": true,
        "author_pub_id": "JXcWFkgAAAAJ:VN7nJs4JPk0C",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/tr7gx/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:1VpvSvB-icIJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "High-level prediction errors in low-level visual cortex",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.08. 21.554095, 2023",
            "author": "David Richter and Tim C Kietzmann and Floris P de Lange",
            "journal": "bioRxiv",
            "pages": "2023.08. 21.554095",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Perception and behaviour are significantly moulded by expectations derived from our prior knowledge. Hierarchical predictive processing theories provide a principled account of the neural mechanisms underpinning these processes, casting perception as a hierarchical inference process. While numerous studies have shown stronger neural activity for surprising inputs, in line with this account, it is unclear what predictions are made across the cortical hierarchy, and therefore what kind of surprise drives this upregulation of activity. Here we leveraged fMRI and visual dissimilarity metrics derived from a deep neural network to arbitrate between two hypotheses: prediction errors may signal a local mismatch between input and expectation at each level of the cortical hierarchy, or prediction errors may incorporate feedback signals and thereby inherit complex tuning properties from higher areas. Our results are in line with this second hypothesis. Prediction errors in both low- and high-level visual cortex primarily scaled with high-level, but not low-level, visual surprise. This scaling with high-level surprise in early visual cortex strongly diverges from feedforward tuning, indicating a shift induced by predictive contexts. Mechanistically, our results suggest that high-level predictions may help constrain perceptual interpretations in earlier areas thereby aiding perceptual inference. Combined, our results elucidate the feature tuning of visual prediction errors and bolster a core hypothesis of hierarchical predictive processing theories, that predictions are relayed top-down to facilitate perception."
        },
        "filled": true,
        "author_pub_id": "JXcWFkgAAAAJ:-nhnvRiOwuoC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.08.21.554095.abstract",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Empirically identifying and computationally modelling the brain-behaviour relationship for human scene categorization",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.01. 22.525084, 2023",
            "author": "Agnessa Karapetian and Antoniya Boyanova and Muthukumar Pandaram and Klaus Obermayer and Tim Christian Kietzmann and Radoslaw Martin Cichy",
            "journal": "bioRxiv",
            "pages": "2023.01. 22.525084",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Humans effortlessly make quick and accurate perceptual decisions about the nature of their immediate visual environment, such as the category of the scene they face. Previous research has revealed a rich set of cortical representations potentially underlying this feat. However, it remains unknown which of these representations are suitably formatted for decision-making. Here, we approached this question empirically and computationally, using neuroimaging and computational modelling. For the empirical part, we collected electroencephalography (EEG) data and reaction times from human participants during a scene categorization task (natural vs. man-made). We then related neural representations to behaviour using a multivariate extension of signal detection theory. We observed a correlation specifically between ~100 ms and ~200 ms after stimulus onset, suggesting that the neural scene representations in this time period are suitably formatted for decision-making. For the computational part, we evaluated a recurrent convolutional neural network (RCNN) as a model of brain and behaviour. Unifying our previous observations in an image-computable model, the RCNN predicted well the neural representations, the behavioural scene categorization data, as well as the relationship between them. Our results identify and computationally characterize the neural and behavioural correlates of scene categorization in humans."
        },
        "filled": true,
        "author_pub_id": "JXcWFkgAAAAJ:-95Q15plzcUC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.01.22.525084.abstract",
        "cites_per_year": {}
    }
]