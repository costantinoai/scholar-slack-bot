[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Word-timestamped transcripts of two spoken narrative recall functional neuroimaging datasets",
            "pub_year": 2023,
            "citation": "Data in Brief 50, 109490, 2023",
            "author": "Savannah J Born and Kathy Shi and Haemy Lee Masson and Hongmi Lee and Yoonjung Lee and Janice Chen",
            "journal": "Data in Brief",
            "volume": "50",
            "pages": "109490",
            "publisher": "Elsevier",
            "abstract": "After watching audiovisual movies, human participants produced spoken narrative recollections during functional magnetic resonance imaging (fMRI); presented here are word-level timestamps of their speech, temporally aligned to the publicly shared fMRI data. For the \u201cFilmFestival\u201d dataset, twenty participants watched ten short audiovisual movies, approximately 2-8 minutes each. For the \u201cSherlock\u201d dataset, seventeen participants watched the first half of the first episode of BBC's Sherlock (48 minutes). After viewing, participants then verbally described what they remembered about the movies in their own words. Participants\u2019 speech was recorded using an MR-compatible microphone. The audio recordings were transcribed, then timestamped by a forced aligner; missing timestamps were filled in manually by human transcriptionists referencing the audio recording. Each file contains the participant's recall word by \u2026"
        },
        "filled": true,
        "author_pub_id": "U4i0WGsAAAAJ:r0BpntZqJG4C",
        "num_citations": 0,
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S2352340923005905",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Observed social touch is processed in a rapid, feedforward manner: an EEG-fMRI fusion study",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 4754-4754, 2023",
            "author": "Haemy Lee Masson and Leyla Isik",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "4754-4754",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Observing social touch evokes a strong social-affective response. Our ability to extract the social-affective meaning of observed touch is supported by enhanced communication between brain networks, including social brain regions and somatosensory cortex. Yet, the direction of information flow across these networks and the overall neural dynamics of these processes remain unknown. The current study uses electroencephalography (EEG) to uncover how representations unfold spatial-temporally in the brain during touch observation. Twenty participants watched 500 ms video clips showing social and non-social touch during EEG recording. Representational similarity analysis reveals that EEG neural patterns are explained by visual features beginning at 90 ms post video onset. Social-affective features are processed shortly after, explaining neural patterns beginning at 150 ms. Next, we tracked the spatial \u2026"
        },
        "filled": true,
        "author_pub_id": "U4i0WGsAAAAJ:iH-uZ7U-co4C",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791745",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Rapid processing of observed touch through social perceptual brain regions: an EEG-fMRI fusion study",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.05. 11.540376, 2023",
            "author": "Haemy Lee Masson and Leyla Isik",
            "journal": "bioRxiv",
            "pages": "2023.05. 11.540376",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Seeing social touch triggers a strong social-affective response that involves multiple brain networks, including visual, social perceptual, and somatosensory systems. Previous studies have identified the specific functional role of each system, but little is known about the speed and directionality of the information flow. Is this information extracted via the social perceptual system or from simulation from somatosensory cortex? To address this, we examined the spatiotemporal neural processing of observed touch. Twenty participants watched 500 ms video clips showing social and non-social touch during EEG recording. Visual and social-affective features were rapidly extracted in the brain, beginning at 90 and 150 ms after video onset, respectively. Combining the EEG data with fMRI data from our prior study with the same stimuli reveals that neural information first arises in early visual cortex (EVC), then in the temporoparietal junction and posterior superior temporal sulcus (TPJ/pSTS), and finally in the somatosensory cortex. EVC and TPJ/pSTS uniquely explain EEG neural patterns, while somatosensory cortex does not contribute to EEG patterns alone, suggesting that social-affective information may flow from TPJ/pSTS to somatosensory cortex. Together, these findings show that social touch is processed quickly, within the timeframe of feedforward visual processes, and that the social-affective meaning of touch is first extracted by a social perceptual pathway. Such rapid processing of social touch may be vital to its effective use during social interaction."
        },
        "filled": true,
        "author_pub_id": "U4i0WGsAAAAJ:j3f4tGmQtD8C",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.05.11.540376.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:BEMs7WNFzAwJ:scholar.google.com/",
        "cites_per_year": {}
    }
]