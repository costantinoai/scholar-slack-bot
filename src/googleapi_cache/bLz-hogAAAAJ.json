[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Shape-biased CNNs are Not Always Superior in Out-of-Distribution Robustness",
            "pub_year": 2024,
            "citation": "Proceedings of the IEEE/CVF Winter Conference on Applications of Computer \u2026, 2024",
            "author": "Xinkuan Qiu and Meina Kan and Yongbin Zhou and Yanchao Bi and Shiguang Shan",
            "conference": "Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision",
            "pages": "2326-2335",
            "abstract": "In recent years, Out-of-Distribution (ood) Robustness has garnered increasing attention in Deep Learning, and shape-biased Convolutional Neural Networks (CNNs) are believed to exhibit higher robustness, attributed to the inherent shape-based decision rule of human cognition. In this work, we delve deeper into the intricate relationship between shape/texture information and ood robustness by leveraging a carefully curated\" Category-Balanced ImageNet\" dataset. We find that shape information is not always superior in distinguishing distinct categories and shape-biased model is not always superior across various ood scenarios. Motivated by these insightful findings, we design a novel method named Shape-Texture Adaptive Recombination (STAR) to achieve higher ood robustness. A category-balanced dataset is firstly used to pretrain a debiased backbone and three specialized heads, each adept at robustly extracting shape, texture, and debiased features. Subsequently, an instance-adaptive recombination head is trained to adaptively adjust the contributions of these distinctive features for each given instance. Through comprehensive experiments, our proposed method achieves state-of-the-art ood robustness across various scenarios such as image corruptions, adversarial attacks, style shifts, and dataset shifts, demonstrating its effectiveness."
        },
        "filled": true,
        "author_pub_id": "bLz-hogAAAAJ:Z5m8FVwuT1cC",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=4066441509092796710",
        "cites_id": [
            "4066441509092796710"
        ],
        "pub_url": "https://openaccess.thecvf.com/content/WACV2024/html/Qiu_Shape-Biased_CNNs_Are_Not_Always_Superior_in_Out-of-Distribution_Robustness_WACV_2024_paper.html",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Jilh8QHnbjgJ:scholar.google.com/",
        "cites_per_year": {
            "2024": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Neural correlates of an illusionary sense of agency caused by virtual reality",
            "pub_year": 2024,
            "citation": "Cerebral Cortex 34 (2), bhad547, 2024",
            "author": "Yiyang Cai and Huichao Yang and Xiaosha Wang and Ziyi Xiong and Simone K\u00fchn and Yanchao Bi and Kunlin Wei",
            "journal": "Cerebral Cortex",
            "volume": "34",
            "number": "2",
            "pages": "bhad547",
            "publisher": "Oxford University Press",
            "abstract": "Sense of agency (SoA) is the sensation that self-actions lead to ensuing perceptual consequences. The prospective mechanism emphasizes that SoA arises from motor prediction and its comparison with actual action outcomes, while the reconstructive mechanism stresses that SoA emerges from retrospective causal processing about the action outcomes. Consistent with the prospective mechanism, motor planning regions were identified by neuroimaging studies using the temporal binding (TB) effect, a behavioral measure often linked to implicit SoA. Yet, TB also occurs during passive observation of another\u2019s action, lending support to the reconstructive mechanism, but its neural correlates remain unexplored. Here, we employed virtual reality (VR) to modulate such observation-based SoA and examined it with functional magnetic resonance imaging (fMRI). After manipulating an avatar hand in VR, participants \u2026"
        },
        "filled": true,
        "author_pub_id": "bLz-hogAAAAJ:uc_IGeMz5qoC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=17776356617593515172",
        "cites_id": [
            "17776356617593515172"
        ],
        "pub_url": "https://academic.oup.com/cercor/article-abstract/34/2/bhad547/7607165",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:pGxTGClOsvYJ:scholar.google.com/",
        "cites_per_year": {
            "2024": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Unraveling the impact of congenital deafness on individual brain organization",
            "pub_year": 2024,
            "citation": "bioRxiv, 2024.02. 02.578685, 2024",
            "author": "Lenia Amaral and Xiaosha Wang and Yanchao Bi and Ella Striem-Amit",
            "journal": "bioRxiv",
            "pages": "2024.02. 02.578685",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Research on brain plasticity, particularly in the context of deafness, consistently emphasizes the reorganization of the auditory cortex. However, a critical question arises: to what extent do all individuals with deafness show the same level of reorganization? To address this question, we examined the individual differences in deafness functional connectivity (FC), specifically from the deprived auditory cortex. Our findings demonstrate a remarkable differentiation between individuals deriving from the absence of shared auditory experiences, resulting in heightened FC variability among deaf individuals, compared to more consistent FC in the hearing group. Notably, this increased variability is particularly pronounced in regions where FC diverges between the deaf and hearing individuals, reflecting the individual differences in how the brain reorganizes in response to sensory deprivation. Additionally, connectivity to language regions also becomes more diverse in deafness across individuals. Importantly, this does not stem from delayed language acquisition, as it is found in deaf native signers, who are exposed to rich natural language since birth. Further, comparing FC diversity between deaf native signers and deaf delayed signers who were deprived of language in early development, we show that language experience also impacts individual differences, although to a more moderate extent. Overall, our research points out the intricate interplay between brain plasticity and individual differences, shedding light on the diverse ways reorganization manifests among individuals. It further joins findings in blindness, showing that individual differences are \u2026"
        },
        "filled": true,
        "author_pub_id": "bLz-hogAAAAJ:4MWp96NkSFoC",
        "num_citations": 1,
        "citedby_url": "/scholar?hl=en&cites=3808712220674204363",
        "cites_id": [
            "3808712220674204363"
        ],
        "pub_url": "https://www.biorxiv.org/content/10.1101/2024.02.02.578685.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:y6L51JVD2zQJ:scholar.google.com/",
        "cites_per_year": {
            "2024": 1
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Processing language partly shares neural genetic basis with processing tools and body parts",
            "pub_year": 2024,
            "citation": "eNeuro, 2024",
            "author": "Haojie Wen and Dahui Wang and Yanchao Bi",
            "journal": "eNeuro",
            "publisher": "Society for Neuroscience",
            "abstract": "Language is an evolutionarily salient faculty for humans that relies on a distributed brain network spanning across frontal, temporal, parietal, and subcortical regions. To understand whether the complex language network shares common or distinct genetic mechanisms, we examined the relationships between the genetic effects underlying the brain responses to language and a set of object domains that have been suggested to coevolve with language: tools, faces (indicating social), and body parts (indicating social and gesturing). Analyzing the twin datasets released by the Human Connectome Project (HCP) that had fMRI data from human twin subjects (monozygotic and dizygotic) undergoing language and working memory tasks contrasting multiple object domains (198 females and 144 males for the language task; 192 females and 142 males for the working memory task), we identified a set of cortical regions \u2026"
        },
        "filled": true,
        "author_pub_id": "bLz-hogAAAAJ:ILKRHgRFtOwC",
        "num_citations": 0,
        "pub_url": "https://www.eneuro.org/content/early/2024/06/16/ENEURO.0138-24.2024.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:SlapExwClKAJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Vision matters for shape representation: Evidence from sculpturing and drawing in the blind",
            "pub_year": 2024,
            "citation": "Cortex 174, 241-255, 2024",
            "author": "Shuang Tian and Lingjuan Chen and Xiaoying Wang and Guochao Li and Ze Fu and Yufeng Ji and Jiahui Lu and Xiaosha Wang and Shiguang Shan and Yanchao Bi",
            "journal": "Cortex",
            "volume": "174",
            "pages": "241-255",
            "publisher": "Elsevier",
            "abstract": "Shape is a property that could be perceived by vision and touch, and is classically considered to be supramodal. While there is mounting evidence for the shared cognitive and neural representation space between visual and tactile shape, previous research tended to rely on dissimilarity structures between objects and had not examined the detailed properties of shape representation in the absence of vision. To address this gap, we conducted three explicit object shape knowledge production experiments with congenitally blind and sighted participants, who were asked to produce verbal features, 3D clay models, and 2D drawings of familiar objects with varying levels of tactile exposure, including tools, large nonmanipulable objects, and animals. We found that the absence of visual experience (i.e., in the blind group) led to stronger differences in animals than in tools and large objects, suggesting that direct tactile \u2026"
        },
        "filled": true,
        "author_pub_id": "bLz-hogAAAAJ:vbGhcppDl1QC",
        "num_citations": 0,
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S0010945224000728",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:eC_bdlCCQq4J:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Separable amygdala activation patterns in the evaluations of robots",
            "pub_year": 2024,
            "citation": "Cerebral Cortex 34 (2), bhae011, 2024",
            "author": "Zhengde Wei and Ying Chen and Qian Zhao and Jiecheng Ren and Yi Piao and Pengyu Zhang and Rujing Zha and Bensheng Qiu and Daren Zhang and Yanchao Bi and Shihui Han and Chunbo Li and Xiaochu Zhang",
            "journal": "Cerebral Cortex",
            "volume": "34",
            "number": "2",
            "pages": "bhae011",
            "publisher": "Oxford University Press",
            "abstract": "Given the increasing presence of robots in everyday environments and the significant challenge posed by social interactions with robots, it is crucial to gain a deeper understanding into the social evaluations of robots. One potentially effective approach to comprehend the fundamental processes underlying controlled and automatic evaluations of robots is to probe brain response to different perception levels of robot-related stimuli. Here, we investigate controlled and automatic evaluations of robots based on brain responses during viewing of suprathreshold (duration: 200 ms) and subthreshold (duration: 17 ms) humanoid robot stimuli. Our behavioral analysis revealed that despite participants\u2019 self-reported positive attitudes, they held negative implicit attitudes toward humanoid robots. Neuroimaging analysis indicated that subthreshold presentation of humanoid robot stimuli elicited significant activation in the \u2026"
        },
        "filled": true,
        "author_pub_id": "bLz-hogAAAAJ:BwyfMAYsbu0C",
        "num_citations": 0,
        "pub_url": "https://academic.oup.com/cercor/article-abstract/34/2/bhae011/7611064",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Qy-BODzQlyMJ:scholar.google.com/",
        "cites_per_year": {}
    }
]