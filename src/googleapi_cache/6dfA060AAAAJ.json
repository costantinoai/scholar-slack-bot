[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Properties of imagined experience across visual, auditory, and other sensory modalities",
            "pub_year": 2024,
            "citation": "Consciousness and Cognition 117, 103598, 2024",
            "author": "Alexander A Sulfaro and Amanda K Robinson and Thomas A Carlson",
            "journal": "Consciousness and Cognition",
            "volume": "117",
            "pages": "103598",
            "publisher": "Academic Press",
            "abstract": "Little is known about the perceptual characteristics of mental images nor how they vary across sensory modalities. We conducted an exhaustive survey into how mental images are experienced across modalities, mainly targeting visual and auditory imagery of a single stimulus, the letter \u201cO\u201d, to facilitate direct comparisons. We investigated temporal properties of mental images (e.g. onset latency, duration), spatial properties (e.g. apparent location), effort (e.g. ease, spontaneity, control), movement requirements (e.g. eye movements), real-imagined interactions (e.g. inner speech while reading), beliefs about imagery norms and terminologies, as well as respondent confidence. Participants also reported on the five traditional senses and their prominence during thinking, imagining, and dreaming. Overall, visual and auditory experiences dominated mental events, although auditory mental images were superior to visual \u2026"
        },
        "filled": true,
        "author_pub_id": "6dfA060AAAAJ:ZVmBtQ9RJaQC",
        "num_citations": 0,
        "pub_url": "https://www.sciencedirect.com/science/article/pii/S1053810023001356",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Visual Representations: Insights from Neural Decoding",
            "pub_year": 2023,
            "citation": "Annual Review of Vision Science 9, 2023",
            "author": "Amanda K Robinson and Genevieve L Quek and Thomas A Carlson",
            "volume": "9",
            "publisher": "Annual Reviews",
            "abstract": "Patterns of brain activity contain meaningful information about the perceived world. Recent decades have welcomed a new era in neural analyses, with computational techniques from machine learning applied to neural data to decode information represented in the brain. In this article, we review how decoding approaches have advanced our understanding of visual representations and discuss efforts to characterize both the complexity and the behavioral relevance of these representations. We outline the current consensus regarding the spatiotemporal structure of visual representations and review recent findings that suggest that visual representations are at once robust to perturbations, yet sensitive to different mental states. Beyond representations of the physical world, recent decoding work has shone a light on how the brain instantiates internally generated states, for example, during imagery and prediction \u2026"
        },
        "filled": true,
        "author_pub_id": "6dfA060AAAAJ:AE81f6nWjdQC",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=1847840328721611713",
        "cites_id": [
            "1847840328721611713"
        ],
        "pub_url": "https://www.annualreviews.org/doi/abs/10.1146/annurev-vision-100120-025301",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:wbsXG_3YpBkJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 3
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Comparing mental imagery experiences across visual, auditory, and other sensory modalities",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.05. 15.540306, 2023",
            "author": "Alexander A Sulfaro and Amanda K Robinson and Thomas A Carlson",
            "journal": "bioRxiv",
            "pages": "2023.05. 15.540306",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Although mental imagery is often studied as a visual phenomenon, it can occur in any sensory modality. Given that mental images may recruit similar modality-specific neural systems to those which support veridical perception, the properties of mental images may be constrained by the modality in which they are experienced. Yet, little is known about how mental images are experienced at all, let alone how such experiences may vary depending on the modality in which they occur. Here we explored how mental images are experienced in different modalities using an extensive questionnaire. Mainly focusing on visual and auditory mental imagery, we surveyed participants on if and how they experienced their thought content in a sensory way when thinking about the appearance or sound of the letter \"O\". Specifically, we investigated temporal properties of imagined content (e.g. onset latency, duration), as well as spatial properties (e.g. apparent location), effort (e.g. ease, spontaneity, control), dependence on body movements (e.g. eye movements), interactions between real and imagined content (e.g. inner speech during reading), the perceived normality of imagery experiences, and how participants labeled their own experiences. Participants also ranked their mental imagery experiences in the five traditional sensory modalities and reported on the involvement of each modality during their thoughts, imagination, and dreams. Confidence ratings were taken for every answer recorded. Overall, visual and auditory experiences tended to dominate mental events relative to other sensory modalities. However, most people reported that auditory mental \u2026"
        },
        "filled": true,
        "author_pub_id": "6dfA060AAAAJ:kyHTWmgVackC",
        "num_citations": 2,
        "citedby_url": "/scholar?hl=en&cites=16780179564019896258",
        "cites_id": [
            "16780179564019896258"
        ],
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.05.15.540306.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:ws-shGgs3-gJ:scholar.google.com/",
        "cites_per_year": {
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Positive serial dependence effects in rating food images for appeal and calories",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5745-5745, 2023",
            "author": "David Alais and Thomas Carlson",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5745-5745",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Many studies have shown that recent perceptual history can bias present perception, known as serial dependence. We examined this phenomenon for sequences of food images that participants rated for either \u2018appeal\u2019or \u2018calories\u2019 and found strong positive dependencies. A large sample in an online experiment (n> 300) made 450 ratings of food images (150 stimuli, randomly presented three times), rating appeal and calories in separate counterbalanced blocks. A first analysis based on the previous trial\u2019s rating showed that for both appeal and calories there were clear assimilations towards the preceding trial\u2019s rating which were well described by a difference of Gaussian model. The amplitude of the serial effect for appeal was roughly twice that for calories. For food appeal, the serial effect was greater in males than females. There were no sex differences for calorie ratings. These serial analyses were based on \u2026"
        },
        "filled": true,
        "author_pub_id": "6dfA060AAAAJ:r655XaDZu5IC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2792529",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The dynamics of object coding within and across the hemispheres",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5973-5973, 2023",
            "author": "Amanda K Robinson and Tijl Grootswagers and Sophia M Shatek and Marlene Behrmann and Thomas A Carlson",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5973-5973",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "The human brain integrates information across the hemispheres to construct a coherent representation of the world. Characterising how visual information is coded in each hemisphere is crucial for understanding the nature of information transfer in the brain. Here, we investigated information processing within each hemisphere and its distinctiveness across hemispheres. We presented participants (N= 20) with images of faces, words and objects in rapid sequences while neural responses were measured using electroencephalography (EEG). To drive distinct responses in each hemisphere, stimuli were presented either centrally or lateralised to the left or right visual fields. Participants performed an orthogonal colour change task on dots that marked possible image positions. Multivariate pattern analyses were applied to the neural data to assess coding of object information in the brain, separately for electrode \u2026"
        },
        "filled": true,
        "author_pub_id": "6dfA060AAAAJ:1W67FsDfIBAC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2792324",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The Time-Course of Food Representation in the Human Brain",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.06. 06.543985, 2023",
            "author": "Denise Moerel and James Psihoyos and Thomas A Carlson",
            "journal": "bioRxiv",
            "pages": "2023.06. 06.543985",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "Humans make decisions about food every day. The visual system provides important information that forms a basis for these food decisions. Although previous research has focussed on visual object and category representations in the brain, it is still unclear how visually presented food is encoded by the brain. Here, we investigate the time-course of food representations in the brain. We used time-resolved multivariate analyses of electroencephalography (EEG) data, obtained from human participants (both sexes), to determine which food features are represented in the brain, and whether focused attention is needed for this. We recorded EEG while participants engaged in one of two tasks. In one task the stimuli were task relevant, whereas in the other task the stimuli were not task relevant. Our findings indicate that the brain can differentiate between food and non-food items from approximately 84 milliseconds after stimulus onset. The neural signal also contained information about food naturalness, the level of transformation, as well as the perceived caloric content. This information was present regardless of whether the food items were task relevant or not. Information about the perceived immediate edibility of the food, however, was only present when the food was task relevant. Furthermore, the recorded brain activity correlated with the behavioural responses in an odd-item-out task. Together, our results contribute to our understanding of how the human brain processes visually presented food."
        },
        "filled": true,
        "author_pub_id": "6dfA060AAAAJ:XyWThvt29VcC",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.06.06.543985.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:M7AkO8VKBwgJ:scholar.google.com/",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Modelling perception as a hierarchical competition differentiates imagined, veridical, and hallucinated percepts",
            "pub_year": 2023,
            "citation": "Neuroscience of Consciousness 2023 (1), niad018, 2023",
            "author": "Alexander A Sulfaro and Amanda K Robinson and Thomas A Carlson",
            "journal": "Neuroscience of Consciousness",
            "volume": "2023",
            "number": "1",
            "pages": "niad018",
            "publisher": "Oxford University Press",
            "abstract": "Mental imagery is a process by which thoughts become experienced with sensory characteristics. Yet, it is not clear why mental images appear diminished compared to veridical images, nor how mental images are phenomenologically distinct from hallucinations, another type of non-veridical sensory experience. Current evidence suggests that imagination and veridical perception share neural resources. If so, we argue that considering how neural representations of externally generated stimuli (i.e. sensory input) and internally generated stimuli (i.e. thoughts) might interfere with one another can sufficiently differentiate between veridical, imaginary, and hallucinatory perception. We here use a simple computational model of a serially connected, hierarchical network with bidirectional information flow to emulate the primate visual system. We show that modelling even first approximations of neural competition \u2026"
        },
        "filled": true,
        "author_pub_id": "6dfA060AAAAJ:KxdiYzj_eL0C",
        "num_citations": 0,
        "pub_url": "https://academic.oup.com/nc/article-pdf/doi/10.1093/nc/niad018/51234392/niad018.pdf",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "The representational dynamics of food in the human brain",
            "pub_year": 2023,
            "citation": "Proceedings of the Annual Meeting of the Cognitive Science Society 45 (45), 2023",
            "author": "Denise Moerel and James Psihoyos and Thomas A Carlson",
            "journal": "Proceedings of the Annual Meeting of the Cognitive Science Society",
            "volume": "45",
            "number": "45",
            "abstract": "The human brain can quickly organise visually perceived objects into categories. Although previous research has focussed on object and category representations in the brain, it is still unclear how one category of ecological importance, food, is represented in the brain. Here, we used time-resolved multivariate analyses of electroencephalography data to investigate the time-course of food representations in the brain. Our results show that the brain distinguishes between food and non-food items from approximately 84 ms onwards. The neural signal also contained information about the naturalness, the level of transformation, as well as the perceived caloric content of food. In addition, the recorded brain activity predicted the behavioural responses of different groups of participants who participated in one of two tasks: a naturalness food categorisation task and an odd-item-out task on 3 presented food items. Together, our results contribute to our understanding of how the human brain processes visually presented food."
        },
        "filled": true,
        "author_pub_id": "6dfA060AAAAJ:Xtec1x7NZGAC",
        "num_citations": 0,
        "pub_url": "https://escholarship.org/uc/item/2nk076x5",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Mapping the Dynamics of Visual Feature Coding: Insights into Perception and Integration",
            "pub_year": 2023,
            "citation": "bioRxiv, 2023.04. 26.538486, 2023",
            "author": "Tijl Grootswagers and Amanda K Robinson and Sophia M Shatek and Thomas Carlson",
            "journal": "bioRxiv",
            "pages": "2023.04. 26.538486",
            "publisher": "Cold Spring Harbor Laboratory",
            "abstract": "The basic computations performed in the human early visual cortex are the foundation for visual perception. While we know a lot about these computations from work in non-human animals, a key missing piece is how the coding of visual features relates to our perceptual experience. To investigate visual feature coding, interactions, and their relationship to human perception, we investigated neural responses and perceptual similarity judgements to a large set of visual stimuli that varied parametrically along four feature dimensions. We measured neural responses using electroencephalography (N=16) to 256 grating stimuli that varied in orientation, spatial frequency, contrast, and colour. We then mapped the response profiles of the neural coding of each visual feature and their interactions, and related these to independently obtained behavioural judgements of stimulus similarity. The results confirmed fundamental principles of feature coding in the visual system, such that all four features were processed simultaneously but differed in their dynamics, and there was distinctive conjunction coding for different combinations of features in the neural responses. Importantly, modelling of the behaviour revealed that every feature contributed to perceptual experience, despite the untargeted nature of the behavioural task. Further, the relationship between neural coding and behaviour was evident from initial processing stages, signifying that the fundamental features, not just their interactions, are crucial for perceptual experience. This study highlights the importance of understanding how feature coding progresses through the visual hierarchy and the \u2026"
        },
        "filled": true,
        "author_pub_id": "6dfA060AAAAJ:WMj-6b1RDO4C",
        "num_citations": 0,
        "pub_url": "https://www.biorxiv.org/content/10.1101/2023.04.26.538486.abstract",
        "cites_per_year": {}
    }
]