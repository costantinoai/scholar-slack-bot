[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Deep neural networks and visuo-semantic models explain complementary components of human ventral-stream representational dynamics",
            "pub_year": 2023,
            "citation": "Journal of Neuroscience 43 (10), 1731-1741, 2023",
            "author": "Kamila M Jozwik and Tim C Kietzmann and Radoslaw M Cichy and Nikolaus Kriegeskorte and Marieke Mur",
            "journal": "Journal of Neuroscience",
            "volume": "43",
            "number": "10",
            "pages": "1731-1741",
            "publisher": "Society for Neuroscience",
            "abstract": "Deep neural networks (DNNs) are promising models of the cortical computations supporting human object recognition. However, despite their ability to explain a significant portion of variance in neural data, the agreement between models and brain representational dynamics is far from perfect. We address this issue by asking which representational features are currently unaccounted for in neural time series data, estimated for multiple areas of the ventral stream via source-reconstructed magnetoencephalography data acquired in human participants (nine females, six males) during object viewing. We focus on the ability of visuo-semantic models, consisting of human-generated labels of object features and categories, to explain variance beyond the explanatory power of DNNs alone. We report a gradual reversal in the relative importance of DNN versus visuo-semantic features as ventral-stream object \u2026"
        },
        "filled": true,
        "author_pub_id": "Eo6JfS8AAAAJ:r0BpntZqJG4C",
        "num_citations": 3,
        "citedby_url": "/scholar?hl=en&cites=16634044447513850",
        "cites_id": [
            "16634044447513850"
        ],
        "pub_url": "https://www.jneurosci.org/content/43/10/1731.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:-tx4RpMYOwAJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 2
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Characterizing the spatial organization of population codes in macaque prefrontal cortex during visuospatial tasks",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5314-5314, 2023",
            "author": "Jinkang Derrick Xiang and Megan Roussy and Benjamin Corrigan and Rogelio Luna and Maryam Mofrad and Lyle Muller and Julio Martinez-Trujillo and Marieke Mur",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5314-5314",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "The lateral prefrontal cortex (LPFC) plays a key role in higher-order cognition. Electrophysiology studies in behaving animals show good decoding of task-relevant information from patterns of activity across neural populations in LPFC. However, functional magnetic resonance imaging (fMRI) studies in humans report only weak decoding of task-relevant information from LPFC activity. The limited access to prefrontal population codes in humans has hampered progress in understanding the neural computations that support human cognition. We hypothesize that the spatial topography of prefrontal population codes is too fine-grained to be effectively resolved by standard fMRI (2\u00d7 2\u00d7 2 mm3). We analyzed microelectrode array data (Utah array, 4\u00d7 4 mm2, 10\u00d7 10 channels spaced 0.4 mm apart) recorded from LPFC areas 8A and 9/46 of two macaques performing three visuospatial tasks: an oculomotor delayed \u2026"
        },
        "filled": true,
        "author_pub_id": "Eo6JfS8AAAAJ:BqipwSGYUEgC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2792079",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Bridging visual developmental neuroscience and deep learning: challenges and future directions",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 4680-4680, 2023",
            "author": "Marieke Mur",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "4680-4680",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "I will synthesize the work presented in this symposium and provide an outlook for the steps ahead in bridging visual developmental neuroscience and deep learning. I will first paint a picture of the emerging understanding of how categorical object representations in visual cortex arise over the course of development. The answer to this question can be considered to lie on a continuum, with one extreme suggesting that we are born with category-selective cortical modules, and the other extreme suggesting that categorical object representations in visual cortex arise from the structure of visual experience alone. Emerging evidence from both experimental and computational work suggests that the answer lies in between: categorical object representations may arise from an interplay between visual experience and constraints imposed by behavioral pressures as well as inductive biases built into our visual system. This \u2026"
        },
        "filled": true,
        "author_pub_id": "Eo6JfS8AAAAJ:YFjsv_pBGBYC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791814",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Neural representation of occluded objects in visual cortex",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 4594-4594, 2023",
            "author": "Courtney Mansfield and Tim Kietzmann and Jasper van den Bosch and Ian Charest and Marieke Mur and Nikolaus Kriegeskorte and Fraser Smith",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "4594-4594",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "The ability of the human visual system to recognize occluded objects is striking, yet current models of vision struggle to account for this successfully. Previous studies investigating occlusion at both the behavioural and neural levels typically used simple shapes or cut outs as occluders, rather than other objects. The goal of the present study was to understand what best explains neural representations of occluded objects under more realistic occlusion ie, when objects occlude other objects. We approached this by explicitly relating activity patterns of occluded objects (eg a cup occluding a face) with those generated when viewing the same objects in isolation (the cup or the face). In an event-related fMRI design, participants (N= 12) performed a one-back task while being presented with objects presented in isolation (un-occluded), occluded by another object, or cut out by a corresponding object silhouette. We \u2026"
        },
        "filled": true,
        "author_pub_id": "Eo6JfS8AAAAJ:NMxIlDl6LWMC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791854",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Measuring competitive oscillatory activity in visual cortical populations using fMRI",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 4777-4777, 2023",
            "author": "Reebal Rafeh and Geoffrey Ngo and Lyle E Muller and Ravi S Menon and Ali R Khan and Taylor W Schmitz and Marieke Mur",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "4777-4777",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Brain oscillations reflect the synchronous periodic activity of neural populations. Oscillations can either be intrinsic to a neural system or can be driven by external stimulation. To better understand competitive processes in neural systems, electroencephalography (EEG) studies use the steady state visual evoked potential (SSVEP) to broadly drive competing oscillations in the visual system. Here we extend the SSVEP paradigm to a functional magnetic resonance imaging (fMRI) experiment to examine whether accelerated fMRI acquisition sequences can capture competing hemodynamic oscillations in localized visual populations. In this 3T fMRI experiment, participants detected target color changes in one visual field quadrant while two gratings were presented in the opposite quadrant. These gratings oscillated at 0.125 and 0.2 Hz (oscillations) or did not oscillate (control). Data were rapidly sampled (TR= 300 ms; 2 \u2026"
        },
        "filled": true,
        "author_pub_id": "Eo6JfS8AAAAJ:hMod-77fHWUC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2791724",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Invariant object recognition in deep neural networks: impact of visual diet and learning goals",
            "pub_year": 2023,
            "citation": "Journal of Vision 23 (9), 5979-5979, 2023",
            "author": "Haider Al-Tahan and Farzad Shayanfar and Ehsan Tousi and Marieke Mur",
            "journal": "Journal of Vision",
            "volume": "23",
            "number": "9",
            "pages": "5979-5979",
            "publisher": "The Association for Research in Vision and Ophthalmology",
            "abstract": "Invariant object recognition is a hallmark of human vision. Humans recognize objects across a wide range of rotations, positions, and scales. A good model of human object recognition should, like humans, be able to generalize across real-world object transformations. Deep neural networks are currently the most popular computational models of the human ventral visual stream. Prior studies reported that these models show signatures of invariant object recognition but showed mixed results on how closely the models match human performance. Inconsistencies across studies in the ability of deep neural networks to recognize objects across transformations may be due to differences in the tested model architectures or training regimes. Here we test object recognition performance for different families of pretrained feedforward deep neural networks across object rotation, position, and scale. We included 95 models \u2026"
        },
        "filled": true,
        "author_pub_id": "Eo6JfS8AAAAJ:blknAaTinKkC",
        "num_citations": 0,
        "pub_url": "https://jov.arvojournals.org/article.aspx?articleid=2792318",
        "cites_per_year": {}
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Neural Networks Need Real-World Behavior",
            "pub_year": 2023,
            "citation": "PsyArXiv, 2023",
            "author": "Aedan Yue Li and Marieke Mur",
            "publisher": "PsyArXiv",
            "abstract": "Bowers et al.(2022) propose to use controlled behavioral experiments when evaluating deep neural networks as models of biological vision. We agree with the sentiment and draw parallels to the notion that \u201cneuroscience needs behavior\u201d. As a promising path forward, we suggest complementing image recognition tasks with increasingly realistic and well-controlled task environments that engage real-world object recognition behavior."
        },
        "filled": true,
        "author_pub_id": "Eo6JfS8AAAAJ:M3NEmzRMIkIC",
        "num_citations": 0,
        "pub_url": "https://psyarxiv.com/tswpa/download?format=pdf",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:Jo1dpbbpM3kJ:scholar.google.com/",
        "cites_per_year": {}
    }
]