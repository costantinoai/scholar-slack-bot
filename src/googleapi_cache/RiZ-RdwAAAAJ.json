[
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Driving and suppressing the human language network using large language models",
            "pub_year": 2023,
            "citation": "BioRxiv, 2023",
            "author": "Greta Tuckute and Aalok Sathe and Shashank Srikant and Maya Taliaferro and Mingye Wang and Martin Schrimpf and Kendrick Kay and Evelina Fedorenko",
            "journal": "BioRxiv",
            "publisher": "Cold Spring Harbor Laboratory Preprints",
            "abstract": "Transformer language models are today\u2019s most accurate models of language processing in the brain. Here, using fMRI-measured brain responses to 1,000 diverse sentences, we develop a GPT-based encoding model and use this model to identify new sentences that are predicted to drive or suppress responses in the human language network. We demonstrate that these model-selected novel sentences indeed drive and suppress activity of human language areas in new individuals (86% increase and 98% decrease relative to the average response to diverse naturalistic sentences). A systematic analysis of the model-selected sentences reveals that surprisal and well-formedness of linguistic input are key determinants of response strength in the language network. These results establish the ability of brain-aligned models to noninvasively control neural activity in higher-level cortical areas, like the language network."
        },
        "filled": true,
        "author_pub_id": "RiZ-RdwAAAAJ:YFjsv_pBGBYC",
        "num_citations": 10,
        "citedby_url": "/scholar?hl=en&cites=7567262626771322004",
        "cites_id": [
            "7567262626771322004"
        ],
        "pub_url": "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10120732/",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:lETLFkRRBGkJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 1,
            "2023": 9
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Aligning model and macaque inferior temporal cortex representations improves model-to-human behavioral alignment and adversarial robustness",
            "pub_year": 2023,
            "citation": "International Conference on Learning Representations (ICLR Notable Top-5%), 2023",
            "author": "Joel Dapello* and Kohitij Kar* and Martin Schrimpf and Robert Geary and Michael Ferguson and David D Cox and James DiCarlo",
            "conference": "International Conference on Learning Representations (ICLR Notable Top-5%)",
            "abstract": "While some state-of-the-art artificial neural network systems in computer vision are strikingly accurate models of the corresponding primate visual processing, there are still many discrepancies between these models and the behavior of primates on object recognition tasks. Many current models suffer from extreme sensitivity to adversarial attacks and often do not align well with the image-by-image behavioral error patterns observed in humans. Previous research has provided strong evidence that primate object recognition behavior can be very accurately predicted by neural population activity in the inferior temporal (IT) cortex, a brain area in the late stages of the visual processing hierarchy. Therefore, here we directly test whether making the late stage representations of models more similar to that of macaque IT produces new models that exhibit more robust, primate-like behavior. We conducted chronic, large-scale multi-electrode recordings across the IT cortex in six non-human primates (rhesus macaques). We then use these data to fine-tune (end-to-end) the model \u201cIT\u201d representations such that they are more aligned with the biological IT representations, while preserving accuracy on object recognition tasks. We generate a cohort of models with a range of IT similarity scores validated on held-out animals across two image sets with distinct statistics. Across a battery of optimization conditions, we observed a strong correlation between the models\u2019 IT-likeness and alignment with human behavior, as well as an increase in its adversarial robustness. We further assessed the limitations of this approach and find that the improvements in behavioral \u2026"
        },
        "filled": true,
        "author_pub_id": "RiZ-RdwAAAAJ:M3NEmzRMIkIC",
        "num_citations": 9,
        "citedby_url": "/scholar?hl=en&cites=15450149728660711715",
        "cites_id": [
            "15450149728660711715"
        ],
        "pub_url": "https://www.biorxiv.org/content/10.1101/2022.07.01.498495.abstract",
        "url_related_articles": "/scholar?oi=bibs&hl=en&q=related:I2lr31H1adYJ:scholar.google.com/",
        "cites_per_year": {
            "2022": 4,
            "2023": 5
        }
    },
    {
        "container_type": "Publication",
        "source": "AUTHOR_PUBLICATION_ENTRY",
        "bib": {
            "title": "Modeling Visual Impairments with Artificial Neural Networks: a Review",
            "pub_year": 2023,
            "citation": "Proceedings of the IEEE/CVF International Conference on Computer Vision \u2026, 2023",
            "author": "Lucia Schiatti and Monica Gori and Martin Schrimpf and Giulia Cappagli and Federica Morelli and Sabrina Signorini and Boris Katz and Andrei Barbu",
            "pages": "1987-1999",
            "abstract": "We present an approach to bridge the gap between the computational models of human vision and the clinical practice on visual impairments (VI). In a nutshell, we propose to connect advances in neuroscience and machine learning to study the impact of VI on key functional competencies and improve treatment strategies. We review related literature, with the goal of promoting the full exploitation of Artificial Neural Network (ANN) models in meeting the needs of visually impaired individuals and the operators working in the field of visual rehabilitation. We first summarize the existing types of visual issues, the key functional vision-related tasks, and the current methodologies used for the assessment of both. Second, we explore the ANNs best suitable to model visual issues and to predict their impact on functional vision-related tasks, at a behavioral (including performance and attention measures) and neural level. We provide guidelines to inform the future research about developing and deploying ANNs for clinical applications targeting individuals affected by VI."
        },
        "filled": true,
        "author_pub_id": "RiZ-RdwAAAAJ:J_g5lzvAfSwC",
        "num_citations": 0,
        "pub_url": "https://openaccess.thecvf.com/content/ICCV2023W/ACVR/html/Schiatti_Modeling_Visual_Impairments_with_Artificial_Neural_Networks_a_Review_ICCVW_2023_paper.html",
        "cites_per_year": {}
    }
]